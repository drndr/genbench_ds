# -*- coding: utf-8 -*-
"""Word Embedding rank.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kam2FvTjVZbLw08nQdFAlPXR50dTzRq4

Load libraries
"""

# imports
!pip install datasets
import pandas as pd
from numpy import dot
from numpy.linalg import norm

!git clone https://github.com/drndr/genbench_ds.git

!python /content/genbench_ds/data/mrr/codesearchnet_ruby/create_ds_mrr_ruby.py

"""Read the jsnol file"""

import json

def read_jsonl(filename):
    data = []
    with open(filename, 'r') as file:
        for line in file:
            data.append(json.loads(line))
    return data
filename = '/content/test_ruby_clf.jsonl'
data = read_jsonl(filename)

import json
with open('test_ruby.json', 'w') as f:
    json.dump(data, f)

"""Define the get_dataset_raw function to generate the distractors"""

import random
from typing import Dict, List
import datasets
import numpy as np
from more_itertools import chunked

def get_dataset_raw(n_distractors) -> Dict[str, datasets.Dataset]:
    raw_datasets: Dict[str, datasets.Dataset] = _load_data_source()
    output: Dict[str, datasets.Dataset] = {}
    random.seed(42)

    for split, dataset in raw_datasets.items():
        if split == "test":
            # Convert dataset to list for easier manipulation
            dataset_list = list(dataset)

            new_data = []

            for idx, item in enumerate(dataset_list):
                new_data.append(item)

                # Create other_items list once and then simply exclude the current item during sampling
                other_items = dataset_list[:idx] + dataset_list[idx+1:]
                random_items = random.sample(other_items, n_distractors)

                input_parts = item["input"].split("[CODESPLIT]")

                for random_item in random_items:
                    random_input_parts = random_item["input"].split("[CODESPLIT]")
                    new_input = input_parts[0] + "[CODESPLIT]" + random_input_parts[1]
                    new_item = {"input": new_input, "target": 0, "target_options": item["target_options"]}
                    new_data.append(new_item)
                print(len(new_data))

            # Convert list back to HuggingFace dataset
            output[split] = datasets.Dataset.from_dict({k: [dic[k] for dic in new_data] for k in new_data[0]})
        else:
            output[split] = dataset

    return output

def _load_data_source() -> Dict[str, datasets.Dataset]:
    return datasets.load_dataset("json", data_files={'test':'/content/test_ruby.json'})

"""Generate the new dataset"""

n_distractors = 99  # adjust this number as per your requirements
new_datasets = get_dataset_raw(n_distractors)

len(new_datasets['test'])

new_datasets['test']['input'][0]
