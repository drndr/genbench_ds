{"input": "Sign the  +.deb+ file with gpg. This has to be done as separate steps\n from creating the +.deb+ file. See +debsigs+ source for behavior\n replicated here. +https://gitlab.com/debsigs/debsigs/blob/master/debsigs.txt#L103-124+\n\n @return [void] [SEP] def sign_deb_file\n      if !signing_passphrase\n        log.info(log_key) { \"Signing not enabled for .deb file\" }\n        return\n      end\n\n      log.info(log_key) { \"Signing enabled for .deb file\" }\n\n      # Check our dependencies and determine command for GnuPG. +Omnibus.which+ returns the path, or nil.\n      gpg = nil\n      if Omnibus.which(\"gpg2\")\n        gpg = \"gpg2\"\n      elsif Omnibus.which(\"gpg\")\n        gpg = \"gpg\"\n      end\n\n      if gpg && Omnibus.which(\"ar\")\n        # Create a directory that will be cleaned when we leave the block\n        Dir.mktmpdir do |tmp_dir|\n          Dir.chdir(tmp_dir) do\n            # Extract the deb file contents\n            shellout!(\"ar x #{Config.package_dir}/#{package_name}\")\n            # Concatenate contents, in order per +debsigs+ documentation.\n            shellout!(\"cat debian-binary control.tar.* data.tar.* > complete\")\n            # Create signature (as +root+)\n            gpg_command =  \"#{gpg} --armor --sign --detach-sign\"\n            gpg_command << \" --local-user '#{project.maintainer}'\"\n            gpg_command << \" --homedir #{ENV['HOME']}/.gnupg\" # TODO: Make this configurable\n            ## pass the +signing_passphrase+ via +STDIN+\n            gpg_command << \" --batch --no-tty\"\n            ## Check `gpg` for the compatibility/need of pinentry-mode\n            # - We're calling gpg with the +--pinentry-mode+ argument, and +STDIN+ of +/dev/null+\n            # - This _will_ fail with exit code 2 no matter what. We want to check the +STDERR+\n            #   for the error message about the parameter. If it is _not present_ in the\n            #   output, then we _do_ want to add it. (If +grep -q+ is +1+, add parameter)\n            if shellout(\"#{gpg} --pinentry-mode loopback </dev/null 2>&1 | grep -q pinentry-mode\").exitstatus == 1\n              gpg_command << \" --pinentry-mode loopback\"\n            end\n            gpg_command << \" --passphrase-fd 0\"\n            gpg_command << \" -o _gpgorigin complete\"\n            shellout!(\"fakeroot #{gpg_command}\", input: signing_passphrase)\n            # Append +_gpgorigin+ to the +.deb+ file (as +root+)\n            shellout!(\"fakeroot ar rc #{Config.package_dir}/#{package_name} _gpgorigin\")\n          end\n        end\n      else\n        log.info(log_key) { \"Signing not possible. Ensure that GnuPG and GNU AR are available\" }\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Symbolizes and sanitizes keys in the option store\n\n @return [Object] @store [SEP] def sanitize_keys!\n      # Symbolize\n      manipulate_keys! { |key_name| key_name.is_a?(Symbol) ? key_name : key_name.to_sym }\n\n      # Underscoreize (because Cocaine doesn't like hyphens)\n      manipulate_keys! { |key_name| key_name.to_s.tr('-', '_').to_sym }\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Look for errors in factories and (optionally) their traits.\n Parameters:\n factory_names - which factories to lint; omit for all factories\n options:\n   traits : true - to lint traits as well as factories [SEP] def lint!(factory_names: nil, traits: false)\n      factories_to_lint = Array(factory_names || self.factory_names)\n      strategy = traits ? :factory_and_traits : :factory\n      Linter.new(self, factories_to_lint, strategy).lint!\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@param [ Hash ] values\n\n @return [ Hash ] [SEP] def verify_compatibility(values)\n      incompatible.each do |a|\n        last_match = ''\n\n        a.each do |key|\n          sym = choices[key].to_sym\n\n          next unless values.key?(sym)\n\n          raise Error, \"Incompatible choices detected: #{last_match}, #{key}\" unless last_match.empty?\n\n          last_match = key\n        end\n      end\n      values\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Checks if the given subject matches the given conditions hash.\n This behavior can be overriden by a model adapter by defining two class methods:\n override_matching_for_conditions?(subject, conditions) and\n matches_conditions_hash?(subject, conditions) [SEP] def matches_conditions_hash?(subject, conditions = @conditions)\n      if conditions.empty?\n        true\n      else\n        if model_adapter(subject).override_conditions_hash_matching? subject, conditions\n          model_adapter(subject).matches_conditions_hash? subject, conditions\n        else\n          conditions.all? do |name, value|\n            if model_adapter(subject).override_condition_matching? subject, name, value\n              model_adapter(subject).matches_condition? subject, name, value\n            else\n              attribute = subject.send(name)\n              if value.kind_of?(Hash)\n                if attribute.kind_of? Array\n                  attribute.any? { |element| matches_conditions_hash? element, value }\n                else\n                  !attribute.nil? && matches_conditions_hash?(attribute, value)\n                end\n              elsif !value.is_a?(String) && value.kind_of?(Enumerable)\n                value.include? attribute\n              else\n                attribute == value\n              end\n            end\n          end\n        end\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Application\n\n\ndef default_level\n  return Tml.session.application.default_level if Tml.session.application\n  @default_level\nend [SEP] def xmessage_rule_key_mapping\n      @rule_key_mapping ||= {\n          number: {\n              one: 'singular',\n              few: 'few',\n              many: 'many',\n              other: 'plural'\n          },\n          gender: {\n              male: 'male',\n              female: 'female',\n              neutral: 'neutral',\n              other: 'other',\n          },\n          date: {\n              future: 'future',\n              present: 'present',\n              past: 'past'\n          }\n      }\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Attach the dmg, storing a reference to the device for later use.\n\n @return [String]\n   the name of the attached device [SEP] def attach_dmg\n      @device ||= Dir.chdir(staging_dir) do\n        log.info(log_key) { \"Attaching dmg as disk\" }\n\n        cmd = shellout! <<-EOH.gsub(/^ {10}/, \"\")\n          hdiutil attach \\\\\n            -readwrite \\\\\n            -noverify \\\\\n            -noautoopen \\\\\n            \"#{writable_dmg}\" | egrep '^/dev/' | sed 1q | awk '{print $1}'\n        EOH\n\n        cmd.stdout.strip\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Rack 1.* method [SEP] def destroy_session(env, sid, options) # rack 1.x compatibilty\n      delete_session(Rack::Request.new(env), sid, options)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Append seed name as a prefix to file name and returns the path.\n\n @!visibility private [SEP] def path_with_prefix(seedname, path)\n      if @swift_seedname_prefix\n        components = path.split(\"/\")\n        prefix = seedname + \"_\"  # Alamofire_\n        filename = components[-1]  # Alamofire.swift\n        extension = File.extname(filename)  # .swift\n\n        # only swift files can have prefix in filename\n        if extension == '.swift' and not filename.start_with? prefix\n          filename = prefix + filename  # Alamofire_Alamofire.swift\n          newpath = components[0...-1].join('/') + '/' + filename\n          File.rename(path, newpath)  # rename real files\n          path = newpath\n        end\n      end\n      path\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Draws the drop-down list.\n\n Parameters:\n [alpha] (+Fixnum+) The opacity with which the drop-down list will be\n         drawn. Allowed values vary between 0 (fully transparent) and 255\n         (fully opaque).\n [z_index] (+Fixnum+) The z-order to draw the object. Objects with larger\n           z-orders will be drawn on top of the ones with smaller z-orders.\n [color] Color of the buttons, if no image was provided, or color to apply\n         a filter to the images.\n [over_color] Color of the buttons when the mouse is over them (when no\n              image was provided). [SEP] def draw(alpha = 0xff, z_index = 0, color = 0xffffff, over_color = 0xcccccc)\n      return unless @visible\n      unless @img\n        bottom = @y + (@open ? @max_h : @h) + @scale_y\n        b_color = (alpha << 24)\n        G.window.draw_quad @x - @scale_x, @y - @scale_y, b_color,\n                           @x + @w + @scale_x, @y - @scale_y, b_color,\n                           @x + @w + @scale_x, bottom, b_color,\n                           @x - @scale_x, bottom, b_color, z_index\n        @buttons.each do |b|\n          c = (alpha << 24) | (b.state == :over ? over_color : color)\n          G.window.draw_quad b.x, b.y, c,\n                             b.x + b.w, b.y, c,\n                             b.x + b.w, b.y + b.h, c,\n                             b.x, b.y + b.h, c, z_index + 1 if b.visible\n        end\n      end\n      @buttons[0].draw(alpha, z_index, color)\n      @buttons[1..-1].each { |b| b.draw alpha, z_index + 1, color }\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Gets a listing of links from reddit.\n\n @param (see LinksComments#info)\n @option opts [String] :subreddit The subreddit targeted. Can be psuedo-subreddits like `all` or `mod`. If blank, the front page\n @option opts [new, controversial, top, saved] :page The page to view.\n @option opts [new, rising] :sort The sorting method. Only relevant on the `new` page\n @option opts [hour, day, week, month, year] :t The timeframe. Only relevant on some pages, such as `top`. Leave empty for all time\n @option opts [1..100] :limit The number of things to return.\n @option opts [String] :after Get things *after* this thing id\n @option opts [String] :before Get things *before* this thing id\n @return (see #clear_sessions) [SEP] def get_listing opts = {}\n      # Build the basic url\n      url = \"%s/%s.json\" % [('/r/' + opts[:subreddit] if opts[:subreddit] ), (opts[:page] if opts[:page])]\n      # Delete subreddit and page from the hash, they dont belong in the query\n      [:subreddit, :page].each {|k| opts.delete k}\n      query = opts\n      # Make the request\n      get(url, query: query)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Given a nid, returns a copy of all the var the node sees at that point. [SEP] def vars(nid, vs={})\n\n      n = node(nid); return vs unless n\n\n      (n['vars'] || {})\n        .each { |k, v| vs[k] = Flor.dup(v) unless vs.has_key?(k) }\n\n      pnid = n['parent']\n\n      if @unit.loader && pnid == nil && n['vdomain'] != false\n\n        @unit.loader.variables(n['vdomain'] || Flor.domain(@exid))\n          .each { |k, v| vs[k] = Flor.dup(v) unless vs.has_key?(k) }\n      end\n\n      if cn = n['cnid']; vars(cn, vs); end\n      vars(pnid, vs) if pnid\n\n      vs\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Recursive implementation of `each_resource_file` for each\n folder in the configuration. [SEP] def _each_resource_file(config)\n      folder = config.folder\n      folder.glob(\"**/*.yml\").select(&to_filter_proc(config.file_filter)).each do |file|\n        yield file, folder\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Returns a hash { key => record } of all the records matching the\n given keys. [SEP] def lget (*keys)\n\n      keys = Rufus::Tokyo::h_or_a_to_s(keys.flatten)\n\n      if @db.respond_to?(:mget)\n        @db.mget(keys)\n      else\n        keys.inject({}) { |h, k| v = self[k]; h[k] = v if v; h }\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Update the collection configuration in zookeeper\n @param [Hash] options\n @option options [String] :config_name\n @option options [String] :dir [SEP] def upconfig(options = {})\n      options[:name] ||= SecureRandom.hex\n      options[:zkhost] ||= zkhost\n\n      upconfig_options = { upconfig: true, n: options[:name] }\n      upconfig_options[:d] = options[:dir] if options[:dir]\n      upconfig_options[:z] = options[:zkhost] if options[:zkhost]\n\n      exec 'zk', upconfig_options\n\n      options[:name]\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Rotate servers given [SEP] def rotate(hsh)\n      current_ec2, new_ec2 = hsh.first\n\n      cur_instances = EC2.by_tags(\"Name\" => current_ec2.to_s)\n      new_instances = EC2.by_tags(\"Name\" => new_ec2.to_s)\n\n      register_and_wait new_instances\n      deregister        cur_instances\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "TODO should exist another method passed! for tag_name_required ? [SEP] def run!(hash=nil)\n      @state = :not_checked\n      #@field.each do |field|\n        #if @state == :passed\n        #  break\n        #end\n        case @setting\n          when :tag_name_required, :tag_name_suggested\n            content = nil\n            if hash\n              #puts \"#{@depth.inspect} - required: #{required.inspect}\"\n\n              found = false\n              self.tag_names.each do |key|\n                if hash.keys.include?(key)\n                  found = true\n                  break\n                end\n              end\n              if found\n                @state = :passed\n              else\n                if @setting == :tag_name_required\n                  #puts \"hash: #{hash.inspect}\"\n                  #puts \"self.tag_names: #{self.tag_names.inspect}\"\n                  @state = :not_passed\n                end\n              end\n            else\n              @state = :passed\n            end\n          when :content_values\n            if hash\n              found = false\n              self.tag_names.each do |key|\n                content = hash[key]\n                #puts content\n                #puts @possible_values.inspect\n                if @possible_values.include?(content)\n                  found = true\n                  break\n                end\n              end\n              if found\n                @state = :passed\n              else\n                @state = :not_passed\n              end\n            end\n          #when :not_blank\n          #  if hash.has_key?(field) and !hash[field].to_s.empty?\n          #    @state = :passed\n          #  else\n          #    @state = :not_passed\n          #  end\n        end\n      #end\n      @state\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@param [ Regexp ] pattern\n @param [ Typhoeus::Response, String ] page\n\n @return [ Array<Array<MatchData, Nokogiri::XML::Element>> ]\n @yield  [ MatchData, Nokogiri::XML::Element ] [SEP] def javascripts_from_page(pattern, page = nil)\n      xpath_pattern_from_page('//script', pattern, page) do |match, node|\n        yield match, node if block_given?\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Fire a single event based on the matched notification.\n\n An action without any parameters is assumed to be executed within the contexxt\n of the target. If there are two parameters we will simply execute the action and\n pass it both the target and the sender. [SEP] def _fire_event_for_notification(event,sender,action)\n      if action.arity == 2\n        target.instance_exec(sender,event,&action)\n      elsif action.arity == 1\n        target.instance_exec(sender,&action)\n      else\n        target.instance_eval(&action)\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Get the shell command to complie the project WIX files\n\n @return [String] [SEP] def candle_command(is_bundle: false)\n      if is_bundle\n        <<-EOH.split.join(\" \").squeeze(\" \").strip\n        candle.exe\n          -nologo\n          #{wix_candle_flags}\n          -ext WixBalExtension\n          #{wix_extension_switches(wix_candle_extensions)}\n          -dOmnibusCacheDir=\"#{windows_safe_path(File.expand_path(Config.cache_dir))}\"\n          \"#{windows_safe_path(staging_dir, 'bundle.wxs')}\"\n        EOH\n      else\n        <<-EOH.split.join(\" \").squeeze(\" \").strip\n          candle.exe\n            -nologo\n            #{wix_candle_flags}\n            #{wix_extension_switches(wix_candle_extensions)}\n            -dProjectSourceDir=\"#{windows_safe_path(project.install_dir)}\" \"project-files.wxs\"\n            \"#{windows_safe_path(staging_dir, 'source.wxs')}\"\n        EOH\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Creates a tensor with all elements set to 1. [SEP] def ones(shape, dtype: :float32, name: nil)\n      _op(:ones, shape, data_type: dtype, name: name)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "A callback that runs before create vote\n Example:\n   BallotBox::Manager.before_vote do |env, opts|\n   end [SEP] def before_vote(options = {}, method = :push, &block)\n      raise BlockNotGiven unless block_given?\n      _before_vote.send(method, [block, options])\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Post to the sign in resource on the API, so that all future\n requests are signed [SEP] def authenticate\n      # :x_amee_source = \"X-AMEE-Source\".to_sym\n      request = Typhoeus::Request.new(\"#{protocol}#{@server}/auth/signIn\", \n        :method => \"post\",\n        :verbose => DEBUG,\n        :headers => {\n          :Accept => content_type(:xml),\n        },\n        :body => form_encode(:username=>@username, :password=>@password)\n      )\n\n      hydra.queue(request)\n      hydra.run\n      response = request.response\n\n      @auth_token = response.headers_hash['AuthToken']\n      d {request.url}\n      d {response.code}\n      d {@auth_token}\n\n      connection_failed if response.code == 0\n\n      unless authenticated?\n        raise AMEE::AuthFailed.new(\"Authentication failed. Please check your username and password. (tried #{@username},#{@password})\")\n      end\n      # Detect API version\n      if response.body.is_json?\n        @version = JSON.parse(response.body)[\"user\"][\"apiVersion\"].to_f\n      elsif response.body.is_xml?\n        @version = REXML::Document.new(response.body).elements['Resources'].elements['SignInResource'].elements['User'].elements['ApiVersion'].text.to_f\n      else\n        @version = 1.0\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Get the shell command to create a zip file that contains\n the contents of the project install directory\n\n @return [String] [SEP] def zip_command\n      <<-EOH.split.join(\" \").squeeze(\" \").strip\n      7z a -r\n      #{windows_safe_path(staging_dir)}\\\\#{project.name}.zip\n      #{windows_safe_path(project.install_dir)}\\\\*\n      EOH\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "folders [SEP] def newfolder\n      @item = model.new(:is_folder=>true)\n      item_init_parent\n      @item.basedirpath = @item.parent.basepath+'/' unless @item.parent_id.nil?\n\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "for simmetry padding\n m = length / 3\n 6: 2 2 2        m   m   m    REST 0\n 5: 2 1 2       m+1  m  m+1        2\n 4: 1 2 1        m  m+1  m         1 [SEP] def flag3(str,left_color='brown',middle_color='pink',right_color='red')\n    m = str.length / 3\n    remainder = str.length % 3\n    central_length = remainder == 1 ? m+1 : m \n    lateral_length = remainder == 2 ? m+1 : m \n    colora(  left_color,    str[ 0 .. lateral_length-1] ) + \n      colora( middle_color, str[ lateral_length .. lateral_length+central_length-1] ) + \n      colora( right_color, str[ lateral_length+central_length .. str.length ] )  \n  end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "geckoboard-ruby gem's dataset.find_or_create id attribute\n e.g. peoplefinder-staging.total_profiles_report [SEP] def id\n      Rails.application.class.parent_name.underscore +\n        '-' +\n        (ENV['ENV'] || Rails.env).downcase +\n        '.' +\n        self.class.name.demodulize.underscore\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Open a new channel of communication and return a new {Channel} object\n with convenience methods for communicating on that channel. The\n channel will be automatically released if the {Channel} instance is\n garbage collected, or if the {Client} connection is {#close}d.\n\n @param id [Integer,nil] The channel id number to use. If nil or not\n   given, a unique channel number will be chosen automatically.\n @raise [ArgumentError] If the given channel id number is not unique or\n   if the given channel id number is greater than {#max_channels}.\n @return [Channel] The new channel handle. [SEP] def channel(id=nil)\n      id = allocate_channel(id)\n      finalizer = Proc.new { release_channel(id) }\n      Channel.new(self, @conn, id, finalizer)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Marks entries as either seen or not seen based on the unique signature of\n the entry, which is calculated by taking the MD5 of common attributes. [SEP] def mark_new_entries(response)\n      digests = summary_digests\n\n      # For each entry in the responses object, mark @_seen as false if the \n      # digest of this entry doesn't exist in the cached object.\n      response.entries.each do |e|\n        seen = digests.include?(digest_for(e))\n        e.instance_variable_set(:@_seen, seen)\n      end\n      \n      response\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "choose right type of value and then transform it for redis [SEP] def value_to_redis name, value\n      if redis_fields_config.has_key?(name)\n        value_transform value, redis_fields_config[name]\n      else\n        value\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Sets an index on a column of the table.\n\n Types maybe be :lexical or :decimal.\n\n Recently (TC 1.4.26 and 1.4.27) inverted indexes have been added,\n they are :token and :qgram. There is an :opt index as well.\n\n Sorry couldn't find any good doc about those inverted indexes apart from :\n\n   http://alpha.mixi.co.jp/blog/?p=1147\n   http://www.excite-webtl.jp/world/english/web/?wb_url=http%3A%2F%2Falpha.mixi.co.jp%2Fblog%2F%3Fp%3D1147&wb_lp=JAEN&wb_dis=2&wb_submit=+%96%7C+%96%F3+\n\n Use :keep to \"add\" and\n :remove (or :void) to \"remove\" an index.\n\n If column_name is :pk or \"\", the index will be set on the primary key.\n\n Returns true in case of success. [SEP] def set_index (column_name, *types)\n\n      column_name = column_name == :pk ? '' : column_name.to_s\n\n      i = types.inject(0) { |ii, t| ii | INDEX_TYPES[t] }\n\n      @db.setindex(column_name, i) || raise_error\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Returns an array of nsqd addresses\n If there's an error, return nil [SEP] def get_nsqds(lookupd, topic = nil)\n      uri_scheme = 'http://' unless lookupd.match(%r(https?://))\n      uri = URI.parse(\"#{uri_scheme}#{lookupd}\")\n\n      uri.query = \"ts=#{Time.now.to_i}\"\n      if topic\n        uri.path = '/lookup'\n        uri.query += \"&topic=#{URI.escape(topic)}\"\n      else\n        uri.path = '/nodes'\n      end\n\n      begin\n        body = Net::HTTP.get(uri)\n        data = JSON.parse(body)\n        producers = data['producers'] || # v1.0.0-compat\n                      (data['data'] && data['data']['producers'])\n\n        if producers\n          producers.map do |producer|\n            \"#{producer['broadcast_address']}:#{producer['tcp_port']}\"\n          end\n        else\n          []\n        end\n      rescue Exception => e\n        error \"Error during discovery for #{lookupd}: #{e}\"\n        nil\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Create a caramelize config file. [SEP] def execute(args)\n      # create dummy config file\n      target_file = @config_file.nil? ? \"caramel.rb\" : @config_file\n      FileUtils.cp(File.dirname(__FILE__) +\"/../caramel.rb\", target_file)\n      if commandparser.verbosity == :normal\n        puts \"Created new configuration file: #{target_file}\"\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Prints a list of tensors.\n\n This is an identity op (behaves like tf.identity) with the side effect of printing data when evaluating. [SEP] def print(input, data, message: nil, name: nil)\n      _op(:print, input, data, message: message, name: name)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "translations [SEP] def build_translations\n      #\n      if is_translated\n        langs = Language.list_with_default\n      else\n        langs = ['']\n      end\n\n      #\n      langs_missing = langs - self.translations.all.map{|r| r.lang}\n\n      langs_missing.each do |lang|\n        self.translations.new(:lang=>lang)\n      end\n\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Returns a new date/time representing the given day in the previous week.\n Week is assumed to start on +start_day+, default is\n +Date.beginning_of_week+ or +config.beginning_of_week+ when set.\n DateTime objects have their time set to 0:00. [SEP] def prev_week(start_day = Date.beginning_of_week)\n      first_hour{ weeks_ago(1).beginning_of_week.days_since(days_span(start_day)) }\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Define a new set of Field alternatives for this message definition. [SEP] def alt_field(number, ref_field, &block)\n      unless @fields_by_name.include?(ref_field)\n        raise \"Unknown ref_field: #{ref_field}\"\n      end\n\n      field = AltField.new(self, ref_field, &block)\n      register_field_by_number(field, number)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Pronunciation\n\n\n @!method get_pronunciation(text:, voice: nil, format: nil, customization_id: nil)\n Get pronunciation.\n Gets the phonetic pronunciation for the specified word. You can request the\n   pronunciation for a specific format. You can also request the pronunciation for a\n   specific voice to see the default translation for the language of that voice or\n   for a specific custom voice model to see the translation for that voice model.\n\n   **Note:** This method is currently a beta release.\n\n   **See also:** [Querying a word from a\n   language](https://cloud.ibm.com/docs/services/text-to-speech/custom-entries.html#cuWordsQueryLanguage).\n @param text [String] The word for which the pronunciation is requested.\n @param voice [String] A voice that specifies the language in which the pronunciation is to be returned.\n   All voices for the same language (for example, `en-US`) return the same\n   translation.\n @param format [String] The phoneme format in which to return the pronunciation. Omit the parameter to\n   obtain the pronunciation in the default format.\n @param customization_id [String] The customization ID (GUID) of a custom voice model for which the pronunciation is\n   to be returned. The language of a specified custom model must match the language\n   of the specified voice. If the word is not defined in the specified custom model,\n   the service returns the default translation for the custom model's language. You\n   must make the request with service credentials created for the instance of the\n   service that owns the custom model. Omit the parameter to see the translation for\n   the specified voice with no customization.\n @return [IBMCloudSdkCore::DetailedResponse] A `IBMCloudSdkCore::DetailedResponse` object representing the response. [SEP] def get_pronunciation(text:, voice: nil, format: nil, customization_id: nil)\n      raise ArgumentError.new(\"text must be provided\") if text.nil?\n\n      headers = {\n      }\n      sdk_headers = Common.new.get_sdk_headers(\"text_to_speech\", \"V1\", \"get_pronunciation\")\n      headers.merge!(sdk_headers)\n\n      params = {\n        \"text\" => text,\n        \"voice\" => voice,\n        \"format\" => format,\n        \"customization_id\" => customization_id\n      }\n\n      method_url = \"/v1/pronunciation\"\n\n      response = request(\n        method: \"GET\",\n        url: method_url,\n        headers: headers,\n        params: params,\n        accept_json: true\n      )\n      response\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@param [ OptBase ] opt\n\n @return [ Array<String> ] [SEP] def opt_help_messages(opt)\n      opt.help_messages.empty? ? [opt.to_s.humanize] : opt.help_messages\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Image resize\n @return [image_tag] [SEP] def ires_tag(path, width: nil, height: nil, type: Type::ALL, mode: Mode::RESIZE, expire: 30.days, **option)\n      image_path = Ires::Service.path(\n        path,\n        width: width || 0,\n        height: height || 0,\n        mode: mode,\n        type: type,\n        expire: expire\n      )\n\n      # Set image_tag\n      image_tag(image_path, option)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "The path on disk to the downloaded asset. The filename is defined by\n +source :cached_name+. If ommited, then it comes from the software's\n +source :url+ value\n\n @return [String] [SEP] def downloaded_file\n      filename = source[:cached_name] if source[:cached_name]\n      filename ||= File.basename(source[:url], \"?*\")\n      File.join(Config.cache_dir, filename)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Retrieve the filters that represent invalid full-text search values.\n\n The parsed, invalid full-text search filters will contain an +:error+ key\n that provides an error message intended for the user.\n\n @param [Array<Hash>] filters an array of filter {Hash hashes}\n @return [Array<Hash>] an array of invalid full-text search filter\n         {Hash hashes} that contain a human-readable error at the\n         +:error+ key [SEP] def invalid_fts_filters(filters)\n      filters.select { |filter|\n        category, name, value = filter.values_at('category', 'name', 'value')\n        category == 'fts' && name == 'search' && value.to_s.length <= 1\n      }.map { |invalid_fts_filter|\n        error = <<-MSG.gsub(/^\\s+/, '').strip\n          Full-text search filter values must be larger than one.\n        MSG\n        invalid_fts_filter.merge(:error => error)\n      }\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "List current tasks [SEP] def list entities = @db.list\n      out\n\n      entities = entities.is_a?(Fixnum) ? @db.list[0...entities] : entities\n\n      entities.reject {|e| e[:status] == :removed }.each_with_index do |e, i|\n        out \" [#{i}]\".blue                     +\n            \"#{e.sticky?? \" + \".bold : \"   \"}\" +\n            e[:title].underline                +\n            \" #{e[:tags].join(' ')}\".cyan\n      end.tap do |list|\n        out \" ...\" if @db.list.length > entities.length && !entities.length.zero?\n        out \"  there are no koi in the water\".green if list.size.zero?\n      end\n\n      out\n      entities\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Get the time for this rate (based on the information on the website) [SEP] def rate_time\n      regexp = Regexp.new(/\\d\\d\\d\\d-\\d\\d-\\d\\d/)\n      page.search('//p[@class=\"nag\"]').each do |p|\n        p.search('b').each do |b|\n          if regexp.match(b.content)\n            return DateTime.strptime(b.content, \"%Y-%m-%d\")\n          end\n        end\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "used in wechat pay api [SEP] def sign_package params\n      params_str = create_sign_str params\n\n      if params_str =~ /trade_type=APP/\n        key = Wxpay.app_api_key\n      else\n        key = Wxpay.api_key\n      end\n      Digest::MD5.hexdigest(params_str+\"&key=#{key}\").upcase\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": ":nodoc:\n Parse all results in the batch.  Add records to shared list.\n If the record was not found, the bins will be nil. [SEP] def parse_row(result_code)\n      batch_index = @data_buffer.read_int32(14)\n      field_count = @data_buffer.read_int16(18)\n      op_count = @data_buffer.read_int16(20)\n\n      if op_count > 0\n        raise Aerospike::Exceptions::Parse.new('Received bins that were not requested!')\n      end\n\n      parse_key(field_count)\n      results[batch_index] = (result_code == 0)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Computes cos of input element-wise.\n\n\n @param input_a tensor X (of type FLOATING_POINT_TYPES)\n\n Options:\n @option name Optional name\n @return Tensor [SEP] def cos(input_a, name: nil)\n      check_allowed_types(input_a, TensorStream::Ops::FLOATING_POINT_TYPES)\n      _op(:cos, input_a, name: name)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Sets the cursor position to the specified +x+ and +y+ locations in the\n console output buffer. If +y+ is nil, the cursor is positioned at +x+ on\n the current line. [SEP] def set_cursor_position(x, y)\n            if stdout && x && y\n                coord = Coord.new(x, y)\n                self.set_console_cursor_position(stdout, coord)\n            end\n        end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Creates a tensor with all elements set to 1.\n Given a single tensor (tensor), this operation returns a\n tensor of the same type and shape as tensor with all elements set to 1.\n Optionally, you can specify a new type (dtype) for the returned tensor.\n\n\n @param input A tensor\n\n Options:\n @option dtype Optional new data type to cast into\n @option name Optional name\n @return Tensor [SEP] def ones_like(input, dtype: nil, name: nil)\n      _op(:ones_like, input, data_type: dtype, name: name)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Retry the given block if a retriable exception is\n raised. Returns the value of the block call if successful.\n\n @param [String] logstr\n   Description of the action being retried. Used in log output.\n\n @param [Array<Exception>] retried_exceptions\n   List of exceptions to retry.  Any other exceptions are raisesd.\n\n @param [Integer] retries\n   Number of times to retry the given block. [SEP] def retry_block(logstr, retried_exceptions = [], retries = Omnibus::Config.fetcher_retries, &block)\n      yield\n    rescue Exception => e\n      raise e unless retried_exceptions.any? { |eclass| e.is_a?(eclass) }\n      if retries != 0\n        log.info(log_key) { \"Retrying failed #{logstr} due to #{e} (#{retries} retries left)...\" }\n        retries -= 1\n        retry\n      else\n        log.error(log_key) { \"#{logstr} failed - #{e.class}!\" }\n        raise\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "when calling validates it should create the Vali instance already and set @klass there! # TODO: fix this in AM. [SEP] def validate(form)\n      property = attributes.first\n\n      # here is the thing: why does AM::UniquenessValidator require a filled-out record to work properly? also, why do we need to set\n      # the class? it would be way easier to pass #validate a hash of attributes and get back an errors hash.\n      # the class for the finder could either be infered from the record or set in the validator instance itself in the call to ::validates.\n      record = form.model_for_property(property)\n      record.send(\"#{property}=\", form.send(property))\n\n      @klass = record.class # this is usually done in the super-sucky #setup method.\n      super(record).tap do |res|\n        form.errors.add(property, record.errors.first.last) if record.errors.present?\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "See UiBibz::Ui::Core::Component.initialize\n Add Header which is a component [SEP] def header content = nil, options = nil, html_options = nil, &block\n      options, content = inherit_options(content, options, block)\n      if is_tap(content, options)\n        @header = UiBibz::Ui::Core::Boxes::Components::CardHeader.new(content, options, html_options).tap(&block).render\n      else\n        @header = UiBibz::Ui::Core::Boxes::Components::CardHeader.new(content, options, html_options, &block).render\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Callback that gets called by Software#build_me after the build is done.\n Invokes license copying for the given software. This ensures that\n licenses are copied before a git cache snapshot is taken, so that the\n license files are correctly restored when a build is skipped due to a\n cache hit.\n\n @param [Software] software\n\n @return [void] [SEP] def execute_post_build(software)\n      collect_licenses_for(software)\n      unless software.skip_transitive_dependency_licensing\n        collect_transitive_dependency_licenses_for(software)\n        check_transitive_dependency_licensing_errors_for(software)\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Create a new Transaction\n\n @see Transaction#link\n\n In fact, it just calls #link with the given arguments at the end of the\n constructor.\n\n @api public\n Associate this Transaction with some things.\n\n @param [Object] things\n   the things you want this Transaction associated with:\n\n   Adapters::AbstractAdapter subclasses will be added as\n     adapters as is.\n   Arrays will have their elements added.\n   Repository will have it's own @adapters added.\n   Resource subclasses will have all the repositories of all\n     their properties added.\n   Resource instances will have all repositories of all their\n     properties added.\n\n @param [Proc] block\n   a block (taking one argument, the Transaction) to execute within\n   this transaction. The transaction will begin and commit around\n   the block, and rollback if an exception is raised.\n\n @api private [SEP] def link(*things)\n      unless none?\n        raise \"Illegal state for link: #{state}\"\n      end\n\n      things.each do |thing|\n        case thing\n          when DataMapper::Adapters::AbstractAdapter\n            @adapters[thing] = :none\n          when DataMapper::Repository\n            link(thing.adapter)\n          when DataMapper::Model\n            link(*thing.repositories)\n          when DataMapper::Resource\n            link(thing.model)\n          when Array\n            link(*thing)\n          else\n            raise \"Unknown argument to #{self.class}#link: #{thing.inspect} (#{thing.class})\"\n        end\n      end\n\n      if block_given?\n        commit { |*block_args| yield(*block_args) }\n      else\n        self\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Returns [String] the exception backtrace including all of the child / caused by exceptions [SEP] def backtrace_to_s\n      trace = ''\n      each_exception do |exception, i|\n        if i.zero?\n          trace = (exception.backtrace || []).join(\"\\n\")\n        else\n          trace << \"\\nCause: #{exception.class.name}: #{exception.message}\\n#{(exception.backtrace || []).join(\"\\n\")}\"\n        end\n      end\n      trace\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Note: relative_path is temporarily expected to be a relative Pathname to\n make refactoring easier (ideally, it would take a string)\n TODO: switch type and path places - and verify [SEP] def silenced?(relative_path, type)\n      path = relative_path.to_s\n\n      if only_patterns && type == :file\n        return true unless only_patterns.any? { |pattern| path =~ pattern }\n      end\n\n      ignore_patterns.any? { |pattern| path =~ pattern }\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Increments the value stored under the given key with the given increment\n (defaults to 1 (integer)).\n\n Warning : Tokyo Cabinet/Tyrant doesn't store counter values as regular\n strings (db['key'] won't yield something that replies properly to #to_i)\n\n Use #counter_value(k) to get the current value set for the counter. [SEP] def incr (key, val=1)\n\n      key = key.to_s\n\n      v = val.is_a?(Fixnum) ? @db.addint(key, val) : @db.adddouble(key, val)\n\n      raise(EdoError.new(\n        \"incr failed, there is probably already a string value set \" +\n        \"for the key '#{key}'. Make sure there is no value before incrementing\"\n      )) unless v\n\n      v\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@!method initialize(args)\n Construct a new client for the Speech to Text service.\n\n @param args [Hash] The args to initialize with\n @option args url [String] The base url to use when contacting the service (e.g.\n   \"https://stream.watsonplatform.net/speech-to-text/api\").\n   The base url may differ between Bluemix regions.\n @option args username [String] The username used to authenticate with the service.\n   Username and password credentials are only required to run your\n   application locally or outside of Bluemix. When running on\n   Bluemix, the credentials will be automatically loaded from the\n   `VCAP_SERVICES` environment variable.\n @option args password [String] The password used to authenticate with the service.\n   Username and password credentials are only required to run your\n   application locally or outside of Bluemix. When running on\n   Bluemix, the credentials will be automatically loaded from the\n   `VCAP_SERVICES` environment variable.\n @option args iam_apikey [String] An API key that can be used to request IAM tokens. If\n   this API key is provided, the SDK will manage the token and handle the\n   refreshing.\n @option args iam_access_token [String] An IAM access token is fully managed by the application.\n   Responsibility falls on the application to refresh the token, either before\n   it expires or reactively upon receiving a 401 from the service as any requests\n   made with an expired token will fail.\n @option args iam_url [String] An optional URL for the IAM service API. Defaults to\n   'https://iam.ng.bluemix.net/identity/token'.\n\n Models\n\n\n @!method get_model(model_id:)\n Get a model.\n Gets information for a single specified language model that is available for use\n   with the service. The information includes the name of the model and its minimum\n   sampling rate in Hertz, among other things.\n\n   **See also:** [Languages and\n   models](https://cloud.ibm.com/docs/services/speech-to-text/models.html).\n @param model_id [String] The identifier of the model in the form of its name from the output of the **Get a\n   model** method.\n @return [IBMCloudSdkCore::DetailedResponse] A `IBMCloudSdkCore::DetailedResponse` object representing the response. [SEP] def get_model(model_id:)\n      raise ArgumentError.new(\"model_id must be provided\") if model_id.nil?\n\n      headers = {\n      }\n      sdk_headers = Common.new.get_sdk_headers(\"speech_to_text\", \"V1\", \"get_model\")\n      headers.merge!(sdk_headers)\n\n      method_url = \"/v1/models/%s\" % [ERB::Util.url_encode(model_id)]\n\n      response = request(\n        method: \"GET\",\n        url: method_url,\n        headers: headers,\n        accept_json: true\n      )\n      response\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Disables an instance method.\n\n @param [Symbol,String]  method_name   The name of the method to disable.\n @param [String]         message       An error message. Defaults to \"Class#method is disabled\". [SEP] def disable_method(method_name, message = nil)\n      disabled_methods[method_name] ||= DisabledMethod.new(self, method_name, message)\n      disabled_methods[method_name].disable!\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Adds a folder to the list of folders where test case definitions are\n to be found. [SEP] def folder(folder = nil, &bl)\n      if folder.nil?\n        @folder\n      else\n        folder = folder.is_a?(String) ? @folder/folder : Path(folder)\n        raise \"Folder `#{folder}` does not exists\" unless folder.exists? && folder.directory?\n        raise \"Folder must be a descendant\" unless folder.inside?(@folder)\n        child = dup do |c|\n          c.parent = self\n          c.folder = folder\n        end\n        yield(child) if block_given?\n        @children << child\n        child\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Process the specified control file [SEP] def process_control(control)\n      control = ETL::Control::Control.resolve(control)\n      say_on_own_line \"Processing control #{control.file}\"\n      \n      ETL::Engine.job = ETL::Execution::Job.new.tap do |job|\n        job.control_file = control.file\n        job.status = 'executing'\n        job.batch_id = ETL::Engine.batch ? ETL::Engine.batch.id : nil\n        job.save!\n      end\n\n      execute_dependencies(control)\n      \n      start_time = Time.now\n      pre_process(control)\n      sources = control.sources\n      destinations = control.destinations\n      \n      say \"Skipping bulk import\" if Engine.skip_bulk_import\n      \n      sources.each do |source|\n        Engine.current_source = source\n        Engine.logger.debug \"Processing source #{source.inspect}\"\n        say \"Source: #{source}\"\n        say \"Limiting enabled: #{Engine.limit}\" if Engine.limit != nil\n        say \"Offset enabled: #{Engine.offset}\" if Engine.offset != nil\n        source.each_with_index do |row, index|\n          # Break out of the row loop if the +Engine.limit+ is specified and \n          # the number of rows read exceeds that value.\n          if Engine.limit != nil && Engine.rows_read >= Engine.limit\n            puts \"Reached limit of #{Engine.limit}\"\n            break\n          end\n          \n          Engine.logger.debug \"Row #{index}: #{row.inspect}\"\n          Engine.rows_read += 1\n          Engine.current_source_row = index + 1\n          say_without_newline \".\" if Engine.realtime_activity && index > 0 && index % 1000 == 0\n          \n          # At this point a single row may be turned into multiple rows via row \n          # processors all code after this line should work with the array of \n          # rows rather than the single row\n          rows = [row]\n          \n          t = Benchmark.realtime do\n            begin\n              Engine.logger.debug \"Processing after read\"\n              control.after_read_processors.each do |processor|\n                processed_rows = []\n                rows.each do |row|\n                  processed_rows << processor.process(row) unless empty_row?(row)\n                end\n                rows = processed_rows.flatten.compact\n              end\n            rescue => e\n              msg = \"Error processing rows after read from #{Engine.current_source} on line #{Engine.current_source_row}: #{e}\"\n              # TODO - track more information: row if possible, full exception...\n              track_error(control, msg)\n              Engine.logger.error(msg)\n              e.backtrace.each { |line| Engine.logger.error(line) }\n              exceeded_error_threshold?(control) ? break : next\n            end\n          end\n          benchmarks[:after_reads] += t unless t.nil?\n          \n          t = Benchmark.realtime do\n            begin\n              Engine.logger.debug \"Executing transforms\"\n              rows.each do |row|\n                # only do the transform if there is a row\n                unless empty_row?(row)\n                  control.transforms.each do |transform|\n                    name = transform.name.to_sym\n                    row[name] = transform.transform(name, row[name], row)\n                  end\n                end\n              end\n            rescue ResolverError => e\n              Engine.logger.error(e.message)\n              track_error(control, e.message)\n            rescue => e\n              msg = \"Error transforming from #{Engine.current_source} on line #{Engine.current_source_row}: #{e}\"\n              track_error(control, msg)\n              Engine.logger.error(msg)\n              e.backtrace.each { |line| Engine.logger.error(line) }\n            ensure\n              begin\n                exceeded_error_threshold?(control) ? break : next\n              rescue => inner_error\n                puts inner_error\n              end\n            end\n          end\n          benchmarks[:transforms] += t unless t.nil?\n          \n          t = Benchmark.realtime do\n            begin\n              # execute row-level \"before write\" processing\n              Engine.logger.debug \"Processing before write\"\n              control.before_write_processors.each do |processor|\n                processed_rows = []\n                rows.each do |row|\n                  processed_rows << processor.process(row) unless empty_row?(row)\n                end\n                rows = processed_rows.flatten.compact\n              end\n            rescue => e\n              msg = \"Error processing rows before write from #{Engine.current_source} on line #{Engine.current_source_row}: #{e}\"\n              track_error(control, msg)\n              Engine.logger.error(msg)\n              e.backtrace.each { |line| Engine.logger.error(line) }\n              exceeded_error_threshold?(control) ? break : next\n            end\n          end\n          benchmarks[:before_writes] += t unless t.nil?\n          \n          t = Benchmark.realtime do\n            begin\n              # write the row to the destination\n              destinations.each_with_index do |destination, index|\n                Engine.current_destination = destination\n                rows.each do |row|\n                  destination.write(row)\n                  Engine.rows_written += 1 if index == 0\n                end\n              end\n            rescue => e\n              msg = \"Error writing to #{Engine.current_destination}: #{e}\"\n              track_error(control, msg)\n              Engine.logger.error msg\n              e.backtrace.each { |line| Engine.logger.error(line) }\n              exceeded_error_threshold?(control) ? break : next\n            end\n          end\n          benchmarks[:writes] += t unless t.nil?\n        end\n        \n        if exceeded_error_threshold?(control)\n          say_on_own_line \"Exiting due to exceeding error threshold: #{control.error_threshold}\"\n          ETL::Engine.exit_code = 1\n        end\n        \n      end\n      \n      destinations.each do |destination|\n        destination.close\n      end\n      \n      say_on_own_line \"Executing before post-process screens\"\n      begin\n        execute_screens(control)\n      rescue FatalScreenError => e\n        say \"Fatal screen error during job execution: #{e.message}\"\n        ETL::Engine.exit_code = 2\n      rescue ScreenError => e\n        say \"Screen error during job execution: #{e.message}\"\n        return\n      else\n        say \"Screens passed\"\n      end\n      \n      post_process(control)\n      \n      if sources.length > 0\n        say_on_own_line \"Read #{Engine.rows_read} lines from sources\"\n      end\n      if destinations.length > 0\n        say \"Wrote #{Engine.rows_written} lines to destinations\"\n      end\n\n      say_on_own_line \"Executing after post-process screens\"\n      begin\n        execute_screens(control, :after_post_process)\n      rescue FatalScreenError => e\n        say \"Fatal screen error during job execution: #{e.message}\"\n        ETL::Engine.exit_code = 3\n      rescue ScreenError => e\n        say \"Screen error during job execution: #{e.message}\"\n        return\n      else\n        say \"Screens passed\"\n      end\n\n      say_on_own_line \"Completed #{control.file} in #{distance_of_time_in_words(start_time)} with #{errors.length} errors.\"\n      say \"Processing average: #{Engine.average_rows_per_second} rows/sec)\"\n      \n      say \"Avg after_reads: #{Engine.rows_read/benchmarks[:after_reads]} rows/sec\" if benchmarks[:after_reads] > 0\n      say \"Avg before_writes: #{Engine.rows_read/benchmarks[:before_writes]} rows/sec\" if benchmarks[:before_writes] > 0\n      say \"Avg transforms: #{Engine.rows_read/benchmarks[:transforms]} rows/sec\" if benchmarks[:transforms] > 0\n      say \"Avg writes: #{Engine.rows_read/benchmarks[:writes]} rows/sec\" if benchmarks[:writes] > 0\n\n      # say \"Avg time writing execution records: #{ETL::Execution::Record.average_time_spent}\"\n      # \n      # ETL::Transform::Transform.benchmarks.each do |klass, t|\n#         say \"Avg #{klass}: #{Engine.rows_read/t} rows/sec\"\n#       end\n\n      ActiveRecord::Base.verify_active_connections!\n      ETL::Engine.job.completed_at = Time.now\n      ETL::Engine.job.status = (errors.length > 0 ? 'completed with errors' : 'completed')\n      ETL::Engine.job.save!\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "If valid option was provided in convert method [SEP] def deal_with_valid_option(temp_tables, temp_columns, temp_column_types, res)\n\t\t\tif !temp_tables.empty?\n\t\t\t\tcheck_given_tables_validity(temp_tables)\n\t\t\t\ttemp_tables.each do |t|\n\t\t\t\t\tres << convert_table(t)\n\t\t\t\tend\n\t\t\telsif !temp_columns.keys.empty?\n\t\t\t\tcheck_given_columns_validity(temp_columns)\n\t\t\t\tres << convert_from_columns_hash(temp_columns)\n\t\t\telsif !temp_column_types.empty?\n\t\t\t\tcheck_given_columns_validity(temp_column_types)\n\t\t\t\tres << convert_from_column_types_hash(temp_column_types)\n\t\t\tend\n\t\tend", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Replacing RSpec's default method_missing implementation so that we can\n include our own special default hooks that allows spec tests to look\n more readable.\n\n Ideally it would have been better if RSpec provided some nice hooks to\n try other default pattern matchers [SEP] def method_missing(sym, *args, &block)\n      #\n      # Note: Be sure that the symbol does not contain the word \"test\". test\n      # is a private method on Ruby objects and will cause the Be and Has\n      # matches to fail.\n      #\n      return Lebowski::RSpec::Matchers::Be.new(sym, *args) if sym.to_s =~ /^be_/\n      return Lebowski::RSpec::Matchers::Has.new(sym, *args) if sym.to_s =~ /^have_/\n      return Lebowski::RSpec::Operators::That.new(sym, *args) if sym.to_s =~ /^that_/      \n      super\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Format data as hex in various styles. [SEP] def print_hex(data, chunk_index, cols=80)\n      case hex_style\n      when 'lower', 'lowercase'\n        # encode to lowercase hex with no newlines\n        print Sixword::Hex.encode(data)\n      when 'finger', 'fingerprint'\n        # encode to GPG fingerprint like hex with newlines\n        newlines_every = cols / 5\n        if chunk_index != 0\n          if chunk_index % newlines_every == 0\n            print \"\\n\"\n          else\n            print ' '\n          end\n        end\n        print Sixword::Hex.encode_fingerprint(data)\n      when 'colon', 'colons'\n        # encode to SSL/SSH fingerprint like hex with colons\n        print ':' unless chunk_index == 0\n        print Sixword::Hex.encode_colons(data)\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "render\n Returns a regexp that matches this particular segment [SEP] def regexp\r\n      unless @regexp\r\n        if self.nodes.find{|i| i.type =~ /^\".+\"$/ }\r\n          # It's a very special regexp if there are constant fields\r\n          re_str = self.nodes.inject(\"^#{name}#{Regexp.escape(field_separator)}\"){|s, i|\r\n            field_re = i.simple_regexp(field_separator, segment_separator)+Regexp.escape(field_separator)+'?'\r\n            field_re = \"(#{field_re})?\" unless i.required\r\n            s+field_re\r\n          } + Regexp.escape(segment_separator)\r\n          @regexp = Regexp.new(re_str)\r\n        else\r\n          # Simple match\r\n          @regexp = Regexp.new(\"^#{name}#{Regexp.escape(field_separator)}[^#{Regexp.escape(segment_separator)}]*#{Regexp.escape(segment_separator)}\")\r\n        end\r\n        #puts sprintf(\"%s %p\", name, @regexp)\r\n      end\r\n      @regexp\r\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Merges the given posable object ids for a single query word into the given search result.\n Helper method for :search_words. [SEP] def merge_search_result_word_matches result, class_name, ids\n      if result.has_key? class_name\n        result[class_name] = result[class_name] & ids\n      else\n        result[class_name] = ids\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Update an existing authorization.\n API Path: /api/v2/authorizations/:id\n == Parameters:\n id::\n   id\n params::\n   Parameters of type PhraseApp::RequestParams::AuthorizationParams\n\n == Returns:\n   PhraseApp::ResponseObjects::Authorization\n   err [SEP] def authorization_update(id, params)\n      path = sprintf(\"/api/v2/authorizations/%s\", id)\n      data_hash = {}\n      post_body = nil\n  \n      if params.present?\n        unless params.kind_of?(PhraseApp::RequestParams::AuthorizationParams)\n          raise PhraseApp::ParamsHelpers::ParamsError.new(\"Expects params to be kind_of PhraseApp::RequestParams::AuthorizationParams\")\n        end\n      end\n  \n      data_hash = params.to_h\n      err = params.validate\n      if err != nil\n        return nil, err\n      end\n      reqHelper = PhraseApp::ParamsHelpers::BodyTypeHelper.new(data_hash, post_body)\n      rc, err = PhraseApp.send_request(@credentials, \"PATCH\", path, reqHelper.ctype, reqHelper.body, 200)\n      if err != nil\n        return nil, err\n      end\n      \n      return PhraseApp::ResponseObjects::Authorization.new(JSON.load(rc.body)), err\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "def determine_role(args)\n   args[:atc] == false ? role = \"pilot\" : role = \"all\"\n   args[:pilots] == false ? role = \"atc\" : role = role\n   role = \"all\" if args[:pilots] == false && args[:atc] == false\n   role\n end [SEP] def stations\n      stations = []\n      CSV.foreach(LOCAL_DATA, :col_sep =>':') do |row|\n        callsign, origin, destination, client = row[0].to_s, row[11].to_s, row[13].to_s, row[3].to_s\n        for cs in @callsign\n          stations << row if callsign[0...cs.length] == cs # && client == \"ATC\") unless @role == \"pilot\"\n          # stations << row if (origin[0...icao.length] == icao || destination[0...icao.length] == icao) unless @role == \"atc\"\n        end\n      end\n      stations\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Creates new immutable collection from the current one,\n updated with either the module's singleton method,\n or the proc having been imported from another module.\n\n @param [Module] source\n @param [Symbol] name\n @param [Symbol] new_name\n\n @return [Transproc::Store] [SEP] def import_method(source, name, new_name = name)\n      from = name.to_sym\n      to   = new_name.to_sym\n\n      fn = source.is_a?(Registry) ? source.fetch(from) : source.method(from)\n      self.class.new(methods.merge(to => fn))\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "A PATH variable format string representing the current PATH with the\n project's embedded/bin directory prepended. The correct path separator\n for the platform is used to join the paths.\n\n @param [Hash] env\n\n @return [Hash] [SEP] def with_embedded_path(env = {})\n      paths = [\"#{install_dir}/bin\", \"#{install_dir}/embedded/bin\"]\n      path_value = prepend_path(paths)\n      env.merge(path_key => path_value)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "-------------------------------------------------------------------------\n ------------------------------------------------------------------------- [SEP] def untracked_files?\n      # execute_command('status --porcelain | grep ??')\n      # $?.exitstatus == 0\n\n      result = execute_command('status --porcelain')\n      match = result.each_line.select { |b| b.start_with? '?? ' }\n      match.length > 0\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@!method initialize(args)\n Construct a new client for the Tone Analyzer service.\n\n @param args [Hash] The args to initialize with\n @option args version [String] The API version date to use with the service, in\n   \"YYYY-MM-DD\" format. Whenever the API is changed in a backwards\n   incompatible way, a new minor version of the API is released.\n   The service uses the API version for the date you specify, or\n   the most recent version before that date. Note that you should\n   not programmatically specify the current date at runtime, in\n   case the API has been updated since your application's release.\n   Instead, specify a version date that is compatible with your\n   application, and don't change it until your application is\n   ready for a later version.\n @option args url [String] The base url to use when contacting the service (e.g.\n   \"https://gateway.watsonplatform.net/tone-analyzer/api\").\n   The base url may differ between Bluemix regions.\n @option args username [String] The username used to authenticate with the service.\n   Username and password credentials are only required to run your\n   application locally or outside of Bluemix. When running on\n   Bluemix, the credentials will be automatically loaded from the\n   `VCAP_SERVICES` environment variable.\n @option args password [String] The password used to authenticate with the service.\n   Username and password credentials are only required to run your\n   application locally or outside of Bluemix. When running on\n   Bluemix, the credentials will be automatically loaded from the\n   `VCAP_SERVICES` environment variable.\n @option args iam_apikey [String] An API key that can be used to request IAM tokens. If\n   this API key is provided, the SDK will manage the token and handle the\n   refreshing.\n @option args iam_access_token [String] An IAM access token is fully managed by the application.\n   Responsibility falls on the application to refresh the token, either before\n   it expires or reactively upon receiving a 401 from the service as any requests\n   made with an expired token will fail.\n @option args iam_url [String] An optional URL for the IAM service API. Defaults to\n   'https://iam.ng.bluemix.net/identity/token'.\n\n Methods\n\n\n @!method tone(tone_input:, sentences: nil, tones: nil, content_language: nil, accept_language: nil, content_type: nil)\n Analyze general tone.\n Use the general purpose endpoint to analyze the tone of your input content. The\n   service analyzes the content for emotional and language tones. The method always\n   analyzes the tone of the full document; by default, it also analyzes the tone of\n   each individual sentence of the content.\n\n   You can submit no more than 128 KB of total input content and no more than 1000\n   individual sentences in JSON, plain text, or HTML format. The service analyzes the\n   first 1000 sentences for document-level analysis and only the first 100 sentences\n   for sentence-level analysis.\n\n   Per the JSON specification, the default character encoding for JSON content is\n   effectively always UTF-8; per the HTTP specification, the default encoding for\n   plain text and HTML is ISO-8859-1 (effectively, the ASCII character set). When\n   specifying a content type of plain text or HTML, include the `charset` parameter\n   to indicate the character encoding of the input text; for example: `Content-Type:\n   text/plain;charset=utf-8`. For `text/html`, the service removes HTML tags and\n   analyzes only the textual content.\n\n   **See also:** [Using the general-purpose\n   endpoint](https://cloud.ibm.com/docs/services/tone-analyzer/using-tone.html#using-the-general-purpose-endpoint).\n @param tone_input [ToneInput] JSON, plain text, or HTML input that contains the content to be analyzed. For JSON\n   input, provide an object of type `ToneInput`.\n @param sentences [Boolean] Indicates whether the service is to return an analysis of each individual sentence\n   in addition to its analysis of the full document. If `true` (the default), the\n   service returns results for each sentence.\n @param tones [Array[String]] **`2017-09-21`:** Deprecated. The service continues to accept the parameter for\n   backward-compatibility, but the parameter no longer affects the response.\n\n   **`2016-05-19`:** A comma-separated list of tones for which the service is to\n   return its analysis of the input; the indicated tones apply both to the full\n   document and to individual sentences of the document. You can specify one or more\n   of the valid values. Omit the parameter to request results for all three tones.\n @param content_language [String] The language of the input text for the request: English or French. Regional\n   variants are treated as their parent language; for example, `en-US` is interpreted\n   as `en`. The input content must match the specified language. Do not submit\n   content that contains both languages. You can use different languages for\n   **Content-Language** and **Accept-Language**.\n   * **`2017-09-21`:** Accepts `en` or `fr`.\n   * **`2016-05-19`:** Accepts only `en`.\n @param accept_language [String] The desired language of the response. For two-character arguments, regional\n   variants are treated as their parent language; for example, `en-US` is interpreted\n   as `en`. You can use different languages for **Content-Language** and\n   **Accept-Language**.\n @param content_type [String] The type of the input. A character encoding can be specified by including a\n   `charset` parameter. For example, 'text/plain;charset=utf-8'.\n @return [IBMCloudSdkCore::DetailedResponse] A `IBMCloudSdkCore::DetailedResponse` object representing the response. [SEP] def tone(tone_input:, sentences: nil, tones: nil, content_language: nil, accept_language: nil, content_type: nil)\n      raise ArgumentError.new(\"tone_input must be provided\") if tone_input.nil?\n\n      headers = {\n        \"Content-Language\" => content_language,\n        \"Accept-Language\" => accept_language,\n        \"Content-Type\" => content_type\n      }\n      sdk_headers = Common.new.get_sdk_headers(\"tone_analyzer\", \"V3\", \"tone\")\n      headers.merge!(sdk_headers)\n\n      params = {\n        \"version\" => @version,\n        \"sentences\" => sentences,\n        \"tones\" => tones.to_a\n      }\n\n      if content_type.start_with?(\"application/json\") && tone_input.instance_of?(Hash)\n        data = tone_input.to_json\n      else\n        data = tone_input\n      end\n\n      method_url = \"/v3/tone\"\n\n      response = request(\n        method: \"POST\",\n        url: method_url,\n        headers: headers,\n        params: params,\n        data: data,\n        accept_json: true\n      )\n      response\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "List available evaluators + devices in the current local environment\n Returns:\n - An array containing the names of those devices [SEP] def list_local_devices\n      local_name = \"job:localhost\"\n      TensorStream::Evaluator.evaluators.collect { |k, v|\n        v[:class].query_supported_devices.collect do |device_str|\n          [local_name, \"ts:#{k}:#{device_str.name}\"].join(\"/\")\n        end\n      }.flatten\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "title:\t\tlegend: \t\txAxis: \t\tyAxis: \t\ttooltip: \tcredits:  :plotOptions [SEP] def defaults_options\n      self.title({:text => nil})\n      self.legend({:layout => \"vertical\", :style => {}})\n      self.xAxis({})\n      self.yAxis({:title => {:text => nil}, :labels => {}})\n      self.tooltip({:enabled => true})\n      self.credits({:enabled => false})\n      self.plotOptions({:areaspline => {}})\n      self.chart({:defaultSeriesType => \"line\", :renderTo => nil})\n      self.subtitle({})\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Pack file entities. Directory entities are queued, not packed in this method. [SEP] def pack_entities(entities)\n      entities.each do |entity|\n        # ignore bad entities\n        next unless entity.is_a?(Hash) && entity[:path]\n\n        path = entity[:path]\n        if File.symlink? path\n          postpone_symlink entity\n        elsif File.directory? path\n          postpone_dir entity\n        elsif File.file? path\n          pack_file_entity entity\n        end\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "seconds [SEP] def move_mouse_randomly\n      x, y = get_cursor_pos\n\n      # For some reason, x or y returns as nil sometimes\n      if x && y\n        x1, y1 = x + rand(3) - 1, y + rand(3) - 1\n        mouse_event(MOUSEEVENTF_ABSOLUTE, x1, y1, 0, 0)\n        puts \"Cursor positon set to #{x1}, #{y1}\"\n      else\n        puts \"X: #{x}, Y: #{y}, last error: #{Win::Error::get_last_error}\"\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Begin downloading one or more torrents.\n\n If passing mulitple urls, pass them as an array. [SEP] def download urls\n      urls = Array(urls)\n      urls = urls.join('%0A')\n\n      options = {\n        body: \"urls=#{urls}\"\n      }\n\n      self.class.post('/command/download', options)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@!group DSL methods\n --------------------------------------------------\n\n Set or retrieve the upgrade code.\n\n @example\n   upgrade_code 'ABCD-1234'\n\n @param [Hash] val\n   the UpgradeCode to set\n\n @return [Hash]\n   the set UpgradeCode [SEP] def upgrade_code(val = NULL)\n      if null?(val)\n        @upgrade_code || raise(MissingRequiredAttribute.new(self, :upgrade_code, \"2CD7259C-776D-4DDB-A4C8-6E544E580AA1\"))\n      else\n        unless val.is_a?(String)\n          raise InvalidValue.new(:upgrade_code, \"be a String\")\n        end\n\n        @upgrade_code = val\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Moves this object as an elevator (i.e., potentially carrying other\n objects) with the specified forces or towards a given point.\n\n Parameters:\n [arg] A Vector specifying either the forces acting on this object or a\n       point towards the object should move.\n [speed] If the first argument is a forces vector, then this should be\n         +nil+. If it is a point, then this is the constant speed at which\n         the object will move (provided as a scalar, not a vector).\n [obstacles] An array of obstacles to be considered in the collision\n             checking, and carried along when colliding from above.\n             Obstacles must be instances of Block (or derived classes),\n             or objects that <code>include Movement</code>.\n [obst_obstacles] Obstacles that should be considered when moving objects\n                  from the +obstacles+ array, i.e., these obstacles won't\n                  interfere in the elevator's movement, but in the movement\n                  of the objects being carried.\n [obst_ramps] Ramps to consider when moving objects from the +obstacles+\n              array, as described for +obst_obstacles+. [SEP] def move_carrying(arg, speed, obstacles, obst_obstacles, obst_ramps)\n      if speed\n        x_d = arg.x - @x; y_d = arg.y - @y\n        distance = Math.sqrt(x_d**2 + y_d**2)\n\n        if distance == 0\n          @speed.x = @speed.y = 0\n          return\n        end\n\n        @speed.x = 1.0 * x_d * speed / distance\n        @speed.y = 1.0 * y_d * speed / distance\n      else\n        arg += G.gravity\n        @speed.x += arg.x / @mass; @speed.y += arg.y / @mass\n        @speed.x = 0 if @speed.x.abs < G.min_speed.x\n        @speed.y = 0 if @speed.y.abs < G.min_speed.y\n        @speed.x = (@speed.x <=> 0) * @max_speed.x if @speed.x.abs > @max_speed.x\n        @speed.y = (@speed.y <=> 0) * @max_speed.y if @speed.y.abs > @max_speed.y\n      end\n\n      x_aim = @x + @speed.x; y_aim = @y + @speed.y\n      passengers = []\n      obstacles.each do |o|\n        if @x + @w > o.x && o.x + o.w > @x\n          foot = o.y + o.h\n          if foot.round(6) == @y.round(6) || @speed.y < 0 && foot < @y && foot > y_aim\n            passengers << o\n          end\n        end\n      end\n\n      prev_x = @x; prev_y = @y\n      if speed\n        if @speed.x > 0 && x_aim >= arg.x || @speed.x < 0 && x_aim <= arg.x\n          @x = arg.x; @speed.x = 0\n        else\n          @x = x_aim\n        end\n        if @speed.y > 0 && y_aim >= arg.y || @speed.y < 0 && y_aim <= arg.y\n          @y = arg.y; @speed.y = 0\n        else\n          @y = y_aim\n        end\n      else\n        @x = x_aim; @y = y_aim\n      end\n\n      forces = Vector.new @x - prev_x, @y - prev_y\n      prev_g = G.gravity.clone\n      G.gravity.x = G.gravity.y = 0\n      passengers.each do |p|\n        prev_speed = p.speed.clone\n        prev_forces = p.stored_forces.clone\n        prev_bottom = p.bottom\n        p.speed.x = p.speed.y = 0\n        p.stored_forces.x = p.stored_forces.y = 0\n        p.instance_exec { @bottom = nil }\n        p.move forces * p.mass, obst_obstacles, obst_ramps\n        p.speed.x = prev_speed.x\n        p.speed.y = prev_speed.y\n        p.stored_forces.x = prev_forces.x\n        p.stored_forces.y = prev_forces.y\n        p.instance_exec(prev_bottom) { |b| @bottom = b }\n      end\n      G.gravity = prev_g\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Finds a random prime number of *at least* bitlength\n Validate primeness using the miller-rabin primality test.\n Increment through odd numbers to test candidates until a good prime is found. [SEP] def get_prime_number(bitlength)\n      prime_cand = get_random_number_with_bitlength(bitlength + 1)\n      prime_cand += 1 if prime_cand.even?\n\n      # loop, adding 2 to keep it odd, until prime_cand is prime.\n      (prime_cand += 2) until miller_rabin_prime?(prime_cand)\n\n      prime_cand\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Parses this segment out of a string, puts the match into value, returns the rest of the string - nil\n if cannot parse [SEP] def parse(str)\r\n      s = str\r\n      #puts \"Parsing segment #{name} from #{s} with regexp [#{regexp.source}]\"\r\n      m = regexp.match(s)\r\n      #puts \"Matched #{m ? m[0] : 'nothing'}\"\r\n      \r\n      return nil unless m\r\n\r\n      s = m.post_match\r\n      self.parsed_str = m[0]\r\n      s = do_repeats(s)\r\n\r\n      #puts \"Parsed segment \"+self.inspect\r\n      return s\r\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Return all nodes in order as an hashalways_use [SEP] def get_hash(params = {}, sorted = true)\n      get_nodes(sorted).map{|n| n.to_hash(params[n.name])}\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Build all schemas with IDs, mapping out the namespace [SEP] def build_schemas(parent_schema)\n      schema = parent_schema.schema\n\n      # Build ref schemas if they exist\n      if schema[\"$ref\"]\n        load_ref_schema(parent_schema, schema[\"$ref\"])\n      end\n\n      case schema[\"extends\"]\n      when String\n        load_ref_schema(parent_schema, schema[\"extends\"])\n      when Array\n        schema['extends'].each do |type|\n          handle_schema(parent_schema, type)\n        end\n      end\n\n      # Check for schemas in union types\n      [\"type\", \"disallow\"].each do |key|\n        if schema[key].is_a?(Array)\n          schema[key].each do |type|\n            if type.is_a?(Hash)\n              handle_schema(parent_schema, type)\n            end\n          end\n        end\n      end\n\n      # Schema properties whose values are objects, the values of which\n      # are themselves schemas.\n      %w[definitions properties patternProperties].each do |key|\n        next unless value = schema[key]\n        value.each do |k, inner_schema|\n          handle_schema(parent_schema, inner_schema)\n        end\n      end\n\n      # Schema properties whose values are themselves schemas.\n      %w[additionalProperties additionalItems dependencies extends].each do |key|\n        next unless schema[key].is_a?(Hash)\n        handle_schema(parent_schema, schema[key])\n      end\n\n      # Schema properties whose values may be an array of schemas.\n      %w[allOf anyOf oneOf not].each do |key|\n        next unless value = schema[key]\n        Array(value).each do |inner_schema|\n          handle_schema(parent_schema, inner_schema)\n        end\n      end\n\n      # Items are always schemas\n      if schema[\"items\"]\n        items = schema[\"items\"].clone\n        items = [items] unless items.is_a?(Array)\n\n        items.each do |item|\n          handle_schema(parent_schema, item)\n        end\n      end\n\n      # Convert enum to a ArraySet\n      if schema[\"enum\"].is_a?(Array)\n        schema[\"enum\"] = ArraySet.new(schema[\"enum\"])\n      end\n\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Returns the current value of the specified form field. It therefore accepts the same\n parameters as the #field method.\n @param [String, Watir::Label] label the label for which to find the form field.\n @param [Watir::Element] start_node the node where to start searching for the label.\n @param [Boolean] placeholder whether to handle label as Watir::Label or as placeholder\n                              attribute for an input field.\n @param [Boolean] id          assumes the given label is an HTML ID and searches for it.\n @return [String, Boolean, Array] current value of the field. [SEP] def value_of(label, start_node: nil, placeholder: false, id: false)\n      field(label,\n            start_node:     start_node,\n            placeholder:    placeholder,\n            id:             id\n      ).field_value\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Returns a hash in the following format:\n {\n   \"pod/web-1\" => [\n     \"Pulling: pulling image \"hello-world:latest\" (1 events)\",\n     \"Pulled: Successfully pulled image \"hello-world:latest\" (1 events)\"\n   ]\n } [SEP] def fetch_events(kubectl)\n      return {} unless exists?\n      out, _err, st = kubectl.run(\"get\", \"events\", \"--output=go-template=#{Event.go_template_for(type, name)}\",\n        log_failure: false)\n      return {} unless st.success?\n\n      event_collector = Hash.new { |hash, key| hash[key] = [] }\n      Event.extract_all_from_go_template_blob(out).each_with_object(event_collector) do |candidate, events|\n        events[id] << candidate.to_s if candidate.seen_since?(@deploy_started_at - 5.seconds)\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "region key manipulation \n hash512(secret)\n => HASH(512bit)\n => [LH(256bit)] / [RH(256bit)]\n => LH -> (set some bits) -> a\n return ( a , RH ) [SEP] def secret_expand(secret)\n      raise \"Bad size of private key\" unless secret.length.equal? 32\n\n      h = hash512(secret)\n      a = int_form_bytes(h[0,32])\n      a &= (1 << 254) - 8\n      a |= (1 << 254)\n      return [a, h[32,32]]\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "This method returns a single crisis.\n\n @param [String] identifier A unique crisis identifier\n @return [Hash] The single crisis as JSON object [SEP] def get_crisis(identifier, params = nil)\n            return nil if identifier.nil? or identifier.empty?\n            endpoint = \"/v1/crises/#{identifier}.json?auth_token=#{@auth_token}\"\n            endpoint += \"&#{URI.encode_www_form params}\" if params\n            response = self.get(endpoint)\n            Sigimera::Crisis.new JSON.parse response.body if response and response.body\n        end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Causes the object to move in cycles across multiple given points (the\n first point in the array is the first point the object will move towards,\n so it doesn't need to be equal to the current/initial position). If\n obstacles are provided, it will behave as an elevator (as in\n +move_carrying+).\n\n Parameters:\n [points] An array of Vectors representing the path that the object will\n          perform.\n [speed] The constant speed at which the object will move. This must be\n         provided as a scalar, not a vector.\n [obstacles] An array of obstacles to be considered in the collision\n             checking, and carried along when colliding from above.\n             Obstacles must be instances of Block (or derived classes),\n             or objects that <code>include Movement</code>.\n [obst_obstacles] Obstacles that should be considered when moving objects\n                  from the +obstacles+ array, i.e., these obstacles won't\n                  interfere in the elevator's movement, but in the movement\n                  of the objects being carried.\n [obst_ramps] Ramps to consider when moving objects from the +obstacles+\n              array, as described for +obst_obstacles+. [SEP] def cycle(points, speed, obstacles = nil, obst_obstacles = nil, obst_ramps = nil)\n      @cur_point = 0 if @cur_point.nil?\n      if obstacles\n        move_carrying points[@cur_point], speed, obstacles, obst_obstacles, obst_ramps\n      else\n        move_free points[@cur_point], speed\n      end\n      if @speed.x == 0 and @speed.y == 0\n        if @cur_point == points.length - 1; @cur_point = 0\n        else; @cur_point += 1; end\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Allow configuration options to be set for named objects. [SEP] def configure_objects(confs={})\n      confs.each do |key,opts|\n        key = key.to_sym\n        @object_configs[key] ={} unless has_config?(key)\n        @object_configs[key].merge!(opts)\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@note Run a command against Google Directory\n\n @param command [Symbol] choose command to perform these include: :user_get, :user_exists? (t/f), :user_create, :user_delete, :user_update & convience commands :user_suspend, :user_reactivate, :user_change_password\n @param attributes [Hash] attributes needed to perform command\n @return [Hash] formatted as: `{success: {command: :command, attributes: {primary_email: \"user@domain\"}, response: GoogleAnswer} }` [SEP] def run( command:, attributes: {} )\n      response  = {}\n      begin\n        response           = send( command, attributes: attributes )\n        response[:status]  = 'success'\n      rescue Google::Apis::ClientError => error\n        response = {status: 'error', response: error,\n                    attributes: attributes, command: command,\n                   }\n      end\n      response\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Get an array of the individual characters for this barcode. Special\ncharacters like FNC1 will be present. Characters from extras are not\npresent. [SEP] def characters\n      chars = data.split(//n)\n\n      if type == 'C'\n        result = []\n        count = 0\n        while count < chars.size\n          if chars[count] =~ /^\\d$/\n            #If encountering a digit, next char/byte *must* be second digit in pair. I.e. if chars[count] is 5,\n            #chars[count+1] must be /[0-9]/, otherwise it's not valid\n            result << \"#{chars[count]}#{chars[count+1]}\"\n            count += 2\n          else\n            result << chars[count]\n            count += 1\n          end\n        end\n        result\n      else\n        chars\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Net::HTTP [SEP] def session\n      @session ||= begin\n        http = Net::HTTP.new @host, @port\n        http.use_ssl = self.use_ssl\n        http.verify_mode = self.verify_mode\n        http.read_timeout = self.read_timeout\n        http.ssl_version = self.ssl_version if self.use_ssl\n        http.start\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Computes reciprocal of square root of x element-wise.\n\n\n @param input_a tensor X (of type FLOATING_POINT_TYPES)\n\n Options:\n @option name Optional name\n @return Tensor [SEP] def rsqrt(input_a, name: nil)\n      check_allowed_types(input_a, TensorStream::Ops::FLOATING_POINT_TYPES)\n      _op(:rsqrt, input_a, name: name)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Convert the pattern into an Addressable URI by substituting\n the template slugs with nonsense strings. [SEP] def to_substituted_uri\n      url = pattern\n      substitutions.each_pair { |slug, value| url = url.sub(slug, value) }\n      begin\n        Addressable::URI.parse(url)\n      rescue Addressable::URI::InvalidURIError\n        SitePrism.logger.warn(\"Ensure you don't use templated port numbers.\")\n        raise SitePrism::InvalidUrlMatcherError\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "split_names(path) -> prefix, [name, ...] [SEP] def split_names(path)\n      names = []\n      while (r = chop_basename(path))\n        path, basename = r\n        names.unshift basename\n      end\n\n      [path, names]\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "carattere per carattere... [SEP] def rainbow(str)\n    i=0\n    ret = '' \n    str=str.to_s\n    while(i < str.length)\n      ch = str[i]\n      palette = $color_db[0][i % $color_db[0].length ]\n      ret << (colora(palette,str[i,1]))\n      i += 1\n    end\n    ret\n  end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "sync all module changes into rim branch [SEP] def sync(message = nil, rebase = nil, split = true)\n    # get the name of the current workspace branch\n    RIM::git_session(@ws_root) do |s|\n      branch = s.current_branch || ''\n      rim_branch = \"rim/\" + branch\n      branch_sha1 = nil\n      changed_modules = nil\n      if branch.empty?\n        raise RimException.new(\"Not on a git branch.\")\n      elsif branch.start_with?(\"rim/\")\n        raise RimException.new(\"The current git branch '#{branch}' is a rim integration branch. Please switch to a non rim branch to proceed.\")\n      else\n        branch = \"refs/heads/#{branch}\"\n        branch_sha1 = s.rev_sha1(rim_branch)\n        remote_rev = get_latest_remote_revision(s, branch)\n        rev = get_latest_clean_path_revision(s, branch, remote_rev)\n        if !s.has_branch?(rim_branch) || has_ancestor?(s, branch, s.rev_sha1(rim_branch)) || !has_ancestor?(s, rim_branch, remote_rev)\n          s.execute(\"git branch -f #{rim_branch} #{rev}\")\n          branch_sha1 = s.rev_sha1(rim_branch)\n        end\n        remote_url = \"file://\" + @ws_root\n        @logger.debug(\"Folder for temporary git repositories: #{@rim_path}\")\n        tmpdir = clone_or_fetch_repository(remote_url, module_tmp_git_path(\".ws\"), \"Cloning workspace git...\")\n        RIM::git_session(tmpdir) do |tmp_session|\n          tmp_session.execute(\"git reset --hard\")\n          tmp_session.execute(\"git clean -xdf\")\n          # use -f here to prevent git checkout from checking for untracked files which might be overwritten. \n          # this is safe since we removed any untracked files before.\n          # this is a workaround for a name case problem on windows:\n          # if a file's name changes case between the current head and the checkout target,\n          # git checkout will report the file with the new name as untracked and will fail\n          tmp_session.execute(\"git checkout -B #{rim_branch} -f remotes/origin/#{rim_branch}\")\n          changed_modules = sync_modules(tmp_session, message)\n          if !split\n            tmp_session.execute(\"git reset --soft #{branch_sha1}\")\n            commit(tmp_session, message ? message : get_commit_message(changed_modules)) if tmp_session.uncommited_changes?\n          end\n          tmp_session.execute(\"git push #{remote_url} #{rim_branch}:#{rim_branch}\")\n        end\n      end\n      if !changed_modules.empty?\n        if rebase\n          s.execute(\"git rebase #{rim_branch}\")\n          @logger.info(\"Changes have been commited to branch #{rim_branch} and workspace has been rebased successfully.\")\n        else\n          @logger.info(\"Changes have been commited to branch #{rim_branch}. Rebase to apply changes to workspace.\")\n        end\n      else\n        @logger.info(\"No changes.\")\n      end\n    end\n  end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Select a flair template and apply it to a user or link\n\n @param template_id [String] The template id to apply.\n @param subreddit [String] The subreddit targeted.\n @param (see LinksComments#info)\n @option opts [String] :link The link id to apply to\n @option opts [String] :user The username to apply flair to\n @option opts [String] :text The flair text\n @return (see #clear_sessions) [SEP] def select_flair_template template_id, subreddit, opts = {}\n      logged_in?\n      params = {\n        flair_template_id: template_id,\n        uh: @modhash,\n        r: subreddit,\n        api_type: 'json'\n      }\n      params.merge! opts\n      post('/api/selectflair', body: params)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "Add output arc to the +place+.\n +block+ is the arc's expresstion, it will be called while firing\n transition. Value returned from the block will be put in output\n place. The block gets +binding+, and +clock+ values. +binding+ is\n a hash with names of input places as keys nad tokens as values. [SEP] def output(place, &block)\n      raise \"This is not a Place object!\" unless place.kind_of? Place\n      raise \"Tried to define output arc without expression! Block is required!\" unless block_given?\n      @outputs << OutputArc.new(place, block)\n    end", "target": 1, "target_options": ["no_match", "match"]}
{"input": "@!group Resource methods\n --------------------------------------------------\n\n The preferred path to a resource on disk with the given +name+. This\n method will perform an \"intelligent\" search for a resource by first\n looking in the local project expected {#resources_path}, and then falling\n back to Omnibus' files.\n\n @example When the resource exists locally\n   resource_path(\"spec.erb\") #=> \"/path/to/project/resources/rpm/spec.erb\"\n\n @example When the resource does not exist locally\n   resource_path(\"spec.erb\") #=> \"/omnibus-x.y.z/resources/rpm/spec.erb\"\n\n @param [String] name\n   the name of the resource on disk to find [SEP] def resource_path(name)\n      local = File.join(resources_path, name)\n\n      if File.exist?(local)\n        log.info(log_key) { \"Using local resource `#{name}' from `#{local}'\" }\n        local\n      else\n        log.debug(log_key) { \"Using vendored resource `#{name}'\" }\n        Omnibus.source_root.join(\"resources/#{id}/#{name}\").to_s\n      end\n    end", "target": 1, "target_options": ["no_match", "match"]}
