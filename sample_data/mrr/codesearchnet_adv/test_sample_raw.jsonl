{"url": "https://github.com/macacajs/wd.py/blob/6d3c52060013e01a67cd52b68b5230b387427bad/macaca/webelement.py#L47-L60", "sha": "6d3c52060013e01a67cd52b68b5230b387427bad", "docstring_summary": "Private method to execute command with data.", "language": "python", "parameters": "(self, command, data=None, unpack=True)", "return_statement": "return self._driver._execute(command, data, unpack)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "None", ",", "arg_3", "=", "True", ")", ":", "if", "not", "arg_2", ":", "arg_2", "=", "{", "}", "arg_2", ".", "setdefault", "(", "'element_id'", ",", "arg_0", ".", "element_id", ")", "return", "arg_0", ".", "_driver", ".", "Func", "(", "arg_1", ",", "arg_2", ",", "arg_3", ")"], "function": "def Func(arg_0, arg_1, arg_2=None, arg_3=True):\n        \"\"\"Private method to execute command with data.\n\n        Args:\n            command(Command): The defined command.\n            data(dict): The uri variable and body.\n\n        Returns:\n            The unwrapped value field in the json response.\n        \"\"\"\n        if not arg_2:\n            arg_2 = {}\n        arg_2.setdefault('element_id', arg_0.element_id)\n        return arg_0._driver.Func(arg_1, arg_2, arg_3)", "path": "macaca/webelement.py", "identifier": "WebElement._execute", "docstring": "Private method to execute command with data.\n\n        Args:\n            command(Command): The defined command.\n            data(dict): The uri variable and body.\n\n        Returns:\n            The unwrapped value field in the json response.", "docstring_tokens": ["Private", "method", "to", "execute", "command", "with", "data", "."], "nwo": "macacajs/wd.py", "score": 0.3182350344440769, "idx": 264188}
{"url": "https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/examples/latent_dirichlet_allocation_distributions.py#L197-L222", "sha": "e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5", "docstring_summary": "Create the decoder function.", "language": "python", "parameters": "(num_topics, num_words)", "return_statement": "return decoder, topics_words", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_2", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\"topics_words_logits\"", ",", "shape", "=", "[", "arg_0", ",", "arg_1", "]", ",", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "glorot_normal_initializer", "(", ")", ")", "arg_3", "=", "tf", ".", "nn", ".", "softmax", "(", "arg_2", ",", "axis", "=", "-", "1", ")", "def", "decoder", "(", "arg_4", ")", ":", "arg_5", "=", "tf", ".", "matmul", "(", "arg_4", ",", "arg_3", ")", "return", "tfd", ".", "OneHotCategorical", "(", "probs", "=", "arg_5", ",", "name", "=", "\"bag_of_words\"", ")", "return", "decoder", ",", "arg_3"], "function": "def Func(arg_0, arg_1):\n  \"\"\"Create the decoder function.\n\n  Args:\n    num_topics: The number of topics.\n    num_words: The number of words.\n\n  Returns:\n    decoder: A `callable` mapping a `Tensor` of encodings to a\n      `tfd.Distribution` instance over words.\n  \"\"\"\n  arg_2 = tf.compat.v1.get_variable(\n      \"topics_words_logits\",\n      shape=[arg_0, arg_1],\n      initializer=tf.compat.v1.glorot_normal_initializer())\n  arg_3 = tf.nn.softmax(arg_2, axis=-1)\n\n  def decoder(arg_4):\n    arg_5 = tf.matmul(arg_4, arg_3)\n    # The observations are bag of words and therefore not one-hot. However,\n    # log_prob of OneHotCategorical computes the probability correctly in\n    # this case.\n    return tfd.OneHotCategorical(probs=arg_5,\n                                 name=\"bag_of_words\")\n\n  return decoder, arg_3", "path": "tensorflow_probability/examples/latent_dirichlet_allocation_distributions.py", "identifier": "make_decoder", "docstring": "Create the decoder function.\n\n  Args:\n    num_topics: The number of topics.\n    num_words: The number of words.\n\n  Returns:\n    decoder: A `callable` mapping a `Tensor` of encodings to a\n      `tfd.Distribution` instance over words.", "docstring_tokens": ["Create", "the", "decoder", "function", "."], "nwo": "tensorflow/probability", "score": 0.9937575147981225, "idx": 277943}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/utils/PyColorize.py#L131-L203", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "Parse and send the colored source.", "language": "python", "parameters": "(self, raw, out = None, scheme = '')", "return_statement": "return (None, error)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "None", ",", "arg_3", "=", "''", ")", ":", "arg_4", "=", "0", "if", "arg_2", "==", "'str'", "or", "arg_0", ".", "out", "==", "'str'", "or", "isinstance", "(", "arg_0", ".", "out", ",", "StringIO", ".", "StringIO", ")", ":", "arg_5", "=", "arg_0", ".", "out", "arg_0", ".", "out", "=", "StringIO", ".", "StringIO", "(", ")", "arg_4", "=", "1", "elif", "arg_2", "is", "not", "None", ":", "arg_0", ".", "out", "=", "arg_2", "if", "arg_3", "==", "'NoColor'", ":", "arg_6", "=", "False", "arg_0", ".", "out", ".", "write", "(", "arg_1", ")", "if", "arg_4", ":", "return", "arg_1", ",", "arg_6", "else", ":", "return", "None", ",", "arg_6", "arg_7", "=", "arg_0", ".", "color_table", "[", "arg_3", "]", ".", "colors", "arg_0", ".", "colors", "=", "arg_7", "arg_0", ".", "raw", "=", "arg_1", ".", "expandtabs", "(", ")", ".", "rstrip", "(", ")", "arg_0", ".", "lines", "=", "[", "0", ",", "0", "]", "arg_9", "=", "0", "arg_10", "=", "arg_0", ".", "raw", ".", "find", "arg_11", "=", "arg_0", ".", "lines", ".", "append", "while", "1", ":", "arg_9", "=", "arg_10", "(", "'\\n'", ",", "arg_9", ")", "+", "1", "if", "not", "arg_9", ":", "break", "arg_11", "(", "arg_9", ")", "arg_11", "(", "len", "(", "arg_0", ".", "raw", ")", ")", "arg_0", ".", "pos", "=", "0", "arg_12", "=", "StringIO", ".", "StringIO", "(", "arg_0", ".", "raw", ")", "arg_6", "=", "False", "try", ":", "for", "arg_13", "in", "generate_tokens", "(", "arg_12", ".", "readline", ")", ":", "arg_0", "(", "*", "arg_13", ")", "except", "tokenize", ".", "TokenError", "as", "ex", ":", "arg_14", "=", "ex", ".", "args", "[", "0", "]", "arg_15", "=", "ex", ".", "args", "[", "1", "]", "[", "0", "]", "arg_0", ".", "out", ".", "write", "(", "\"%s\\n\\n*** ERROR: %s%s%s\\n\"", "%", "(", "arg_7", "[", "token", ".", "ERRORTOKEN", "]", ",", "arg_14", ",", "arg_0", ".", "raw", "[", "arg_0", ".", "lines", "[", "arg_15", "]", ":", "]", ",", "arg_7", ".", "normal", ")", ")", "arg_6", "=", "True", "arg_0", ".", "out", ".", "write", "(", "arg_7", ".", "normal", "+", "'\\n'", ")", "if", "arg_4", ":", "arg_16", "=", "arg_0", ".", "out", ".", "getvalue", "(", ")", "arg_0", ".", "out", "=", "arg_5", "return", "(", "arg_16", ",", "arg_6", ")", "return", "(", "None", ",", "arg_6", ")"], "function": "def Func(arg_0, arg_1, arg_2 = None, arg_3 = ''):\n        \"\"\" Parse and send the colored source.\n\n        If out and scheme are not specified, the defaults (given to\n        constructor) are used.\n\n        out should be a file-type object. Optionally, out can be given as the\n        string 'str' and the parser will automatically return the output in a\n        string.\"\"\"\n\n        arg_4 = 0\n        if arg_2 == 'str' or arg_0.out == 'str' or \\\n           isinstance(arg_0.out,StringIO.StringIO):\n            # XXX - I don't really like this state handling logic, but at this\n            # point I don't want to make major changes, so adding the\n            # isinstance() check is the simplest I can do to ensure correct\n            # behavior.\n            arg_5 = arg_0.out\n            arg_0.out = StringIO.StringIO()\n            arg_4 = 1\n        elif arg_2 is not None:\n            arg_0.out = arg_2\n\n        # Fast return of the unmodified input for NoColor scheme\n        if arg_3 == 'NoColor':\n            arg_6 = False\n            arg_0.out.write(arg_1)\n            if arg_4:\n                return arg_1,arg_6\n            else:\n                return None,arg_6\n\n        # local shorthands\n        arg_7 = arg_0.color_table[arg_3].colors\n        arg_0.colors = arg_7 # put in object so __call__ sees it\n\n        # Remove trailing whitespace and normalize tabs\n        arg_0.raw = arg_1.expandtabs().rstrip()\n\n        # store line offsets in self.lines\n        arg_0.lines = [0, 0]\n        arg_9 = 0\n        arg_10 = arg_0.raw.find\n        arg_11 = arg_0.lines.append\n        while 1:\n            arg_9 = arg_10('\\n', arg_9) + 1\n            if not arg_9: break\n            arg_11(arg_9)\n        arg_11(len(arg_0.raw))\n\n        # parse the source and write it\n        arg_0.pos = 0\n        arg_12 = StringIO.StringIO(arg_0.raw)\n\n        arg_6 = False\n        try:\n            for arg_13 in generate_tokens(arg_12.readline):\n                arg_0(*arg_13)\n        except tokenize.TokenError as ex:\n            arg_14 = ex.args[0]\n            arg_15 = ex.args[1][0]\n            arg_0.out.write(\"%s\\n\\n*** ERROR: %s%s%s\\n\" %\n                           (arg_7[token.ERRORTOKEN],\n                            arg_14, arg_0.raw[arg_0.lines[arg_15]:],\n                            arg_7.normal)\n                           )\n            arg_6 = True\n        arg_0.out.write(arg_7.normal+'\\n')\n        if arg_4:\n            arg_16 = arg_0.out.getvalue()\n            arg_0.out = arg_5\n            return (arg_16, arg_6)\n        return (None, arg_6)", "path": "environment/lib/python2.7/site-packages/IPython/utils/PyColorize.py", "identifier": "Parser.format2", "docstring": "Parse and send the colored source.\n\n        If out and scheme are not specified, the defaults (given to\n        constructor) are used.\n\n        out should be a file-type object. Optionally, out can be given as the\n        string 'str' and the parser will automatically return the output in a\n        string.", "docstring_tokens": ["Parse", "and", "send", "the", "colored", "source", "."], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 264292}
{"url": "https://github.com/trailofbits/manticore/blob/54c5a15b1119c523ae54c09972413e8b97f11629/manticore/native/cpu/abstractcpu.py#L767-L776", "sha": "54c5a15b1119c523ae54c09972413e8b97f11629", "docstring_summary": "Write `data` to the stack and decrement the stack pointer accordingly.", "language": "python", "parameters": "(self, data, force=False)", "return_statement": "return self.STACK", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "False", ")", ":", "arg_0", ".", "STACK", "-=", "len", "(", "arg_1", ")", "arg_0", ".", "write_bytes", "(", "arg_0", ".", "STACK", ",", "arg_1", ",", "arg_2", ")", "return", "arg_0", ".", "STACK"], "function": "def Func(arg_0, arg_1, arg_2=False):\n        \"\"\"\n        Write `data` to the stack and decrement the stack pointer accordingly.\n\n        :param str data: Data to write\n        :param force: whether to ignore memory permissions\n        \"\"\"\n        arg_0.STACK -= len(arg_1)\n        arg_0.write_bytes(arg_0.STACK, arg_1, arg_2)\n        return arg_0.STACK", "path": "manticore/native/cpu/abstractcpu.py", "identifier": "Cpu.push_bytes", "docstring": "Write `data` to the stack and decrement the stack pointer accordingly.\n\n        :param str data: Data to write\n        :param force: whether to ignore memory permissions", "docstring_tokens": ["Write", "data", "to", "the", "stack", "and", "decrement", "the", "stack", "pointer", "accordingly", "."], "nwo": "trailofbits/manticore", "score": 0.9483643694003796, "idx": 267458}
{"url": "https://github.com/jaraco/svg.charts/blob/23053497b3f1af4e760f355050107ae3bc05909d/svg/charts/graph.py#L263-L283", "sha": "23053497b3f1af4e760f355050107ae3bc05909d", "docstring_summary": "Calculate the margin in pixels below the plot area, setting\n\t\tborder_bottom.", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "7", "if", "arg_0", ".", "key", "and", "arg_0", ".", "key_position", "==", "'bottom'", ":", "arg_1", "+=", "len", "(", "arg_0", ".", "data", ")", "*", "(", "arg_0", ".", "font_size", "+", "5", ")", "arg_1", "+=", "10", "if", "arg_0", ".", "show_x_labels", ":", "arg_2", "=", "arg_0", ".", "x_label_font_size", "if", "arg_0", ".", "rotate_x_labels", ":", "arg_3", "=", "map", "(", "len", ",", "arg_0", ".", "get_x_labels", "(", ")", ")", "arg_4", "=", "functools", ".", "reduce", "(", "max", ",", "arg_3", ")", "arg_2", "*=", "0.6", "*", "arg_4", "arg_1", "+=", "arg_2", "if", "arg_0", ".", "stagger_x_labels", ":", "arg_1", "+=", "arg_2", "+", "10", "if", "arg_0", ".", "show_x_title", ":", "arg_1", "+=", "arg_0", ".", "x_title_font_size", "+", "5", "arg_0", ".", "border_bottom", "=", "arg_1"], "function": "def Func(arg_0):\n\t\t\"\"\"\n\t\tCalculate the margin in pixels below the plot area, setting\n\t\tborder_bottom.\n\t\t\"\"\"\n\t\targ_1 = 7\n\t\tif arg_0.key and arg_0.key_position == 'bottom':\n\t\t\targ_1 += len(arg_0.data) * (arg_0.font_size + 5)\n\t\t\targ_1 += 10\n\t\tif arg_0.show_x_labels:\n\t\t\targ_2 = arg_0.x_label_font_size\n\t\t\tif arg_0.rotate_x_labels:\n\t\t\t\targ_3 = map(len, arg_0.get_x_labels())\n\t\t\t\targ_4 = functools.reduce(max, arg_3)\n\t\t\t\targ_2 *= 0.6 * arg_4\n\t\t\targ_1 += arg_2\n\t\t\tif arg_0.stagger_x_labels:\n\t\t\t\targ_1 += arg_2 + 10\n\t\tif arg_0.show_x_title:\n\t\t\targ_1 += arg_0.x_title_font_size + 5\n\t\targ_0.border_bottom = arg_1", "path": "svg/charts/graph.py", "identifier": "Graph.calculate_bottom_margin", "docstring": "Calculate the margin in pixels below the plot area, setting\n\t\tborder_bottom.", "docstring_tokens": ["Calculate", "the", "margin", "in", "pixels", "below", "the", "plot", "area", "setting", "border_bottom", "."], "nwo": "jaraco/svg.charts", "score": 0.28766460361146773, "idx": 263618}
{"url": "https://github.com/gamechanger/dusty/blob/dc12de90bb6945023d6f43a8071e984313a1d984/dusty/compiler/spec_assembler.py#L152-L159", "sha": "dc12de90bb6945023d6f43a8071e984313a1d984", "docstring_summary": "This function takes an app or library name and will return the corresponding repo\n    for that app or library", "language": "python", "parameters": "(app_or_library_name)", "return_statement": "return Repo(repo_name)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "get_specs", "(", ")", "arg_2", "=", "arg_1", ".", "get_app_or_lib", "(", "arg_0", ")", "[", "'repo'", "]", "if", "not", "arg_2", ":", "return", "None", "return", "Repo", "(", "arg_2", ")"], "function": "def Func(arg_0):\n    \"\"\" This function takes an app or library name and will return the corresponding repo\n    for that app or library\"\"\"\n    arg_1 = get_specs()\n    arg_2 = arg_1.get_app_or_lib(arg_0)['repo']\n    if not arg_2:\n        return None\n    return Repo(arg_2)", "path": "dusty/compiler/spec_assembler.py", "identifier": "get_repo_of_app_or_library", "docstring": "This function takes an app or library name and will return the corresponding repo\n    for that app or library", "docstring_tokens": ["This", "function", "takes", "an", "app", "or", "library", "name", "and", "will", "return", "the", "corresponding", "repo", "for", "that", "app", "or", "library"], "nwo": "gamechanger/dusty", "score": 0.7406161721252564, "idx": 267551}
{"url": "https://github.com/kmpm/nodemcu-uploader/blob/557a25f37b1fb4e31a745719e237e42fff192834/nodemcu_uploader/main.py#L48-L72", "sha": "557a25f37b1fb4e31a745719e237e42fff192834", "docstring_summary": "The upload operation", "language": "python", "parameters": "(uploader, sources, verify, do_compile, do_file, do_restart)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ",", "arg_4", ",", "arg_5", ")", ":", "arg_1", ",", "arg_6", "=", "destination_from_source", "(", "arg_1", ")", "if", "len", "(", "arg_6", ")", "==", "len", "(", "arg_1", ")", ":", "if", "arg_0", ".", "prepare", "(", ")", ":", "for", "arg_7", ",", "arg_8", "in", "zip", "(", "arg_1", ",", "arg_6", ")", ":", "if", "arg_3", ":", "arg_0", ".", "file_remove", "(", "os", ".", "path", ".", "splitext", "(", "arg_8", ")", "[", "0", "]", "+", "'.lc'", ")", "arg_0", ".", "write_file", "(", "arg_7", ",", "arg_8", ",", "arg_2", ")", "if", "arg_3", "and", "arg_8", "!=", "'init.lua'", ":", "arg_0", ".", "file_compile", "(", "arg_8", ")", "arg_0", ".", "file_remove", "(", "arg_8", ")", "if", "arg_4", ":", "arg_0", ".", "file_do", "(", "os", ".", "path", ".", "splitext", "(", "arg_8", ")", "[", "0", "]", "+", "'.lc'", ")", "elif", "arg_4", ":", "arg_0", ".", "file_do", "(", "arg_8", ")", "else", ":", "raise", "Exception", "(", "'Error preparing nodemcu for reception'", ")", "else", ":", "raise", "Exception", "(", "'You must specify a destination filename for each file you want to upload.'", ")", "if", "arg_5", ":", "arg_0", ".", "node_restart", "(", ")", "log", ".", "info", "(", "'All done!'", ")"], "function": "def Func(arg_0, arg_1, arg_2, arg_3, arg_4, arg_5):\n    \"\"\"The upload operation\"\"\"\n    arg_1, arg_6 = destination_from_source(arg_1)\n    if len(arg_6) == len(arg_1):\n        if arg_0.prepare():\n            for arg_7, arg_8 in zip(arg_1, arg_6):\n                if arg_3:\n                    arg_0.file_remove(os.path.splitext(arg_8)[0]+'.lc')\n                arg_0.write_file(arg_7, arg_8, arg_2)\n                #init.lua is not allowed to be compiled\n                if arg_3 and arg_8 != 'init.lua':\n                    arg_0.file_compile(arg_8)\n                    arg_0.file_remove(arg_8)\n                    if arg_4:\n                        arg_0.file_do(os.path.splitext(arg_8)[0]+'.lc')\n                elif arg_4:\n                    arg_0.file_do(arg_8)\n        else:\n            raise Exception('Error preparing nodemcu for reception')\n    else:\n        raise Exception('You must specify a destination filename for each file you want to upload.')\n\n    if arg_5:\n        arg_0.node_restart()\n    log.info('All done!')", "path": "nodemcu_uploader/main.py", "identifier": "operation_upload", "docstring": "The upload operation", "docstring_tokens": ["The", "upload", "operation"], "nwo": "kmpm/nodemcu-uploader", "score": 0.3810531840267151, "idx": 262555}
{"url": "https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/setuptools/command/easy_install.py#L1528-L1555", "sha": "e86c2173ea386654f4ae061148e8fbe3f25e715c", "docstring_summary": "Write changed .pth file back to disk", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "if", "not", "arg_0", ".", "dirty", ":", "return", "arg_1", "=", "'\\n'", ".", "join", "(", "map", "(", "arg_0", ".", "make_relative", ",", "arg_0", ".", "paths", ")", ")", "if", "arg_1", ":", "log", ".", "debug", "(", "\"Saving %s\"", ",", "arg_0", ".", "filename", ")", "arg_1", "=", "(", "\"import sys; sys.__plen = len(sys.path)\\n\"", "\"%s\\n\"", "\"import sys; new=sys.path[sys.__plen:];\"", "\" del sys.path[sys.__plen:];\"", "\" p=getattr(sys,'__egginsert',0); sys.path[p:p]=new;\"", "\" sys.__egginsert = p+len(new)\\n\"", ")", "%", "arg_1", "if", "os", ".", "path", ".", "islink", "(", "arg_0", ".", "filename", ")", ":", "os", ".", "unlink", "(", "arg_0", ".", "filename", ")", "arg_2", "=", "open", "(", "arg_0", ".", "filename", ",", "'wt'", ")", "arg_2", ".", "write", "(", "arg_1", ")", "arg_2", ".", "close", "(", ")", "elif", "os", ".", "path", ".", "exists", "(", "arg_0", ".", "filename", ")", ":", "log", ".", "debug", "(", "\"Deleting empty %s\"", ",", "arg_0", ".", "filename", ")", "os", ".", "unlink", "(", "arg_0", ".", "filename", ")", "arg_0", ".", "dirty", "=", "False"], "function": "def Func(arg_0):\n        \"\"\"Write changed .pth file back to disk\"\"\"\n        if not arg_0.dirty:\n            return\n\n        arg_1 = '\\n'.join(map(arg_0.make_relative, arg_0.paths))\n        if arg_1:\n            log.debug(\"Saving %s\", arg_0.filename)\n            arg_1 = (\n                \"import sys; sys.__plen = len(sys.path)\\n\"\n                \"%s\\n\"\n                \"import sys; new=sys.path[sys.__plen:];\"\n                \" del sys.path[sys.__plen:];\"\n                \" p=getattr(sys,'__egginsert',0); sys.path[p:p]=new;\"\n                \" sys.__egginsert = p+len(new)\\n\"\n            ) % arg_1\n\n            if os.path.islink(arg_0.filename):\n                os.unlink(arg_0.filename)\n            arg_2 = open(arg_0.filename, 'wt')\n            arg_2.write(arg_1)\n            arg_2.close()\n\n        elif os.path.exists(arg_0.filename):\n            log.debug(\"Deleting empty %s\", arg_0.filename)\n            os.unlink(arg_0.filename)\n\n        arg_0.dirty = False", "path": "capybara/virtualenv/lib/python2.7/site-packages/setuptools/command/easy_install.py", "identifier": "PthDistributions.save", "docstring": "Write changed .pth file back to disk", "docstring_tokens": ["Write", "changed", ".", "pth", "file", "back", "to", "disk"], "nwo": "AkihikoITOH/capybara", "score": 0.24979334806965703, "idx": 278151}
{"url": "https://github.com/c-soft/satel_integra/blob/3b6d2020d1e10dc5aa40f30ee4ecc0f3a053eb3c/satel_integra/satel_integra.py#L12-L20", "sha": "3b6d2020d1e10dc5aa40f30ee4ecc0f3a053eb3c", "docstring_summary": "Function to calculate checksum as per Satel manual.", "language": "python", "parameters": "(command)", "return_statement": "return crc", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "0x147A", "for", "arg_2", "in", "arg_0", ":", "arg_1", "=", "(", "(", "arg_1", "<<", "1", ")", "&", "0xFFFF", ")", "|", "(", "arg_1", "&", "0x8000", ")", ">>", "15", "arg_1", "=", "arg_1", "^", "0xFFFF", "arg_1", "=", "(", "arg_1", "+", "(", "arg_1", ">>", "8", ")", "+", "arg_2", ")", "&", "0xFFFF", "return", "arg_1"], "function": "def Func(arg_0):\n    \"\"\"Function to calculate Func as per Satel manual.\"\"\"\n    arg_1 = 0x147A\n    for arg_2 in arg_0:\n        # rotate (crc 1 bit left)\n        arg_1 = ((arg_1 << 1) & 0xFFFF) | (arg_1 & 0x8000) >> 15\n        arg_1 = arg_1 ^ 0xFFFF\n        arg_1 = (arg_1 + (arg_1 >> 8) + arg_2) & 0xFFFF\n    return arg_1", "path": "satel_integra/satel_integra.py", "identifier": "checksum", "docstring": "Function to calculate checksum as per Satel manual.", "docstring_tokens": ["Function", "to", "calculate", "checksum", "as", "per", "Satel", "manual", "."], "nwo": "c-soft/satel_integra", "score": 0.683472553404196, "idx": 270920}
{"url": "https://github.com/mikeshultz/rawl/blob/818ebeabba5e051627d444c4849fde55947f94be/rawl/__init__.py#L354-L369", "sha": "818ebeabba5e051627d444c4849fde55947f94be", "docstring_summary": "Handle provided columns and if necessary, convert columns to a list for \n        internal strage.", "language": "python", "parameters": "(self, columns)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "if", "type", "(", "arg_1", ")", "==", "list", ":", "arg_0", ".", "columns", "=", "arg_1", "elif", "type", "(", "arg_1", ")", "==", "str", ":", "arg_0", ".", "columns", "=", "[", "c", ".", "strip", "(", ")", "for", "c", "in", "arg_1", ".", "split", "(", ")", "]", "elif", "type", "(", "arg_1", ")", "==", "IntEnum", ":", "arg_0", ".", "columns", "=", "[", "str", "(", "c", ")", "for", "c", "in", "arg_1", "]", "else", ":", "raise", "RawlException", "(", "\"Unknown format for columns\"", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\" \n        Handle provided columns and if necessary, convert columns to a list for \n        internal strage.\n\n        :columns: A sequence of columns for the table. Can be list, comma\n            -delimited string, or IntEnum.\n        \"\"\"\n        if type(arg_1) == list:\n            arg_0.columns = arg_1\n        elif type(arg_1) == str:\n            arg_0.columns = [c.strip() for c in arg_1.split()]\n        elif type(arg_1) == IntEnum:\n            arg_0.columns = [str(c) for c in arg_1]\n        else:\n            raise RawlException(\"Unknown format for columns\")", "path": "rawl/__init__.py", "identifier": "RawlBase.process_columns", "docstring": "Handle provided columns and if necessary, convert columns to a list for \n        internal strage.\n\n        :columns: A sequence of columns for the table. Can be list, comma\n            -delimited string, or IntEnum.", "docstring_tokens": ["Handle", "provided", "columns", "and", "if", "necessary", "convert", "columns", "to", "a", "list", "for", "internal", "strage", "."], "nwo": "mikeshultz/rawl", "score": 0.15726537023232431, "idx": 272846}
{"url": "https://github.com/worstcase/blockade/blob/3dc6ad803f0b0d56586dec9542a6a06aa06cf569/blockade/cli.py#L210-L214", "sha": "3dc6ad803f0b0d56586dec9542a6a06aa06cf569", "docstring_summary": "Kill some or all containers", "language": "python", "parameters": "(opts)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "arg_0", ".", "signal", "if", "hasattr", "(", "arg_0", ",", "'signal'", ")", "else", "\"SIGKILL\"", "__with_containers", "(", "arg_0", ",", "Blockade", ".", "kill", ",", "signal", "=", "arg_1", ")"], "function": "def Func(arg_0):\n    \"\"\"Kill some or all containers\n    \"\"\"\n    arg_1 = arg_0.signal if hasattr(arg_0, 'signal') else \"SIGKILL\"\n    __with_containers(arg_0, Blockade.kill, signal=arg_1)", "path": "blockade/cli.py", "identifier": "cmd_kill", "docstring": "Kill some or all containers", "docstring_tokens": ["Kill", "some", "or", "all", "containers"], "nwo": "worstcase/blockade", "score": 0.7770804820985606, "idx": 266471}
{"url": "https://github.com/thusoy/pwm/blob/fff7d755c34f3a7235a8bf217ffa2ff5aed4926f/pwm/core.py#L217-L233", "sha": "fff7d755c34f3a7235a8bf217ffa2ff5aed4926f", "docstring_summary": "Modify an existing domain.", "language": "python", "parameters": "(self, domain_name, new_salt=False, username=None)", "return_statement": "return domain", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "False", ",", "arg_3", "=", "None", ")", ":", "arg_4", "=", "arg_0", ".", "_get_domain_from_db", "(", "arg_1", ")", "if", "arg_4", "is", "None", ":", "raise", "NoSuchDomainException", "if", "arg_2", ":", "_logger", ".", "info", "(", "\"Generating new salt..\"", ")", "arg_4", ".", "new_salt", "(", ")", "if", "arg_3", "is", "not", "None", ":", "arg_4", ".", "username", "=", "arg_3", "return", "arg_4"], "function": "def Func(arg_0, arg_1, arg_2=False, arg_3=None):\n        \"\"\" Modify an existing domain.\n\n        :param domain_name: The name of the domain to modify.\n        :param new_salt: Whether to generate a new salt for the domain.\n        :param username: If given, change domain username to this value.\n        :returns: The modified :class:`Domain <pwm.core.Domain>` object.\n        \"\"\"\n        arg_4 = arg_0._get_domain_from_db(arg_1)\n        if arg_4 is None:\n            raise NoSuchDomainException\n        if arg_2:\n            _logger.info(\"Generating new salt..\")\n            arg_4.new_salt()\n        if arg_3 is not None:\n            arg_4.username = arg_3\n        return arg_4", "path": "pwm/core.py", "identifier": "PWM.modify_domain", "docstring": "Modify an existing domain.\n\n        :param domain_name: The name of the domain to modify.\n        :param new_salt: Whether to generate a new salt for the domain.\n        :param username: If given, change domain username to this value.\n        :returns: The modified :class:`Domain <pwm.core.Domain>` object.", "docstring_tokens": ["Modify", "an", "existing", "domain", "."], "nwo": "thusoy/pwm", "score": 0.15726537023232431, "idx": 264672}
{"url": "https://github.com/uogbuji/amara3-xml/blob/88c18876418cffc89bb85b4a3193e5002b6b39a6/pylib/uxml/uxpath/functions.py#L281-L298", "sha": "88c18876418cffc89bb85b4a3193e5002b6b39a6", "docstring_summary": "Yields the result of applying an expression to each item in the input sequence.", "language": "python", "parameters": "(ctx, seq, expr)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "from", ".", "import", "context", ",", "parse", "as", "uxpathparse", "if", "hasattr", "(", "arg_1", ",", "'compute'", ")", ":", "arg_1", "=", "arg_1", ".", "compute", "(", "arg_0", ")", "arg_2", "=", "next", "(", "string_arg", "(", "arg_0", ",", "arg_2", ")", ",", "''", ")", "arg_3", "=", "uxpathparse", "(", "arg_2", ")", "for", "arg_4", "in", "arg_1", ":", "arg_5", "=", "arg_0", ".", "copy", "(", "arg_4", "=", "arg_4", ")", "yield", "from", "arg_3", ".", "compute", "(", "arg_5", ")"], "function": "def Func(arg_0, arg_1, arg_2):\n    '''\n    Yields the result of applying an expression to each item in the input sequence.\n\n    * seq: input sequence\n    * expr: expression to be converted to string, then dynamically evaluated for each item on the sequence to produce the result\n    '''\n    from . import context, parse as uxpathparse\n\n    if hasattr(arg_1, 'compute'):\n        arg_1 = arg_1.compute(arg_0)\n\n    arg_2 = next(string_arg(arg_0, arg_2), '')\n\n    arg_3 = uxpathparse(arg_2)\n    for arg_4 in arg_1:\n        arg_5 = arg_0.copy(arg_4=arg_4)\n        yield from arg_3.compute(arg_5)", "path": "pylib/uxml/uxpath/functions.py", "identifier": "foreach_", "docstring": "Yields the result of applying an expression to each item in the input sequence.\n\n    * seq: input sequence\n    * expr: expression to be converted to string, then dynamically evaluated for each item on the sequence to produce the result", "docstring_tokens": ["Yields", "the", "result", "of", "applying", "an", "expression", "to", "each", "item", "in", "the", "input", "sequence", "."], "nwo": "uogbuji/amara3-xml", "score": 0.16246995141409282, "idx": 279938}
{"url": "https://github.com/nephics/mat4py/blob/6c1a2ad903937437cc5f24f3c3f5aa2c5a77a1c1/mat4py/loadmat.py#L286-L302", "sha": "6c1a2ad903937437cc5f24f3c3f5aa2c5a77a1c1", "docstring_summary": "Read a cell array.\n    Returns an array with rows of the cell array.", "language": "python", "parameters": "(fd, endian, header)", "return_statement": "return squeeze(array)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "arg_3", "=", "[", "list", "(", ")", "for", "i", "in", "range", "(", "arg_2", "[", "'dims'", "]", "[", "0", "]", ")", "]", "for", "arg_4", "in", "range", "(", "arg_2", "[", "'dims'", "]", "[", "0", "]", ")", ":", "for", "arg_5", "in", "range", "(", "arg_2", "[", "'dims'", "]", "[", "1", "]", ")", ":", "arg_6", ",", "arg_7", ",", "arg_8", "=", "read_var_header", "(", "arg_0", ",", "arg_1", ")", "arg_9", "=", "read_var_array", "(", "arg_8", ",", "arg_1", ",", "arg_6", ")", "arg_3", "[", "arg_4", "]", ".", "append", "(", "arg_9", ")", "arg_0", ".", "seek", "(", "arg_7", ")", "if", "arg_2", "[", "'dims'", "]", "[", "0", "]", "==", "1", ":", "return", "squeeze", "(", "arg_3", "[", "0", "]", ")", "return", "squeeze", "(", "arg_3", ")"], "function": "def Func(arg_0, arg_1, arg_2):\n    \"\"\"Read a cell array.\n    Returns an array with rows of the cell array.\n    \"\"\"\n    arg_3 = [list() for i in range(arg_2['dims'][0])]\n    for arg_4 in range(arg_2['dims'][0]):\n        for arg_5 in range(arg_2['dims'][1]):\n            # read the matrix header and array\n            arg_6, arg_7, arg_8 = read_var_header(arg_0, arg_1)\n            arg_9 = read_var_array(arg_8, arg_1, arg_6)\n            arg_3[arg_4].append(arg_9)\n            # move on to next field\n            arg_0.seek(arg_7)\n    # pack and return the array\n    if arg_2['dims'][0] == 1:\n        return squeeze(arg_3[0])\n    return squeeze(arg_3)", "path": "mat4py/loadmat.py", "identifier": "read_cell_array", "docstring": "Read a cell array.\n    Returns an array with rows of the cell array.", "docstring_tokens": ["Read", "a", "cell", "array", ".", "Returns", "an", "array", "with", "rows", "of", "the", "cell", "array", "."], "nwo": "nephics/mat4py", "score": 0.3187018950262521, "idx": 267402}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/zmq/session.py#L494-L586", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "Build and send a message via stream or socket.", "language": "python", "parameters": "(self, stream, msg_or_type, content=None, parent=None, ident=None,\n             buffers=None, subheader=None, track=False, header=None)", "return_statement": "return msg", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", "=", "None", ",", "arg_4", "=", "None", ",", "arg_5", "=", "None", ",", "arg_6", "=", "None", ",", "arg_7", "=", "None", ",", "arg_8", "=", "False", ",", "arg_9", "=", "None", ")", ":", "if", "not", "isinstance", "(", "arg_1", ",", "(", "zmq", ".", "Socket", ",", "ZMQStream", ")", ")", ":", "raise", "TypeError", "(", "\"stream must be Socket or ZMQStream, not %r\"", "%", "type", "(", "arg_1", ")", ")", "elif", "arg_8", "and", "isinstance", "(", "arg_1", ",", "ZMQStream", ")", ":", "raise", "TypeError", "(", "\"ZMQStream cannot track messages\"", ")", "if", "isinstance", "(", "arg_2", ",", "(", "Message", ",", "dict", ")", ")", ":", "arg_10", "=", "arg_2", "else", ":", "arg_10", "=", "arg_0", ".", "msg", "(", "arg_2", ",", "arg_3", "=", "arg_3", ",", "arg_4", "=", "arg_4", ",", "arg_7", "=", "arg_7", ",", "arg_9", "=", "arg_9", ")", "arg_6", "=", "[", "]", "if", "arg_6", "is", "None", "else", "arg_6", "arg_11", "=", "arg_0", ".", "serialize", "(", "arg_10", ",", "arg_5", ")", "arg_12", "=", "0", "if", "arg_6", ":", "arg_12", "=", "zmq", ".", "SNDMORE", "arg_13", "=", "False", "else", ":", "arg_13", "=", "arg_8", "if", "arg_8", ":", "arg_14", "=", "arg_1", ".", "Func_multipart", "(", "arg_11", ",", "arg_12", ",", "copy", "=", "False", ",", "arg_8", "=", "arg_13", ")", "else", ":", "arg_14", "=", "arg_1", ".", "Func_multipart", "(", "arg_11", ",", "arg_12", ",", "copy", "=", "False", ")", "for", "arg_15", "in", "arg_6", "[", ":", "-", "1", "]", ":", "arg_1", ".", "Func", "(", "arg_15", ",", "arg_12", ",", "copy", "=", "False", ")", "if", "arg_6", ":", "if", "arg_8", ":", "arg_14", "=", "arg_1", ".", "Func", "(", "arg_6", "[", "-", "1", "]", ",", "copy", "=", "False", ",", "arg_8", "=", "arg_8", ")", "else", ":", "arg_14", "=", "arg_1", ".", "Func", "(", "arg_6", "[", "-", "1", "]", ",", "copy", "=", "False", ")", "if", "arg_0", ".", "debug", ":", "pprint", ".", "pprint", "(", "arg_10", ")", "pprint", ".", "pprint", "(", "arg_11", ")", "pprint", ".", "pprint", "(", "arg_6", ")", "arg_10", "[", "'tracker'", "]", "=", "arg_14", "return", "arg_10"], "function": "def Func(arg_0, arg_1, arg_2, arg_3=None, arg_4=None, arg_5=None,\n             arg_6=None, arg_7=None, arg_8=False, arg_9=None):\n        \"\"\"Build and Func a message via stream or socket.\n\n        The message format used by this function internally is as follows:\n\n        [ident1,ident2,...,DELIM,HMAC,p_header,p_parent,p_content,\n         buffer1,buffer2,...]\n\n        The serialize/unserialize methods convert the nested message dict into this\n        format.\n\n        Parameters\n        ----------\n\n        stream : zmq.Socket or ZMQStream\n            The socket-like object used to Func the data.\n        msg_or_type : str or Message/dict\n            Normally, msg_or_type will be a msg_type unless a message is being\n            sent more than once. If a header is supplied, this can be set to\n            None and the msg_type will be pulled from the header.\n\n        content : dict or None\n            The content of the message (ignored if msg_or_type is a message).\n        header : dict or None\n            The header dict for the message (ignores if msg_to_type is a message).\n        parent : Message or dict or None\n            The parent or parent header describing the parent of this message\n            (ignored if msg_or_type is a message).\n        ident : bytes or list of bytes\n            The zmq.IDENTITY routing path.\n        subheader : dict or None\n            Extra header keys for this message's header (ignored if msg_or_type\n            is a message).\n        buffers : list or None\n            The already-serialized buffers to be appended to the message.\n        track : bool\n            Whether to track.  Only for use with Sockets, because ZMQStream\n            objects cannot track messages.\n\n        Returns\n        -------\n        msg : dict\n            The constructed message.\n        (msg,tracker) : (dict, MessageTracker)\n            if track=True, then a 2-tuple will be returned,\n            the first element being the constructed\n            message, and the second being the MessageTracker\n\n        \"\"\"\n\n        if not isinstance(arg_1, (zmq.Socket, ZMQStream)):\n            raise TypeError(\"stream must be Socket or ZMQStream, not %r\"%type(arg_1))\n        elif arg_8 and isinstance(arg_1, ZMQStream):\n            raise TypeError(\"ZMQStream cannot track messages\")\n\n        if isinstance(arg_2, (Message, dict)):\n            # We got a Message or message dict, not a msg_type so don't\n            # build a new Message.\n            arg_10 = arg_2\n        else:\n            arg_10 = arg_0.msg(arg_2, arg_3=arg_3, arg_4=arg_4,\n                           arg_7=arg_7, arg_9=arg_9)\n\n        arg_6 = [] if arg_6 is None else arg_6\n        arg_11 = arg_0.serialize(arg_10, arg_5)\n        arg_12 = 0\n        if arg_6:\n            arg_12 = zmq.SNDMORE\n            arg_13 = False\n        else:\n            arg_13=arg_8\n        if arg_8:\n            arg_14 = arg_1.Func_multipart(arg_11, arg_12, copy=False, arg_8=arg_13)\n        else:\n            arg_14 = arg_1.Func_multipart(arg_11, arg_12, copy=False)\n        for arg_15 in arg_6[:-1]:\n            arg_1.Func(arg_15, arg_12, copy=False)\n        if arg_6:\n            if arg_8:\n                arg_14 = arg_1.Func(arg_6[-1], copy=False, arg_8=arg_8)\n            else:\n                arg_14 = arg_1.Func(arg_6[-1], copy=False)\n\n        # omsg = Message(msg)\n        if arg_0.debug:\n            pprint.pprint(arg_10)\n            pprint.pprint(arg_11)\n            pprint.pprint(arg_6)\n\n        arg_10['tracker'] = arg_14\n\n        return arg_10", "path": "environment/lib/python2.7/site-packages/IPython/zmq/session.py", "identifier": "Session.send", "docstring": "Build and send a message via stream or socket.\n\n        The message format used by this function internally is as follows:\n\n        [ident1,ident2,...,DELIM,HMAC,p_header,p_parent,p_content,\n         buffer1,buffer2,...]\n\n        The serialize/unserialize methods convert the nested message dict into this\n        format.\n\n        Parameters\n        ----------\n\n        stream : zmq.Socket or ZMQStream\n            The socket-like object used to send the data.\n        msg_or_type : str or Message/dict\n            Normally, msg_or_type will be a msg_type unless a message is being\n            sent more than once. If a header is supplied, this can be set to\n            None and the msg_type will be pulled from the header.\n\n        content : dict or None\n            The content of the message (ignored if msg_or_type is a message).\n        header : dict or None\n            The header dict for the message (ignores if msg_to_type is a message).\n        parent : Message or dict or None\n            The parent or parent header describing the parent of this message\n            (ignored if msg_or_type is a message).\n        ident : bytes or list of bytes\n            The zmq.IDENTITY routing path.\n        subheader : dict or None\n            Extra header keys for this message's header (ignored if msg_or_type\n            is a message).\n        buffers : list or None\n            The already-serialized buffers to be appended to the message.\n        track : bool\n            Whether to track.  Only for use with Sockets, because ZMQStream\n            objects cannot track messages.\n\n        Returns\n        -------\n        msg : dict\n            The constructed message.\n        (msg,tracker) : (dict, MessageTracker)\n            if track=True, then a 2-tuple will be returned,\n            the first element being the constructed\n            message, and the second being the MessageTracker", "docstring_tokens": ["Build", "and", "send", "a", "message", "via", "stream", "or", "socket", "."], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 269480}
{"url": "https://github.com/dougalsutherland/skl-groups/blob/2584c10a413626c6d5f9078cdbf3dcc84e4e9a5b/skl_groups/kernels/mmk.py#L72-L84", "sha": "2584c10a413626c6d5f9078cdbf3dcc84e4e9a5b", "docstring_summary": "Specify the data to which kernel values should be computed.", "language": "python", "parameters": "(self, X, y=None)", "return_statement": "return self", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "None", ")", ":", "arg_0", ".", "features_", "=", "as_features", "(", "arg_1", ",", "stack", "=", "True", ",", "bare", "=", "True", ")", "return", "arg_0"], "function": "def Func(arg_0, arg_1, arg_2=None):\n        '''\n        Specify the data to which kernel values should be computed.\n\n        Parameters\n        ----------\n        X : list of arrays or :class:`skl_groups.features.Features`\n            The bags to compute \"to\".\n        '''\n        arg_0.features_ = as_features(arg_1, stack=True, bare=True)\n        # TODO: could precompute things like squared norms if kernel == \"rbf\".\n        # Probably should add support to sklearn instead of hacking it here.\n        return arg_0", "path": "skl_groups/kernels/mmk.py", "identifier": "MeanMapKernel.fit", "docstring": "Specify the data to which kernel values should be computed.\n\n        Parameters\n        ----------\n        X : list of arrays or :class:`skl_groups.features.Features`\n            The bags to compute \"to\".", "docstring_tokens": ["Specify", "the", "data", "to", "which", "kernel", "values", "should", "be", "computed", "."], "nwo": "dougalsutherland/skl-groups", "score": 0.1940526577236167, "idx": 269682}
{"url": "https://github.com/rossengeorgiev/aprs-python/blob/94b89a6da47a322129484efcaf1e82f6a9932891/aprslib/inet.py#L221-L263", "sha": "94b89a6da47a322129484efcaf1e82f6a9932891", "docstring_summary": "Attemps connection to the server", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_0", ".", "logger", ".", "info", "(", "\"Attempting connection to %s:%s\"", ",", "arg_0", ".", "server", "[", "0", "]", ",", "arg_0", ".", "server", "[", "1", "]", ")", "try", ":", "arg_0", ".", "_open_socket", "(", ")", "arg_1", "=", "arg_0", ".", "sock", ".", "getpeername", "(", ")", "arg_0", ".", "logger", ".", "info", "(", "\"Connected to %s\"", ",", "str", "(", "arg_1", ")", ")", "arg_0", ".", "sock", ".", "setblocking", "(", "1", ")", "arg_0", ".", "sock", ".", "settimeout", "(", "5", ")", "arg_0", ".", "sock", ".", "setsockopt", "(", "socket", ".", "SOL_SOCKET", ",", "socket", ".", "SO_KEEPALIVE", ",", "1", ")", "arg_2", "=", "arg_0", ".", "sock", ".", "recv", "(", "512", ")", "if", "is_py3", ":", "arg_2", "=", "arg_2", ".", "decode", "(", "'latin-1'", ")", "if", "arg_2", "[", "0", "]", "==", "\"#\"", ":", "arg_0", ".", "logger", ".", "debug", "(", "\"Banner: %s\"", ",", "arg_2", ".", "rstrip", "(", ")", ")", "else", ":", "raise", "ConnectionError", "(", "\"invalid banner from server\"", ")", "except", "ConnectionError", "as", "e", ":", "arg_0", ".", "logger", ".", "error", "(", "str", "(", "e", ")", ")", "arg_0", ".", "close", "(", ")", "raise", "except", "(", "socket", ".", "error", ",", "socket", ".", "timeout", ")", "as", "e", ":", "arg_0", ".", "close", "(", ")", "arg_0", ".", "logger", ".", "error", "(", "\"Socket error: %s\"", "%", "str", "(", "e", ")", ")", "if", "str", "(", "e", ")", "==", "\"timed out\"", ":", "raise", "ConnectionError", "(", "\"no banner from server\"", ")", "else", ":", "raise", "ConnectionError", "(", "e", ")", "arg_0", ".", "Funced", "=", "True"], "function": "def Func(arg_0):\n        \"\"\"\n        Attemps connection to the server\n        \"\"\"\n\n        arg_0.logger.info(\"Attempting connection to %s:%s\", arg_0.server[0], arg_0.server[1])\n\n        try:\n            arg_0._open_socket()\n\n            arg_1 = arg_0.sock.getpeername()\n\n            arg_0.logger.info(\"Connected to %s\", str(arg_1))\n\n            # 5 second timeout to receive server banner\n            arg_0.sock.setblocking(1)\n            arg_0.sock.settimeout(5)\n\n            arg_0.sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n\n            arg_2 = arg_0.sock.recv(512)\n            if is_py3:\n                arg_2 = arg_2.decode('latin-1')\n\n            if arg_2[0] == \"#\":\n                arg_0.logger.debug(\"Banner: %s\", arg_2.rstrip())\n            else:\n                raise ConnectionError(\"invalid banner from server\")\n\n        except ConnectionError as e:\n            arg_0.logger.error(str(e))\n            arg_0.close()\n            raise\n        except (socket.error, socket.timeout) as e:\n            arg_0.close()\n\n            arg_0.logger.error(\"Socket error: %s\" % str(e))\n            if str(e) == \"timed out\":\n                raise ConnectionError(\"no banner from server\")\n            else:\n                raise ConnectionError(e)\n\n        arg_0.Funced = True", "path": "aprslib/inet.py", "identifier": "IS._connect", "docstring": "Attemps connection to the server", "docstring_tokens": ["Attemps", "connection", "to", "the", "server"], "nwo": "rossengeorgiev/aprs-python", "score": 0.3643830340421162, "idx": 271360}
{"url": "https://github.com/jhermann/rituals/blob/1534f50d81e19bbbe799e2eba0acdefbce047c06/src/rituals/acts/documentation.py#L279-L293", "sha": "1534f50d81e19bbbe799e2eba0acdefbce047c06", "docstring_summary": "Provide a zipped stream of the docs tree.", "language": "python", "parameters": "(self, docs_base)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "with", "pushd", "(", "arg_1", ")", ":", "with", "tempfile", ".", "NamedTemporaryFile", "(", "prefix", "=", "'pythonhosted-'", ",", "delete", "=", "False", ")", "as", "ziphandle", ":", "pass", "arg_2", "=", "shutil", ".", "make_archive", "(", "ziphandle", ".", "name", ",", "'zip'", ")", "notify", ".", "info", "(", "\"Uploading {:.1f} MiB from '{}' to '{}'...\"", ".", "format", "(", "os", ".", "path", ".", "getsize", "(", "arg_2", ")", "/", "1024.0", ",", "arg_2", ",", "arg_0", ".", "target", ")", ")", "with", "io", ".", "open", "(", "arg_2", ",", "'rb'", ")", "as", "zipread", ":", "try", ":", "yield", "zipread", "finally", ":", "os", ".", "remove", "(", "ziphandle", ".", "name", ")", "os", ".", "remove", "(", "ziphandle", ".", "name", "+", "'.zip'", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\" Provide a zipped stream of the docs tree.\"\"\"\n        with pushd(arg_1):\n            with tempfile.NamedTemporaryFile(prefix='pythonhosted-', delete=False) as ziphandle:\n                pass\n            arg_2 = shutil.make_archive(ziphandle.name, 'zip')\n\n        notify.info(\"Uploading {:.1f} MiB from '{}' to '{}'...\"\n                    .format(os.path.getsize(arg_2) / 1024.0, arg_2, arg_0.target))\n        with io.open(arg_2, 'rb') as zipread:\n            try:\n                yield zipread\n            finally:\n                os.remove(ziphandle.name)\n                os.remove(ziphandle.name + '.zip')", "path": "src/rituals/acts/documentation.py", "identifier": "DocsUploader._zipped", "docstring": "Provide a zipped stream of the docs tree.", "docstring_tokens": ["Provide", "a", "zipped", "stream", "of", "the", "docs", "tree", "."], "nwo": "jhermann/rituals", "score": 0.3756179881544838, "idx": 277735}
{"url": "https://github.com/nirum/descent/blob/074c8452f15a0da638668a4fe139fde06ccfae7f/descent/proxops.py#L251-L259", "sha": "074c8452f15a0da638668a4fe139fde06ccfae7f", "docstring_summary": "Applies a proximal operator to the columns of a matrix", "language": "python", "parameters": "(x, rho, proxop)", "return_statement": "return xnext", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "arg_3", "=", "np", ".", "zeros_like", "(", "arg_0", ")", "for", "arg_4", "in", "range", "(", "arg_0", ".", "shape", "[", "1", "]", ")", ":", "arg_3", "[", ":", ",", "arg_4", "]", "=", "arg_2", "(", "arg_0", "[", ":", ",", "arg_4", "]", ",", "arg_1", ")", "return", "arg_3"], "function": "def Func(arg_0, arg_1, arg_2):\n    \"\"\"Applies a proximal operator to the Func of a matrix\"\"\"\n\n    arg_3 = np.zeros_like(arg_0)\n\n    for arg_4 in range(arg_0.shape[1]):\n        arg_3[:, arg_4] = arg_2(arg_0[:, arg_4], arg_1)\n\n    return arg_3", "path": "descent/proxops.py", "identifier": "columns", "docstring": "Applies a proximal operator to the columns of a matrix", "docstring_tokens": ["Applies", "a", "proximal", "operator", "to", "the", "columns", "of", "a", "matrix"], "nwo": "nirum/descent", "score": 0.18112697196067942, "idx": 278107}
{"url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L861-L881", "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "docstring_summary": "Write one log file into the summary text file.", "language": "python", "parameters": "(fhandle,file2read)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "if", "os", ".", "path", ".", "isfile", "(", "arg_1", ")", ":", "with", "open", "(", "arg_1", ",", "'r'", ")", "as", "tfile", ":", "arg_0", ".", "write", "(", "'============ Content of '", "+", "arg_1", ")", "arg_0", ".", "write", "(", "'\\n'", ")", "arg_0", ".", "write", "(", "tfile", ".", "read", "(", ")", ")", "arg_0", ".", "write", "(", "'\\n\\n'", ")"], "function": "def Func(arg_0,arg_1):\n    \"\"\"\n    Write one log file into the summary text file.\n\n    Parameters\n    ----------\n    fhandle :  Python file handle\n        file handle to the summary text file\n    file2read : Python file handle\n        file handle to log file where we want to add its content to the summary text file.\n\n    :return: none\n    \"\"\"\n    if os.path.isfile(arg_1):\n\n        # write summary of failed tests logs\n        with open(arg_1,'r') as tfile:\n            arg_0.write('============ Content of '+ arg_1)\n            arg_0.write('\\n')\n            arg_0.write(tfile.read())\n            arg_0.write('\\n\\n')", "path": "scripts/logscrapedaily.py", "identifier": "write_file_content", "docstring": "Write one log file into the summary text file.\n\n    Parameters\n    ----------\n    fhandle :  Python file handle\n        file handle to the summary text file\n    file2read : Python file handle\n        file handle to log file where we want to add its content to the summary text file.\n\n    :return: none", "docstring_tokens": ["Write", "one", "log", "file", "into", "the", "summary", "text", "file", "."], "nwo": "h2oai/h2o-3", "score": 0.9922845645433422, "idx": 274777}
{"url": "https://github.com/vpelletier/python-libaio/blob/5b5a2fed5418e2bd1ac9197fa46c69dae86c6fe3/libaio/__init__.py#L221-L232", "sha": "5b5a2fed5418e2bd1ac9197fa46c69dae86c6fe3", "docstring_summary": "The buffer list this instance operates on.", "language": "python", "parameters": "(self)", "return_statement": "return self._buffer_list", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "if", "arg_0", ".", "_iocb", ".", "aio_lio_opcode", "==", "libaio", ".", "IO_CMD_POLL", ":", "raise", "AttributeError", "return", "arg_0", ".", "_Func"], "function": "def Func(arg_0):\n        \"\"\"\n        The buffer list this instance operates on.\n\n        Only available in mode != AIOBLOCK_MODE_POLL.\n\n        Changes on a submitted transfer are not fully applied until its\n        next submission: kernel will still be using original buffer list.\n        \"\"\"\n        if arg_0._iocb.aio_lio_opcode == libaio.IO_CMD_POLL:\n            raise AttributeError\n        return arg_0._Func", "path": "libaio/__init__.py", "identifier": "AIOBlock.buffer_list", "docstring": "The buffer list this instance operates on.\n\n        Only available in mode != AIOBLOCK_MODE_POLL.\n\n        Changes on a submitted transfer are not fully applied until its\n        next submission: kernel will still be using original buffer list.", "docstring_tokens": ["The", "buffer", "list", "this", "instance", "operates", "on", "."], "nwo": "vpelletier/python-libaio", "score": 0.18579120894425885, "idx": 263928}
{"url": "https://github.com/LLNL/scraper/blob/881a316e4c04dfa5a9cf491b7c7f9f997a7c56ea/scripts/github_stats.py#L535-L550", "sha": "881a316e4c04dfa5a9cf491b7c7f9f997a7c56ea", "docstring_summary": "Removes all rows of the associated date from the given csv file.\n        Defaults to today.", "language": "python", "parameters": "(self, file_path='', date=str(datetime.date.today()))", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "''", ",", "arg_2", "=", "arg_3", "(", "arg_4", ".", "date", ".", "today", "(", ")", ")", ")", ":", "arg_6", "=", "os", ".", "path", ".", "isfile", "(", "arg_1", ")", "if", "arg_6", ":", "with", "open", "(", "arg_1", ",", "'rb'", ")", "as", "inp", ",", "open", "(", "'temp.csv'", ",", "'wb'", ")", "as", "out", ":", "arg_7", "=", "csv", ".", "writer", "(", "out", ")", "for", "arg_8", "in", "csv", ".", "reader", "(", "inp", ")", ":", "if", "arg_8", "[", "0", "]", "!=", "arg_2", ":", "arg_7", ".", "writerow", "(", "arg_8", ")", "inp", ".", "close", "(", ")", "out", ".", "close", "(", ")", "os", ".", "remove", "(", "arg_1", ")", "os", ".", "rename", "(", "\"temp.csv\"", ",", "arg_1", ")"], "function": "def Func(arg_0, arg_1='', arg_2=arg_3(arg_4.date.today())):\n        \"\"\"\n        Removes all rows of the associated date from the given csv file.\n        Defaults to today.\n        \"\"\"\n        arg_6 = os.path.isfile(arg_1)\n        if arg_6:\n            with open(arg_1, 'rb') as inp, open('temp.csv', 'wb') as out:\n                arg_7 = csv.writer(out)\n                for arg_8 in csv.reader(inp):\n                    if arg_8[0] != arg_2:\n                        arg_7.writerow(arg_8)\n            inp.close()\n            out.close()\n            os.remove(arg_1)\n            os.rename(\"temp.csv\",arg_1)", "path": "scripts/github_stats.py", "identifier": "GitHub_LLNL_Stats.remove_date", "docstring": "Removes all rows of the associated date from the given csv file.\n        Defaults to today.", "docstring_tokens": ["Removes", "all", "rows", "of", "the", "associated", "date", "from", "the", "given", "csv", "file", ".", "Defaults", "to", "today", "."], "nwo": "LLNL/scraper", "score": 0.5080454153836005, "idx": 277106}
{"url": "https://github.com/Parsl/parsl/blob/d7afb3bc37f50dcf224ae78637944172edb35dac/parsl/app/app.py#L78-L116", "sha": "d7afb3bc37f50dcf224ae78637944172edb35dac", "docstring_summary": "The App decorator function.", "language": "python", "parameters": "(apptype, data_flow_kernel=None, walltime=60, cache=False, executors='all')", "return_statement": "return wrapper", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ",", "arg_2", "=", "60", ",", "arg_3", "=", "False", ",", "arg_4", "=", "'all'", ")", ":", "from", "parsl", ".", "app", ".", "python", "import", "PythonFunc", "from", "parsl", ".", "app", ".", "bash", "import", "BashFunc", "logger", ".", "warning", "(", "\"The 'Func' decorator will be deprecated in Parsl 0.8. Please use 'python_app' or 'bash_app' instead.\"", ")", "if", "arg_0", "==", "'python'", ":", "arg_5", "=", "PythonFunc", "elif", "arg_0", "==", "'bash'", ":", "arg_5", "=", "BashFunc", "else", ":", "raise", "InvalidFuncTypeError", "(", "\"Invalid apptype requested {}; must be 'python' or 'bash'\"", ".", "format", "(", "arg_0", ")", ")", "def", "wrapper", "(", "arg_6", ")", ":", "return", "arg_5", "(", "arg_6", ",", "arg_1", "=", "arg_1", ",", "arg_2", "=", "arg_2", ",", "arg_3", "=", "arg_3", ",", "arg_4", "=", "arg_4", ")", "return", "wrapper"], "function": "def Func(arg_0, arg_1=None, arg_2=60, arg_3=False, arg_4='all'):\n    \"\"\"The Func decorator function.\n\n    Args:\n        - apptype (string) : Functype can be bash|python\n\n    Kwargs:\n        - data_flow_kernel (DataFlowKernel): The :class:`~parsl.dataflow.dflow.DataFlowKernel` responsible for\n          managing this app. This can be omitted only\n          after calling :meth:`parsl.dataflow.dflow.DataFlowKernelLoader.load`.\n        - walltime (int) : Walltime for app in seconds,\n             default=60\n        - executors (str|list) : Labels of the executors that this app can execute over. Default is 'all'.\n        - cache (Bool) : Enable caching of the app call\n             default=False\n\n    Returns:\n         A PythonFunc or BashFunc object, which when called runs the apps through the executor.\n    \"\"\"\n\n    from parsl.app.python import PythonFunc\n    from parsl.app.bash import BashFunc\n\n    logger.warning(\"The 'Func' decorator will be deprecated in Parsl 0.8. Please use 'python_app' or 'bash_app' instead.\")\n\n    if arg_0 == 'python':\n        arg_5 = PythonFunc\n    elif arg_0 == 'bash':\n        arg_5 = BashFunc\n    else:\n        raise InvalidFuncTypeError(\"Invalid apptype requested {}; must be 'python' or 'bash'\".format(arg_0))\n\n    def wrapper(arg_6):\n        return arg_5(arg_6,\n                         arg_1=arg_1,\n                         arg_2=arg_2,\n                         arg_3=arg_3,\n                         arg_4=arg_4)\n    return wrapper", "path": "parsl/app/app.py", "identifier": "App", "docstring": "The App decorator function.\n\n    Args:\n        - apptype (string) : Apptype can be bash|python\n\n    Kwargs:\n        - data_flow_kernel (DataFlowKernel): The :class:`~parsl.dataflow.dflow.DataFlowKernel` responsible for\n          managing this app. This can be omitted only\n          after calling :meth:`parsl.dataflow.dflow.DataFlowKernelLoader.load`.\n        - walltime (int) : Walltime for app in seconds,\n             default=60\n        - executors (str|list) : Labels of the executors that this app can execute over. Default is 'all'.\n        - cache (Bool) : Enable caching of the app call\n             default=False\n\n    Returns:\n         A PythonApp or BashApp object, which when called runs the apps through the executor.", "docstring_tokens": ["The", "App", "decorator", "function", "."], "nwo": "Parsl/parsl", "score": 0.8824753515365124, "idx": 261786}
{"url": "https://github.com/inspirehep/harvesting-kit/blob/33a7f8aa9dade1d863110c6d8b27dfd955cb471f/harvestingkit/bibrecord.py#L227-L297", "sha": "33a7f8aa9dade1d863110c6d8b27dfd955cb471f", "docstring_summary": "Create a record object from the marcxml description.", "language": "python", "parameters": "(marcxml=None, verbose=CFG_BIBRECORD_DEFAULT_VERBOSE_LEVEL,\n                  correct=CFG_BIBRECORD_DEFAULT_CORRECT, parser='',\n                  sort_fields_by_indicators=False,\n                  keep_singletons=CFG_BIBRECORD_KEEP_SINGLETONS)", "return_statement": "return (rec, int(not errs), errs)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", "=", "None", ",", "arg_1", "=", "arg_2", ",", "arg_3", "=", "arg_4", ",", "arg_5", "=", "''", ",", "arg_6", "=", "False", ",", "arg_7", "=", "arg_8", ")", ":", "if", "arg_0", "is", "None", ":", "return", "{", "}", "try", ":", "arg_9", "=", "_Func_lxml", "(", "arg_0", ",", "arg_1", ",", "arg_3", ",", "arg_7", "=", "arg_7", ")", "except", "InvenioBibRecordParserError", "as", "ex1", ":", "return", "(", "None", ",", "0", ",", "str", "(", "ex1", ")", ")", "if", "arg_6", ":", "_record_sort_by_indicators", "(", "arg_9", ")", "arg_10", "=", "[", "]", "if", "arg_3", ":", "arg_10", "=", "_correct_record", "(", "arg_9", ")", "return", "(", "arg_9", ",", "int", "(", "not", "arg_10", ")", ",", "arg_10", ")"], "function": "def Func(arg_0=None, arg_1=arg_2,\n                  arg_3=arg_4, arg_5='',\n                  arg_6=False,\n                  arg_7=arg_8):\n    \"\"\"Create a record object from the marcxml description.\n\n    Uses the lxml parser.\n\n    The returned object is a tuple (record, status_code, list_of_errors),\n    where status_code is 0 when there are errors, 1 when no errors.\n\n    The return record structure is as follows::\n\n        Record := {tag : [Field]}\n        Field := (Subfields, ind1, ind2, value)\n        Subfields := [(code, value)]\n\n    .. code-block:: none\n\n                                    .--------.\n                                    | record |\n                                    '---+----'\n                                        |\n               .------------------------+------------------------------------.\n               |record['001']           |record['909']        |record['520'] |\n               |                        |                     |              |\n        [list of fields]           [list of fields]     [list of fields]    ...\n               |                        |                     |\n               |               .--------+--+-----------.      |\n               |               |           |           |      |\n               |[0]            |[0]        |[1]       ...     |[0]\n          .----+------.  .-----+-----.  .--+--------.     .---+-------.\n          | Field 001 |  | Field 909 |  | Field 909 |     | Field 520 |\n          '-----------'  '-----+-----'  '--+--------'     '---+-------'\n               |               |           |                  |\n              ...              |          ...                ...\n                               |\n                    .----------+-+--------+------------.\n                    |            |        |            |\n                    |[0]         |[1]     |[2]         |\n          [list of subfields]   'C'      '4'          ...\n                    |\n               .----+---------------+------------------------+\n               |                    |                        |\n        ('a', 'value')              |            ('a', 'value for another a')\n                     ('b', 'value for subfield b')\n\n    :param marcxml: an XML string representation of the record to create\n    :param verbose: the level of verbosity: 0 (silent), 1-2 (warnings),\n                    3(strict:stop when errors)\n    :param correct: 1 to enable correction of marcxml syntax. Else 0.\n    :return: a tuple (record, status_code, list_of_errors), where status\n             code is 0 where there are errors, 1 when no errors\n    \"\"\"\n    if arg_0 is None:\n        return {}\n    try:\n        arg_9 = _Func_lxml(arg_0, arg_1, arg_3,\n                                  arg_7=arg_7)\n    except InvenioBibRecordParserError as ex1:\n        return (None, 0, str(ex1))\n\n    if arg_6:\n        _record_sort_by_indicators(arg_9)\n\n    arg_10 = []\n    if arg_3:\n        # Correct the structure of the record.\n        arg_10 = _correct_record(arg_9)\n\n    return (arg_9, int(not arg_10), arg_10)", "path": "harvestingkit/bibrecord.py", "identifier": "create_record", "docstring": "Create a record object from the marcxml description.\n\n    Uses the lxml parser.\n\n    The returned object is a tuple (record, status_code, list_of_errors),\n    where status_code is 0 when there are errors, 1 when no errors.\n\n    The return record structure is as follows::\n\n        Record := {tag : [Field]}\n        Field := (Subfields, ind1, ind2, value)\n        Subfields := [(code, value)]\n\n    .. code-block:: none\n\n                                    .--------.\n                                    | record |\n                                    '---+----'\n                                        |\n               .------------------------+------------------------------------.\n               |record['001']           |record['909']        |record['520'] |\n               |                        |                     |              |\n        [list of fields]           [list of fields]     [list of fields]    ...\n               |                        |                     |\n               |               .--------+--+-----------.      |\n               |               |           |           |      |\n               |[0]            |[0]        |[1]       ...     |[0]\n          .----+------.  .-----+-----.  .--+--------.     .---+-------.\n          | Field 001 |  | Field 909 |  | Field 909 |     | Field 520 |\n          '-----------'  '-----+-----'  '--+--------'     '---+-------'\n               |               |           |                  |\n              ...              |          ...                ...\n                               |\n                    .----------+-+--------+------------.\n                    |            |        |            |\n                    |[0]         |[1]     |[2]         |\n          [list of subfields]   'C'      '4'          ...\n                    |\n               .----+---------------+------------------------+\n               |                    |                        |\n        ('a', 'value')              |            ('a', 'value for another a')\n                     ('b', 'value for subfield b')\n\n    :param marcxml: an XML string representation of the record to create\n    :param verbose: the level of verbosity: 0 (silent), 1-2 (warnings),\n                    3(strict:stop when errors)\n    :param correct: 1 to enable correction of marcxml syntax. Else 0.\n    :return: a tuple (record, status_code, list_of_errors), where status\n             code is 0 where there are errors, 1 when no errors", "docstring_tokens": ["Create", "a", "record", "object", "from", "the", "marcxml", "description", "."], "nwo": "inspirehep/harvesting-kit", "score": 0.23137166388621372, "idx": 277478}
{"url": "https://github.com/dagster-io/dagster/blob/4119f8c773089de64831b1dfb9e168e353d401dc/python_modules/dagster/dagster/core/definitions/repository.py#L102-L112", "sha": "4119f8c773089de64831b1dfb9e168e353d401dc", "docstring_summary": "Return all pipelines as a list", "language": "python", "parameters": "(self)", "return_statement": "return pipelines", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "list", "(", "map", "(", "arg_0", ".", "get_pipeline", ",", "arg_0", ".", "pipeline_dict", ".", "keys", "(", ")", ")", ")", "arg_0", ".", "_construct_solid_defs", "(", "arg_1", ")", "return", "arg_1"], "function": "def Func(arg_0):\n        '''Return all pipelines as a list\n\n        Returns:\n            List[PipelineDefinition]:\n\n        '''\n        arg_1 = list(map(arg_0.get_pipeline, arg_0.pipeline_dict.keys()))\n        # This does uniqueness check\n        arg_0._construct_solid_defs(arg_1)\n        return arg_1", "path": "python_modules/dagster/dagster/core/definitions/repository.py", "identifier": "RepositoryDefinition.get_all_pipelines", "docstring": "Return all pipelines as a list\n\n        Returns:\n            List[PipelineDefinition]:", "docstring_tokens": ["Return", "all", "pipelines", "as", "a", "list"], "nwo": "dagster-io/dagster", "score": 0.9668997379845927, "idx": 279395}
{"url": "https://github.com/zqfang/GSEApy/blob/673e9ec1391e3b14d3e8a4353117151fd2cb9345/gseapy/gsea.py#L384-L438", "sha": "673e9ec1391e3b14d3e8a4353117151fd2cb9345", "docstring_summary": "GSEA main procedure", "language": "python", "parameters": "(self)", "return_statement": "return", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "assert", "arg_0", ".", "permutation_type", "in", "[", "\"phenotype\"", ",", "\"gene_set\"", "]", "assert", "arg_0", ".", "min_size", "<=", "arg_0", ".", "max_size", "arg_0", ".", "_logger", ".", "info", "(", "\"Parsing data files for GSEA.............................\"", ")", "arg_1", ",", "arg_2", ",", "arg_3", "=", "gsea_cls_parser", "(", "arg_0", ".", "classes", ")", "arg_4", "=", "arg_0", ".", "load_data", "(", "arg_3", ")", "assert", "len", "(", "arg_4", ")", ">", "1", "arg_5", "=", "ranking_metric", "(", "df", "=", "arg_4", ",", "method", "=", "arg_0", ".", "method", ",", "pos", "=", "arg_1", ",", "neg", "=", "arg_2", ",", "classes", "=", "arg_3", ",", "ascending", "=", "arg_0", ".", "ascending", ")", "arg_0", ".", "ranking", "=", "arg_5", "arg_7", "=", "arg_0", ".", "load_gmt", "(", "gene_list", "=", "arg_5", ".", "index", ".", "values", ",", "arg_7", "=", "arg_0", ".", "gene_sets", ")", "arg_0", ".", "_logger", ".", "info", "(", "\"%04d gene_sets used for further statistical testing.....\"", "%", "len", "(", "arg_7", ")", ")", "arg_0", ".", "_logger", ".", "info", "(", "\"Start to Func GSEA...Might take a while..................\"", ")", "arg_0", ".", "_set_cores", "(", ")", "arg_8", "=", "arg_4", "if", "arg_0", ".", "permutation_type", "==", "'phenotype'", "else", "arg_5", "arg_9", ",", "arg_10", ",", "arg_11", ",", "arg_12", "=", "gsea_compute_tensor", "(", "data", "=", "arg_8", ",", "arg_7", "=", "arg_7", ",", "n", "=", "arg_0", ".", "permutation_num", ",", "weighted_score_type", "=", "arg_0", ".", "weighted_score_type", ",", "permutation_type", "=", "arg_0", ".", "permutation_type", ",", "method", "=", "arg_0", ".", "method", ",", "pheno_pos", "=", "arg_1", ",", "pheno_neg", "=", "arg_2", ",", "classes", "=", "arg_3", ",", "ascending", "=", "arg_0", ".", "ascending", ",", "processes", "=", "arg_0", ".", "_processes", ",", "seed", "=", "arg_0", ".", "seed", ")", "arg_0", ".", "_logger", ".", "info", "(", "\"Start to generate GSEApy reports and figures............\"", ")", "arg_13", "=", "zip", "(", "arg_12", ",", "list", "(", "arg_9", ")", ",", "arg_10", ",", "arg_11", ")", "arg_0", ".", "_save_results", "(", "zipdata", "=", "arg_13", ",", "outdir", "=", "arg_0", ".", "outdir", ",", "module", "=", "arg_0", ".", "module", ",", "arg_7", "=", "arg_7", ",", "rank_metric", "=", "arg_5", ",", "permutation_type", "=", "arg_0", ".", "permutation_type", ")", "arg_0", ".", "_heatmat", "(", "df", "=", "arg_4", ".", "loc", "[", "arg_5", ".", "index", "]", ",", "classes", "=", "arg_3", ",", "pheno_pos", "=", "arg_1", ",", "pheno_neg", "=", "arg_2", ")", "if", "not", "arg_0", ".", "_noplot", ":", "arg_0", ".", "_plotting", "(", "rank_metric", "=", "arg_5", ",", "results", "=", "arg_0", ".", "results", ",", "graph_num", "=", "arg_0", ".", "graph_num", ",", "outdir", "=", "arg_0", ".", "outdir", ",", "figsize", "=", "arg_0", ".", "figsize", ",", "format", "=", "arg_0", ".", "format", ",", "pheno_pos", "=", "arg_1", ",", "pheno_neg", "=", "arg_2", ")", "arg_0", ".", "_logger", ".", "info", "(", "\"Congratulations. GSEApy ran successfully.................\\n\"", ")", "if", "arg_0", ".", "_outdir", "is", "None", ":", "arg_0", ".", "_tmpdir", ".", "cleanup", "(", ")", "return"], "function": "def Func(arg_0):\n        \"\"\"GSEA main procedure\"\"\"\n\n        assert arg_0.permutation_type in [\"phenotype\", \"gene_set\"]\n        assert arg_0.min_size <= arg_0.max_size\n\n        # Start Analysis\n        arg_0._logger.info(\"Parsing data files for GSEA.............................\")\n        # phenotype labels parsing\n        arg_1, arg_2, arg_3 = gsea_cls_parser(arg_0.classes)\n        # select correct expression genes and values.\n        arg_4 = arg_0.load_data(arg_3)\n        # data frame must have length > 1\n        assert len(arg_4) > 1\n        # ranking metrics calculation.\n        arg_5 = ranking_metric(df=arg_4, method=arg_0.method, pos=arg_1, neg=arg_2,\n                              classes=arg_3, ascending=arg_0.ascending)\n        arg_0.ranking = arg_5\n        # filtering out gene sets and build gene sets dictionary\n        arg_7 = arg_0.load_gmt(gene_list=arg_5.index.values, arg_7=arg_0.gene_sets)\n\n        arg_0._logger.info(\"%04d gene_sets used for further statistical testing.....\"% len(arg_7))\n        arg_0._logger.info(\"Start to Func GSEA...Might take a while..................\")\n        # cpu numbers\n        arg_0._set_cores()\n        # compute ES, NES, pval, FDR, RES\n        arg_8 = arg_4 if arg_0.permutation_type =='phenotype' else arg_5\n        arg_9,arg_10,arg_11, arg_12 = gsea_compute_tensor(data=arg_8, arg_7=arg_7, n=arg_0.permutation_num,\n                                                             weighted_score_type=arg_0.weighted_score_type,\n                                                             permutation_type=arg_0.permutation_type,\n                                                             method=arg_0.method,\n                                                             pheno_pos=arg_1, pheno_neg=arg_2,\n                                                             classes=arg_3, ascending=arg_0.ascending,\n                                                             processes=arg_0._processes, seed=arg_0.seed)\n        \n        arg_0._logger.info(\"Start to generate GSEApy reports and figures............\")\n        arg_13 = zip(arg_12, list(arg_9), arg_10, arg_11)\n        arg_0._save_results(zipdata=arg_13, outdir=arg_0.outdir, module=arg_0.module,\n                                   arg_7=arg_7, rank_metric=arg_5, permutation_type=arg_0.permutation_type)\n\n        # reorder datarame for heatmap\n        arg_0._heatmat(df=arg_4.loc[arg_5.index], classes=arg_3, \n                      pheno_pos=arg_1, pheno_neg=arg_2)\n        # Plotting\n        if not arg_0._noplot:\n            arg_0._plotting(rank_metric=arg_5, results=arg_0.results,\n                           graph_num=arg_0.graph_num, outdir=arg_0.outdir,\n                           figsize=arg_0.figsize, format=arg_0.format,\n                           pheno_pos=arg_1, pheno_neg=arg_2)\n\n        arg_0._logger.info(\"Congratulations. GSEApy ran successfully.................\\n\")\n        if arg_0._outdir is None:\n            arg_0._tmpdir.cleanup()\n\n        return", "path": "gseapy/gsea.py", "identifier": "GSEA.run", "docstring": "GSEA main procedure", "docstring_tokens": ["GSEA", "main", "procedure"], "nwo": "zqfang/GSEApy", "score": 0.7702436323138905, "idx": 268998}
{"url": "https://github.com/bprinty/gems/blob/3ff76407af0e71621dada744cd964611e998699c/gems/datatypes.py#L456-L464", "sha": "3ff76407af0e71621dada744cd964611e998699c", "docstring_summary": "Extend list from object, if object is list.", "language": "python", "parameters": "(self, item)", "return_statement": "return", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "if", "arg_0", ".", "meta_type", "==", "'dict'", ":", "raise", "AssertionError", "(", "'Cannot Func to object of `dict` base type!'", ")", "if", "arg_0", ".", "meta_type", "==", "'list'", ":", "arg_0", ".", "_list", ".", "Func", "(", "arg_1", ")", "return"], "function": "def Func(arg_0, arg_1):\n        \"\"\"\n        Extend list from object, if object is list.\n        \"\"\"\n        if arg_0.meta_type == 'dict':\n            raise AssertionError('Cannot Func to object of `dict` base type!')\n        if arg_0.meta_type == 'list':\n            arg_0._list.Func(arg_1)\n        return", "path": "gems/datatypes.py", "identifier": "composite.extend", "docstring": "Extend list from object, if object is list.", "docstring_tokens": ["Extend", "list", "from", "object", "if", "object", "is", "list", "."], "nwo": "bprinty/gems", "score": 0.16246995141409282, "idx": 261624}
{"url": "https://github.com/numenta/nupic/blob/5922fafffdccc8812e72b3324965ad2f7d4bbdad/src/nupic/algorithms/backtracking_tm.py#L2771-L2807", "sha": "5922fafffdccc8812e72b3324965ad2f7d4bbdad", "docstring_summary": "This method deletes all synapses whose permanence is less than\n    minPermanence and deletes any segments that have less than\n    minNumSyns synapses remaining.", "language": "python", "parameters": "(self, minPermanence=None, minNumSyns=None)", "return_statement": "return totalSegsRemoved, totalSynsRemoved", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ",", "arg_2", "=", "None", ")", ":", "if", "arg_1", "is", "None", ":", "arg_1", "=", "arg_0", ".", "connectedPerm", "if", "arg_2", "is", "None", ":", "arg_2", "=", "arg_0", ".", "activationThreshold", "arg_3", ",", "arg_4", "=", "0", ",", "0", "for", "arg_5", ",", "arg_6", "in", "itertools", ".", "product", "(", "xrange", "(", "arg_0", ".", "numberOfCols", ")", ",", "xrange", "(", "arg_0", ".", "cellsPerColumn", ")", ")", ":", "(", "arg_7", ",", "arg_8", ")", "=", "arg_0", ".", "_FuncInCell", "(", "colIdx", "=", "arg_5", ",", "cellIdx", "=", "arg_6", ",", "segList", "=", "arg_0", ".", "cells", "[", "arg_5", "]", "[", "arg_6", "]", ",", "arg_1", "=", "arg_1", ",", "arg_2", "=", "arg_2", ")", "arg_3", "+=", "arg_7", "arg_4", "+=", "arg_8", "if", "arg_0", ".", "verbosity", ">=", "5", ":", "print", "\"Cells, all segments:\"", "arg_0", ".", "printCells", "(", "predictedOnly", "=", "False", ")", "return", "arg_3", ",", "arg_4"], "function": "def Func(arg_0, arg_1=None, arg_2=None):\n    \"\"\"\n    This method deletes all synapses whose permanence is less than\n    minPermanence and deletes any segments that have less than\n    minNumSyns synapses remaining.\n\n    :param minPermanence: (float) Any syn whose permanence is 0 or < \n           ``minPermanence``  will be deleted. If None is passed in, then \n           ``self.connectedPerm`` is used.\n    :param minNumSyns: (int) Any segment with less than ``minNumSyns`` synapses \n           remaining in it will be deleted. If None is passed in, then \n           ``self.activationThreshold`` is used.\n    :returns: (tuple) ``numSegsRemoved``, ``numSynsRemoved``\n    \"\"\"\n    # Fill in defaults\n    if arg_1 is None:\n      arg_1 = arg_0.connectedPerm\n    if arg_2 is None:\n      arg_2 = arg_0.activationThreshold\n\n    # Loop through all cells\n    arg_3, arg_4 = 0, 0\n    for arg_5, arg_6 in itertools.product(xrange(arg_0.numberOfCols),\n                                  xrange(arg_0.cellsPerColumn)):\n\n      (arg_7, arg_8) = arg_0._FuncInCell(\n          colIdx=arg_5, cellIdx=arg_6, segList=arg_0.cells[arg_5][arg_6],\n          arg_1=arg_1, arg_2=arg_2)\n      arg_3 += arg_7\n      arg_4 += arg_8\n\n    # Print all cells if verbosity says to\n    if arg_0.verbosity >= 5:\n      print \"Cells, all segments:\"\n      arg_0.printCells(predictedOnly=False)\n\n    return arg_3, arg_4", "path": "src/nupic/algorithms/backtracking_tm.py", "identifier": "BacktrackingTM.trimSegments", "docstring": "This method deletes all synapses whose permanence is less than\n    minPermanence and deletes any segments that have less than\n    minNumSyns synapses remaining.\n\n    :param minPermanence: (float) Any syn whose permanence is 0 or < \n           ``minPermanence``  will be deleted. If None is passed in, then \n           ``self.connectedPerm`` is used.\n    :param minNumSyns: (int) Any segment with less than ``minNumSyns`` synapses \n           remaining in it will be deleted. If None is passed in, then \n           ``self.activationThreshold`` is used.\n    :returns: (tuple) ``numSegsRemoved``, ``numSynsRemoved``", "docstring_tokens": ["This", "method", "deletes", "all", "synapses", "whose", "permanence", "is", "less", "than", "minPermanence", "and", "deletes", "any", "segments", "that", "have", "less", "than", "minNumSyns", "synapses", "remaining", "."], "nwo": "numenta/nupic", "score": 0.9869177850423402, "idx": 276679}
{"url": "https://github.com/connectordb/connectordb-python/blob/2092b0cb30898139a247176bcf433d5a4abde7cb/connectordb/_websocket.py#L249-L263", "sha": "2092b0cb30898139a247176bcf433d5a4abde7cb", "docstring_summary": "Called when the websocket is closed", "language": "python", "parameters": "(self, ws)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "if", "arg_0", ".", "status", "==", "\"disconnected\"", ":", "return", "logging", ".", "debug", "(", "\"ConnectorDB:WS: Websocket closed\"", ")", "if", "arg_0", ".", "pingtimer", "is", "not", "None", ":", "arg_0", ".", "pingtimer", ".", "cancel", "(", ")", "arg_0", ".", "disconnected_time", "=", "time", ".", "time", "(", ")", "if", "arg_0", ".", "status", "==", "\"disconnecting\"", ":", "arg_0", ".", "status", "=", "\"disconnected\"", "elif", "arg_0", ".", "status", "==", "\"connected\"", ":", "arg_0", ".", "__reconnect", "(", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"Called when the websocket is closed\"\"\"\n        if arg_0.status == \"disconnected\":\n            return  # This can be double-called on disconnect\n        logging.debug(\"ConnectorDB:WS: Websocket closed\")\n\n        # Turn off the ping timer\n        if arg_0.pingtimer is not None:\n            arg_0.pingtimer.cancel()\n\n        arg_0.disconnected_time = time.time()\n        if arg_0.status == \"disconnecting\":\n            arg_0.status = \"disconnected\"\n        elif arg_0.status == \"connected\":\n            arg_0.__reconnect()", "path": "connectordb/_websocket.py", "identifier": "WebsocketHandler.__on_close", "docstring": "Called when the websocket is closed", "docstring_tokens": ["Called", "when", "the", "websocket", "is", "closed"], "nwo": "connectordb/connectordb-python", "score": 0.25890992733444657, "idx": 267936}
{"url": "https://github.com/RRZE-HPC/kerncraft/blob/c60baf8043e4da8d8d66da7575021c2f4c6c78af/kerncraft/models/ecm.py#L28-L49", "sha": "c60baf8043e4da8d8d66da7575021c2f4c6c78af", "docstring_summary": "Split list of integers into blocks of block_size and return block indices.", "language": "python", "parameters": "(indices, block_size, initial_boundary=0)", "return_statement": "return blocks", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "0", ")", ":", "arg_3", "=", "[", "]", "for", "arg_4", "in", "arg_0", ":", "arg_5", "=", "(", "arg_4", "-", "arg_2", ")", "//", "float", "(", "arg_1", ")", "if", "arg_5", "not", "in", "arg_3", ":", "arg_3", ".", "append", "(", "arg_5", ")", "arg_3", ".", "sort", "(", ")", "return", "arg_3"], "function": "def Func(arg_0, arg_1, arg_2=0):\n    \"\"\"\n    Split list of integers into blocks of block_size and return block indices.\n\n    First block element will be located at initial_boundary (default 0).\n\n    >>> Func([0, -1, -2, -3, -4, -5, -6, -7, -8, -9], 8)\n    [0,-1]\n    >>> Func([0], 8)\n    [0]\n    >>> Func([0], 8, initial_boundary=32)\n    [-4]\n    \"\"\"\n    arg_3 = []\n\n    for arg_4 in arg_0:\n        arg_5 = (arg_4-arg_2)//float(arg_1)\n        if arg_5 not in arg_3:\n            arg_3.append(arg_5)\n    arg_3.sort()\n\n    return arg_3", "path": "kerncraft/models/ecm.py", "identifier": "blocking", "docstring": "Split list of integers into blocks of block_size and return block indices.\n\n    First block element will be located at initial_boundary (default 0).\n\n    >>> blocking([0, -1, -2, -3, -4, -5, -6, -7, -8, -9], 8)\n    [0,-1]\n    >>> blocking([0], 8)\n    [0]\n    >>> blocking([0], 8, initial_boundary=32)\n    [-4]", "docstring_tokens": ["Split", "list", "of", "integers", "into", "blocks", "of", "block_size", "and", "return", "block", "indices", "."], "nwo": "RRZE-HPC/kerncraft", "score": 0.3938336572392353, "idx": 265593}
{"url": "https://github.com/LuminosoInsight/luminoso-api-client-python/blob/3bedf2a454aee39214c11fbf556ead3eecc27881/luminoso_api/v5_upload.py#L35-L47", "sha": "3bedf2a454aee39214c11fbf556ead3eecc27881", "docstring_summary": "Limit a document to just the three fields we should upload.", "language": "python", "parameters": "(doc)", "return_statement": "return {\n        'text': doc['text'],\n        'metadata': doc.get('metadata', []),\n        'title': doc.get('title', '')\n    }", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_0", "=", "dict", "(", "arg_0", ")", "if", "'text'", "not", "in", "arg_0", ":", "raise", "ValueError", "(", "\"The document {!r} has no text field\"", ".", "format", "(", "arg_0", ")", ")", "return", "{", "'text'", ":", "arg_0", "[", "'text'", "]", ",", "'metadata'", ":", "arg_0", ".", "get", "(", "'metadata'", ",", "[", "]", ")", ",", "'title'", ":", "arg_0", ".", "get", "(", "'title'", ",", "''", ")", "}"], "function": "def Func(arg_0):\n    \"\"\"\n    Limit a document to just the three fields we should upload.\n    \"\"\"\n    # Mutate a copy of the document to fill in missing fields\n    arg_0 = dict(arg_0)\n    if 'text' not in arg_0:\n        raise ValueError(\"The document {!r} has no text field\".format(arg_0))\n    return {\n        'text': arg_0['text'],\n        'metadata': arg_0.get('metadata', []),\n        'title': arg_0.get('title', '')\n    }", "path": "luminoso_api/v5_upload.py", "identifier": "_simplify_doc", "docstring": "Limit a document to just the three fields we should upload.", "docstring_tokens": ["Limit", "a", "document", "to", "just", "the", "three", "fields", "we", "should", "upload", "."], "nwo": "LuminosoInsight/luminoso-api-client-python", "score": 0.568966879505561, "idx": 276178}
{"url": "https://github.com/domainaware/parsedmarc/blob/ecc9fd434c23d896ccd1f35795ccc047f946ed05/parsedmarc/__init__.py#L386-L406", "sha": "ecc9fd434c23d896ccd1f35795ccc047f946ed05", "docstring_summary": "Parses a file at the given path, a file-like object. or bytes as a\n    aggregate DMARC report", "language": "python", "parameters": "(_input, nameservers=None, dns_timeout=2.0,\n                                parallel=False)", "return_statement": "return parse_aggregate_report_xml(xml,\n                                      nameservers=nameservers,\n                                      timeout=dns_timeout,\n                                      parallel=parallel)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ",", "arg_2", "=", "2.0", ",", "arg_3", "=", "False", ")", ":", "arg_4", "=", "extract_xml", "(", "arg_0", ")", "return", "parse_aggregate_report_xml", "(", "arg_4", ",", "arg_1", "=", "arg_1", ",", "timeout", "=", "arg_2", ",", "arg_3", "=", "arg_3", ")"], "function": "def Func(arg_0, arg_1=None, arg_2=2.0,\n                                arg_3=False):\n    \"\"\"Parses a file at the given path, a file-like object. or bytes as a\n    aggregate DMARC report\n\n    Args:\n        _input: A path to a file, a file like object, or bytes\n        nameservers (list): A list of one or more nameservers to use\n        (Cloudflare's public DNS resolvers by default)\n        dns_timeout (float): Sets the DNS timeout in seconds\n        parallel (bool): Parallel processing\n\n    Returns:\n        OrderedDict: The parsed DMARC aggregate report\n    \"\"\"\n    arg_4 = extract_xml(arg_0)\n\n    return parse_aggregate_report_xml(arg_4,\n                                      arg_1=arg_1,\n                                      timeout=arg_2,\n                                      arg_3=arg_3)", "path": "parsedmarc/__init__.py", "identifier": "parse_aggregate_report_file", "docstring": "Parses a file at the given path, a file-like object. or bytes as a\n    aggregate DMARC report\n\n    Args:\n        _input: A path to a file, a file like object, or bytes\n        nameservers (list): A list of one or more nameservers to use\n        (Cloudflare's public DNS resolvers by default)\n        dns_timeout (float): Sets the DNS timeout in seconds\n        parallel (bool): Parallel processing\n\n    Returns:\n        OrderedDict: The parsed DMARC aggregate report", "docstring_tokens": ["Parses", "a", "file", "at", "the", "given", "path", "a", "file", "-", "like", "object", ".", "or", "bytes", "as", "a", "aggregate", "DMARC", "report"], "nwo": "domainaware/parsedmarc", "score": 0.7452768887820926, "idx": 277019}
{"url": "https://github.com/Contraz/demosys-py/blob/6466128a3029c4d09631420ccce73024025bd5b6/demosys/management/commands/createeffect.py#L60-L68", "sha": "6466128a3029c4d09631420ccce73024025bd5b6", "docstring_summary": "Scan for available templates in effect_templates", "language": "python", "parameters": "(value)", "return_statement": "return value", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "list_templates", "(", ")", "if", "arg_0", "not", "in", "arg_1", ":", "raise", "ArgumentTypeError", "(", "\"Effect template '{}' does not exist.\\n Available templates: {} \"", ".", "format", "(", "arg_0", ",", "\", \"", ".", "join", "(", "arg_1", ")", ")", ")", "return", "arg_0"], "function": "def Func(arg_0):\n    \"\"\"Scan for available templates in effect_templates\"\"\"\n    arg_1 = list_templates()\n\n    if arg_0 not in arg_1:\n        raise ArgumentTypeError(\"Effect template '{}' does not exist.\\n Available templates: {} \".format(\n            arg_0, \", \".join(arg_1)))\n\n    return arg_0", "path": "demosys/management/commands/createeffect.py", "identifier": "available_templates", "docstring": "Scan for available templates in effect_templates", "docstring_tokens": ["Scan", "for", "available", "templates", "in", "effect_templates"], "nwo": "Contraz/demosys-py", "score": 0.534901783741059, "idx": 267207}
{"url": "https://github.com/edx/edx-enterprise/blob/aea91379ab0a87cd3bc798961fce28b60ee49a80/enterprise/models.py#L510-L528", "sha": "aea91379ab0a87cd3bc798961fce28b60ee49a80", "docstring_summary": "Return link by email.", "language": "python", "parameters": "(self, user_email)", "return_statement": "return None", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "try", ":", "arg_2", "=", "User", ".", "objects", ".", "get", "(", "email", "=", "arg_1", ")", "try", ":", "return", "arg_0", ".", "get", "(", "user_id", "=", "arg_2", ".", "id", ")", "except", "EnterpriseCustomerUser", ".", "DoesNotExist", ":", "pass", "except", "User", ".", "DoesNotExist", ":", "pass", "try", ":", "return", "PendingEnterpriseCustomerUser", ".", "objects", ".", "get", "(", "arg_1", "=", "arg_1", ")", "except", "PendingEnterpriseCustomerUser", ".", "DoesNotExist", ":", "pass", "return", "None"], "function": "def Func(arg_0, arg_1):\n        \"\"\"\n        Return link by email.\n        \"\"\"\n        try:\n            arg_2 = User.objects.get(email=arg_1)\n            try:\n                return arg_0.get(user_id=arg_2.id)\n            except EnterpriseCustomerUser.DoesNotExist:\n                pass\n        except User.DoesNotExist:\n            pass\n\n        try:\n            return PendingEnterpriseCustomerUser.objects.get(arg_1=arg_1)\n        except PendingEnterpriseCustomerUser.DoesNotExist:\n            pass\n\n        return None", "path": "enterprise/models.py", "identifier": "EnterpriseCustomerUserManager.get_link_by_email", "docstring": "Return link by email.", "docstring_tokens": ["Return", "link", "by", "email", "."], "nwo": "edx/edx-enterprise", "score": 0.6522400190762081, "idx": 272837}
{"url": "https://github.com/ibm-watson-iot/iot-python/blob/195f05adce3fba4ec997017e41e02ebd85c0c4cc/src/wiotp/sdk/gateway/client.py#L139-L151", "sha": "195f05adce3fba4ec997017e41e02ebd85c0c4cc", "docstring_summary": "Internal callback for gateway notification messages, parses source device from topic string and\n        passes the information on to the registered device command callback", "language": "python", "parameters": "(self, client, userdata, pahoMessage)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ")", ":", "try", ":", "arg_4", "=", "Notification", "(", "arg_3", ",", "arg_0", ".", "_messageCodecs", ")", "except", "InvalidEventException", "as", "e", ":", "arg_0", ".", "logger", ".", "critical", "(", "str", "(", "e", ")", ")", "else", ":", "arg_0", ".", "logger", ".", "debug", "(", "\"Received Notification\"", ")", "if", "arg_0", ".", "notificationCallback", ":", "arg_0", ".", "notificationCallback", "(", "arg_4", ")"], "function": "def Func(arg_0, arg_1, arg_2, arg_3):\n        \"\"\"\n        Internal callback for gateway notification messages, parses source device from topic string and\n        passes the information on to the registered device command callback\n        \"\"\"\n        try:\n            arg_4 = Notification(arg_3, arg_0._messageCodecs)\n        except InvalidEventException as e:\n            arg_0.logger.critical(str(e))\n        else:\n            arg_0.logger.debug(\"Received Notification\")\n            if arg_0.notificationCallback:\n                arg_0.notificationCallback(arg_4)", "path": "src/wiotp/sdk/gateway/client.py", "identifier": "GatewayClient._onMessageNotification", "docstring": "Internal callback for gateway notification messages, parses source device from topic string and\n        passes the information on to the registered device command callback", "docstring_tokens": ["Internal", "callback", "for", "gateway", "notification", "messages", "parses", "source", "device", "from", "topic", "string", "and", "passes", "the", "information", "on", "to", "the", "registered", "device", "command", "callback"], "nwo": "ibm-watson-iot/iot-python", "score": 0.6135771375083736, "idx": 267789}
{"url": "https://github.com/dereneaton/ipyrad/blob/5eeb8a178160f45faf71bf47cec4abe998a575d1/ipyrad/core/assembly.py#L1069-L1089", "sha": "5eeb8a178160f45faf71bf47cec4abe998a575d1", "docstring_summary": "hidden wrapped function to start step 4", "language": "python", "parameters": "(self, samples, force, ipyclient)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ")", ":", "if", "arg_0", ".", "_headers", ":", "print", "(", "\"\\n  Step 4: Joint estimation of error rate and heterozygosity\"", ")", "arg_1", "=", "_get_samples", "(", "arg_0", ",", "arg_1", ")", "if", "not", "arg_0", ".", "_samples_precheck", "(", "arg_1", ",", "4", ",", "arg_2", ")", ":", "raise", "IPyradError", "(", "FIRST_RUN_3", ")", "elif", "not", "arg_2", ":", "if", "all", "(", "[", "arg_4", ".", "stats", ".", "state", ">=", "4", "for", "arg_4", "in", "arg_1", "]", ")", ":", "print", "(", "JOINTS_EXIST", ".", "format", "(", "len", "(", "arg_1", ")", ")", ")", "return", "assemble", ".", "jointestimate", ".", "run", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ")"], "function": "def Func(arg_0, arg_1, arg_2, arg_3):\n        \"\"\" hidden wrapped function to start step 4 \"\"\"\n\n        if arg_0._headers:\n            print(\"\\n  Step 4: Joint estimation of error rate and heterozygosity\")\n\n        ## Get sample objects from list of strings\n        arg_1 = _get_samples(arg_0, arg_1)\n\n        ## Check if all/none in the right state\n        if not arg_0._samples_precheck(arg_1, 4, arg_2):\n            raise IPyradError(FIRST_RUN_3)\n\n        elif not arg_2:\n            ## skip if all are finished\n            if all([arg_4.stats.state >= 4 for arg_4 in arg_1]):\n                print(JOINTS_EXIST.format(len(arg_1)))\n                return\n\n        ## send to function\n        assemble.jointestimate.run(arg_0, arg_1, arg_2, arg_3)", "path": "ipyrad/core/assembly.py", "identifier": "Assembly._step4func", "docstring": "hidden wrapped function to start step 4", "docstring_tokens": ["hidden", "wrapped", "function", "to", "start", "step", "4"], "nwo": "dereneaton/ipyrad", "score": 0.4137745335171406, "idx": 271031}
{"url": "https://github.com/open-mmlab/mmcv/blob/0d77f61450aab4dde8b8585a577cc496acb95d7f/mmcv/image/transforms/colorspace.py#L16-L30", "sha": "0d77f61450aab4dde8b8585a577cc496acb95d7f", "docstring_summary": "Convert a BGR image to grayscale image.", "language": "python", "parameters": "(img, keepdim=False)", "return_statement": "return out_img", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "False", ")", ":", "arg_2", "=", "cv2", ".", "cvtColor", "(", "arg_0", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "if", "arg_1", ":", "arg_2", "=", "arg_2", "[", "...", ",", "None", "]", "return", "arg_2"], "function": "def Func(arg_0, arg_1=False):\n    \"\"\"Convert a BGR image to grayscale image.\n\n    Args:\n        img (ndarray): The input image.\n        keepdim (bool): If False (by default), then return the grayscale image\n            with 2 dims, otherwise 3 dims.\n\n    Returns:\n        ndarray: The converted grayscale image.\n    \"\"\"\n    arg_2 = cv2.cvtColor(arg_0, cv2.COLOR_BGR2GRAY)\n    if arg_1:\n        arg_2 = arg_2[..., None]\n    return arg_2", "path": "mmcv/image/transforms/colorspace.py", "identifier": "bgr2gray", "docstring": "Convert a BGR image to grayscale image.\n\n    Args:\n        img (ndarray): The input image.\n        keepdim (bool): If False (by default), then return the grayscale image\n            with 2 dims, otherwise 3 dims.\n\n    Returns:\n        ndarray: The converted grayscale image.", "docstring_tokens": ["Convert", "a", "BGR", "image", "to", "grayscale", "image", "."], "nwo": "open-mmlab/mmcv", "score": 0.9830119364646916, "idx": 276352}
{"url": "https://github.com/trailofbits/manticore/blob/54c5a15b1119c523ae54c09972413e8b97f11629/manticore/native/cpu/x86.py#L2686-L2693", "sha": "54c5a15b1119c523ae54c09972413e8b97f11629", "docstring_summary": "Sets byte if greater or equal.", "language": "python", "parameters": "(cpu, dest)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_1", ".", "write", "(", "Operators", ".", "ITEBV", "(", "arg_1", ".", "size", ",", "arg_0", ".", "SF", "==", "arg_0", ".", "OF", ",", "1", ",", "0", ")", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"\n        Sets byte if greater or equal.\n\n        :param cpu: current CPU.\n        :param dest: destination operand.\n        \"\"\"\n        arg_1.write(Operators.ITEBV(arg_1.size, arg_0.SF == arg_0.OF, 1, 0))", "path": "manticore/native/cpu/x86.py", "identifier": "X86Cpu.SETGE", "docstring": "Sets byte if greater or equal.\n\n        :param cpu: current CPU.\n        :param dest: destination operand.", "docstring_tokens": ["Sets", "byte", "if", "greater", "or", "equal", "."], "nwo": "trailofbits/manticore", "score": 0.9483643694003796, "idx": 265670}
{"url": "https://github.com/soerenwolfers/swutil/blob/2d598f2deac8b7e20df95dbc68017e5ab5d6180c/swutil/decorators.py#L8-L16", "sha": "2d598f2deac8b7e20df95dbc68017e5ab5d6180c", "docstring_summary": "Decorator that logs function calls in their self.log", "language": "python", "parameters": "(function)", "return_statement": "return wrapper", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "def", "wrapper", "(", "arg_1", ",", "*", "arg_2", ",", "**", "arg_3", ")", ":", "arg_1", ".", "log", ".", "log", "(", "group", "=", "arg_0", ".", "__name__", ",", "message", "=", "'Enter'", ")", "arg_0", "(", "arg_1", ",", "*", "arg_2", ",", "**", "arg_3", ")", "arg_1", ".", "log", ".", "log", "(", "group", "=", "arg_0", ".", "__name__", ",", "message", "=", "'Exit'", ")", "return", "wrapper"], "function": "def Func(arg_0):\n    '''\n    Decorator that logs function calls in their self.log\n    '''\n    def wrapper(arg_1,*arg_2,**arg_3):  \n        arg_1.log.log(group=arg_0.__name__,message='Enter') \n        arg_0(arg_1,*arg_2,**arg_3)\n        arg_1.log.log(group=arg_0.__name__,message='Exit') \n    return wrapper", "path": "swutil/decorators.py", "identifier": "log_calls", "docstring": "Decorator that logs function calls in their self.log", "docstring_tokens": ["Decorator", "that", "logs", "function", "calls", "in", "their", "self", ".", "log"], "nwo": "soerenwolfers/swutil", "score": 0.2747185692836802, "idx": 265684}
{"url": "https://github.com/LordSputnik/mutagen/blob/38e62c8dc35c72b16554f5dbe7c0fde91acc3411/mutagen/flac.py#L686-L698", "sha": "38e62c8dc35c72b16554f5dbe7c0fde91acc3411", "docstring_summary": "Remove Vorbis comments from a file.", "language": "python", "parameters": "(self, filename=None)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ")", ":", "if", "arg_1", "is", "None", ":", "arg_1", "=", "arg_0", ".", "filename", "for", "arg_2", "in", "list", "(", "arg_0", ".", "metadata_blocks", ")", ":", "if", "isinstance", "(", "arg_2", ",", "VCFLACDict", ")", ":", "arg_0", ".", "metadata_blocks", ".", "remove", "(", "arg_2", ")", "arg_0", ".", "tags", "=", "None", "arg_0", ".", "save", "(", ")", "break"], "function": "def Func(arg_0, arg_1=None):\n        \"\"\"Remove Vorbis comments from a file.\n\n        If no filename is given, the one most recently loaded is used.\n        \"\"\"\n        if arg_1 is None:\n            arg_1 = arg_0.filename\n        for arg_2 in list(arg_0.metadata_blocks):\n            if isinstance(arg_2, VCFLACDict):\n                arg_0.metadata_blocks.remove(arg_2)\n                arg_0.tags = None\n                arg_0.save()\n                break", "path": "mutagen/flac.py", "identifier": "FLAC.delete", "docstring": "Remove Vorbis comments from a file.\n\n        If no filename is given, the one most recently loaded is used.", "docstring_tokens": ["Remove", "Vorbis", "comments", "from", "a", "file", "."], "nwo": "LordSputnik/mutagen", "score": 0.19099661306507362, "idx": 274196}
{"url": "https://github.com/EmbodiedCognition/pagoda/blob/8892f847026d98aba8646ecbc4589397e6dec7bd/pagoda/physics.py#L547-L550", "sha": "8892f847026d98aba8646ecbc4589397e6dec7bd", "docstring_summary": "List of axes for this object's degrees of freedom.", "language": "python", "parameters": "(self)", "return_statement": "return [np.array(self.ode_obj.getAxis(i))\n                for i in range(self.ADOF or self.LDOF)]", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "return", "[", "np", ".", "array", "(", "arg_0", ".", "ode_obj", ".", "getAxis", "(", "arg_1", ")", ")", "for", "arg_1", "in", "range", "(", "arg_0", ".", "ADOF", "or", "arg_0", ".", "LDOF", ")", "]"], "function": "def Func(arg_0):\n        '''List of Func for this object's degrees of freedom.'''\n        return [np.array(arg_0.ode_obj.getAxis(arg_1))\n                for arg_1 in range(arg_0.ADOF or arg_0.LDOF)]", "path": "pagoda/physics.py", "identifier": "Joint.axes", "docstring": "List of axes for this object's degrees of freedom.", "docstring_tokens": ["List", "of", "axes", "for", "this", "object", "s", "degrees", "of", "freedom", "."], "nwo": "EmbodiedCognition/pagoda", "score": 0.17185066990864498, "idx": 265070}
{"url": "https://github.com/polyaxon/polyaxon-cli/blob/a7f5eed74d4d909cad79059f3c21c58606881449/polyaxon_cli/cli/admin.py#L110-L125", "sha": "a7f5eed74d4d909cad79059f3c21c58606881449", "docstring_summary": "Teardown a polyaxon deployment given a config file.", "language": "python", "parameters": "(file)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "read_deployment_config", "(", "arg_0", ")", "arg_2", "=", "DeployManager", "(", "arg_1", "=", "arg_1", ",", "filepath", "=", "arg_0", ")", "arg_3", "=", "None", "try", ":", "if", "click", ".", "confirm", "(", "'Would you like to execute pre-delete hooks?'", ",", "default", "=", "True", ")", ":", "arg_2", ".", "Func", "(", "hooks", "=", "True", ")", "else", ":", "arg_2", ".", "Func", "(", "hooks", "=", "False", ")", "except", "Exception", "as", "e", ":", "Printer", ".", "print_error", "(", "'Polyaxon could not Func the deployment.'", ")", "arg_3", "=", "e", "if", "arg_3", ":", "Printer", ".", "print_error", "(", "'Error message `{}`.'", ".", "format", "(", "arg_3", ")", ")"], "function": "def Func(arg_0):  # pylint:disable=redefined-builtin\n    \"\"\"Teardown a polyaxon deployment given a config file.\"\"\"\n    arg_1 = read_deployment_config(arg_0)\n    arg_2 = DeployManager(arg_1=arg_1, filepath=arg_0)\n    arg_3 = None\n    try:\n        if click.confirm('Would you like to execute pre-delete hooks?', default=True):\n            arg_2.Func(hooks=True)\n        else:\n            arg_2.Func(hooks=False)\n    except Exception as e:\n        Printer.print_error('Polyaxon could not Func the deployment.')\n        arg_3 = e\n\n    if arg_3:\n        Printer.print_error('Error message `{}`.'.format(arg_3))", "path": "polyaxon_cli/cli/admin.py", "identifier": "teardown", "docstring": "Teardown a polyaxon deployment given a config file.", "docstring_tokens": ["Teardown", "a", "polyaxon", "deployment", "given", "a", "config", "file", "."], "nwo": "polyaxon/polyaxon-cli", "score": 0.288315270050036, "idx": 267670}
{"url": "https://github.com/SectorLabs/django-postgres-extra/blob/eef2ed5504d225858d4e4f5d77a838082ca6053e/psqlextra/backend/hstore_required.py#L134-L149", "sha": "eef2ed5504d225858d4e4f5d77a838082ca6053e", "docstring_summary": "Renames an existing REQUIRED CONSTRAINT for the specified\n        hstore key.", "language": "python", "parameters": "(self, old_table_name, new_table_name,\n                                old_field, new_field, key)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ",", "arg_4", ",", "arg_5", ")", ":", "arg_6", "=", "arg_0", ".", "_required_constraint_name", "(", "arg_1", ",", "arg_3", ",", "arg_5", ")", "arg_7", "=", "arg_0", ".", "_required_constraint_name", "(", "arg_2", ",", "arg_4", ",", "arg_5", ")", "arg_8", "=", "arg_0", ".", "sql_hstore_required_rename", ".", "format", "(", "table", "=", "arg_0", ".", "quote_name", "(", "arg_2", ")", ",", "arg_6", "=", "arg_0", ".", "quote_name", "(", "arg_6", ")", ",", "arg_7", "=", "arg_0", ".", "quote_name", "(", "arg_7", ")", ")", "arg_0", ".", "execute", "(", "arg_8", ")"], "function": "def Func(arg_0, arg_1, arg_2,\n                                arg_3, arg_4, arg_5):\n        \"\"\"Renames an existing REQUIRED CONSTRAINT for the specified\n        hstore key.\"\"\"\n\n        arg_6 = arg_0._required_constraint_name(\n            arg_1, arg_3, arg_5)\n        arg_7 = arg_0._required_constraint_name(\n            arg_2, arg_4, arg_5)\n\n        arg_8 = arg_0.sql_hstore_required_rename.format(\n            table=arg_0.quote_name(arg_2),\n            arg_6=arg_0.quote_name(arg_6),\n            arg_7=arg_0.quote_name(arg_7)\n        )\n        arg_0.execute(arg_8)", "path": "psqlextra/backend/hstore_required.py", "identifier": "HStoreRequiredSchemaEditorMixin._rename_hstore_required", "docstring": "Renames an existing REQUIRED CONSTRAINT for the specified\n        hstore key.", "docstring_tokens": ["Renames", "an", "existing", "REQUIRED", "CONSTRAINT", "for", "the", "specified", "hstore", "key", "."], "nwo": "SectorLabs/django-postgres-extra", "score": 0.938393672171891, "idx": 275845}
{"url": "https://github.com/Microsoft/botbuilder-python/blob/274663dd91c811bae6ac4488915ba5880771b0a7/libraries/botbuilder-core/botbuilder/core/message_factory.py#L47-L70", "sha": "274663dd91c811bae6ac4488915ba5880771b0a7", "docstring_summary": "Returns a message that includes a set of suggested actions and optional text.", "language": "python", "parameters": "(actions: List[CardAction], text: str = None, speak: str = None,\n                          input_hint: Union[InputHints, str] = InputHints.accepting_input)", "return_statement": "return message", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ":", "arg_1", "[", "arg_2", "]", ",", "arg_3", ":", "arg_4", "=", "None", ",", "arg_5", ":", "arg_4", "=", "None", ",", "arg_6", ":", "arg_7", "[", "arg_8", ",", "arg_4", "]", "=", "arg_8", ".", "accepting_input", ")", "->", "Activity", ":", "arg_0", "=", "SuggestedActions", "(", "arg_0", "=", "arg_0", ")", "arg_10", "=", "Activity", "(", "type", "=", "ActivityTypes", ".", "message", ",", "arg_6", "=", "arg_6", ",", "Func", "=", "arg_0", ")", "if", "arg_3", ":", "arg_10", ".", "text", "=", "arg_3", "if", "arg_5", ":", "arg_10", ".", "speak", "=", "arg_5", "return", "arg_10"], "function": "def Func(arg_0: arg_1[arg_2], arg_3: arg_4 = None, arg_5: arg_4 = None,\n                          arg_6: arg_7[arg_8, arg_4] = arg_8.accepting_input) -> Activity:\n        \"\"\"\n        Returns a message that includes a set of suggested actions and optional text.\n\n        :Example:\n        message = MessageFactory.Func([CardAction(title='a', type=ActionTypes.im_back, value='a'),\n                                                    CardAction(title='b', type=ActionTypes.im_back, value='b'),\n                                                    CardAction(title='c', type=ActionTypes.im_back, value='c')], 'Choose a color')\n        await context.send_activity(message)\n\n        :param actions:\n        :param text:\n        :param speak:\n        :param input_hint:\n        :return:\n        \"\"\"\n        arg_0 = SuggestedActions(arg_0=arg_0)\n        arg_10 = Activity(type=ActivityTypes.message, arg_6=arg_6, Func=arg_0)\n        if arg_3:\n            arg_10.text = arg_3\n        if arg_5:\n            arg_10.speak = arg_5\n        return arg_10", "path": "libraries/botbuilder-core/botbuilder/core/message_factory.py", "identifier": "MessageFactory.suggested_actions", "docstring": "Returns a message that includes a set of suggested actions and optional text.\n\n        :Example:\n        message = MessageFactory.suggested_actions([CardAction(title='a', type=ActionTypes.im_back, value='a'),\n                                                    CardAction(title='b', type=ActionTypes.im_back, value='b'),\n                                                    CardAction(title='c', type=ActionTypes.im_back, value='c')], 'Choose a color')\n        await context.send_activity(message)\n\n        :param actions:\n        :param text:\n        :param speak:\n        :param input_hint:\n        :return:", "docstring_tokens": ["Returns", "a", "message", "that", "includes", "a", "set", "of", "suggested", "actions", "and", "optional", "text", "."], "nwo": "Microsoft/botbuilder-python", "score": 0.9771084554457546, "idx": 268178}
{"url": "https://github.com/trailofbits/manticore/blob/54c5a15b1119c523ae54c09972413e8b97f11629/manticore/core/state.py#L158-L164", "sha": "54c5a15b1119c523ae54c09972413e8b97f11629", "docstring_summary": "Constrain state.", "language": "python", "parameters": "(self, constraint)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_1", "=", "arg_0", ".", "migrate_expression", "(", "arg_1", ")", "arg_0", ".", "_Functs", ".", "add", "(", "arg_1", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"Constrain state.\n\n        :param manticore.core.smtlib.Bool Funct: Constraint to add\n        \"\"\"\n        arg_1 = arg_0.migrate_expression(arg_1)\n        arg_0._Functs.add(arg_1)", "path": "manticore/core/state.py", "identifier": "StateBase.constrain", "docstring": "Constrain state.\n\n        :param manticore.core.smtlib.Bool constraint: Constraint to add", "docstring_tokens": ["Constrain", "state", "."], "nwo": "trailofbits/manticore", "score": 0.9483643694003796, "idx": 263615}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/html/notebook/notebookapp.py#L427-L462", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "initialize tornado webapp and httpserver", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_0", ".", "web_app", "=", "NotebookWebApplication", "(", "arg_0", ",", "arg_0", ".", "kernel_manager", ",", "arg_0", ".", "notebook_manager", ",", "arg_0", ".", "cluster_manager", ",", "arg_0", ".", "log", ",", "arg_0", ".", "base_project_url", ",", "arg_0", ".", "webapp_settings", ")", "if", "arg_0", ".", "certfile", ":", "arg_2", "=", "dict", "(", "certfile", "=", "arg_0", ".", "certfile", ")", "if", "arg_0", ".", "keyfile", ":", "arg_2", "[", "'keyfile'", "]", "=", "arg_0", ".", "keyfile", "else", ":", "arg_2", "=", "None", "arg_0", ".", "web_app", ".", "password", "=", "arg_0", ".", "password", "arg_0", ".", "http_server", "=", "httpserver", ".", "HTTPServer", "(", "arg_0", ".", "web_app", ",", "arg_2", "=", "arg_2", ")", "if", "arg_2", "is", "None", "and", "not", "arg_0", ".", "ip", "and", "not", "(", "arg_0", ".", "read_only", "and", "not", "arg_0", ".", "password", ")", ":", "arg_0", ".", "log", ".", "critical", "(", "'WARNING: the notebook server is listening on all IP addresses '", "'but not using any encryption or authentication. This is highly '", "'insecure and not recommended.'", ")", "arg_5", "=", "None", "for", "arg_6", "in", "random_ports", "(", "arg_0", ".", "port", ",", "arg_0", ".", "port_retries", "+", "1", ")", ":", "try", ":", "arg_0", ".", "http_server", ".", "listen", "(", "arg_6", ",", "arg_0", ".", "ip", ")", "except", "socket", ".", "error", ",", "e", ":", "if", "e", ".", "errno", "!=", "errno", ".", "EADDRINUSE", ":", "raise", "arg_0", ".", "log", ".", "info", "(", "'The port %i is already in use, trying another random port.'", "%", "arg_6", ")", "else", ":", "arg_0", ".", "port", "=", "arg_6", "arg_5", "=", "True", "break", "if", "not", "arg_5", ":", "arg_0", ".", "log", ".", "critical", "(", "'ERROR: the notebook server could not be started because '", "'no available port could be found.'", ")", "arg_0", ".", "exit", "(", "1", ")"], "function": "def Func(arg_0):\n        \"\"\"initialize tornado webapp and httpserver\"\"\"\n        arg_0.web_app = NotebookWebApplication(\n            arg_0, arg_0.kernel_manager, arg_0.notebook_manager, \n            arg_0.cluster_manager, arg_0.log,\n            arg_0.base_project_url, arg_0.webapp_settings\n        )\n        if arg_0.certfile:\n            arg_2 = dict(certfile=arg_0.certfile)\n            if arg_0.keyfile:\n                arg_2['keyfile'] = arg_0.keyfile\n        else:\n            arg_2 = None\n        arg_0.web_app.password = arg_0.password\n        arg_0.http_server = httpserver.HTTPServer(arg_0.web_app, arg_2=arg_2)\n        if arg_2 is None and not arg_0.ip and not (arg_0.read_only and not arg_0.password):\n            arg_0.log.critical('WARNING: the notebook server is listening on all IP addresses '\n                              'but not using any encryption or authentication. This is highly '\n                              'insecure and not recommended.')\n\n        arg_5 = None\n        for arg_6 in random_ports(arg_0.port, arg_0.port_retries+1):\n            try:\n                arg_0.http_server.listen(arg_6, arg_0.ip)\n            except socket.error, e:\n                if e.errno != errno.EADDRINUSE:\n                    raise\n                arg_0.log.info('The port %i is already in use, trying another random port.' % arg_6)\n            else:\n                arg_0.port = arg_6\n                arg_5 = True\n                break\n        if not arg_5:\n            arg_0.log.critical('ERROR: the notebook server could not be started because '\n                              'no available port could be found.')\n            arg_0.exit(1)", "path": "environment/lib/python2.7/site-packages/IPython/frontend/html/notebook/notebookapp.py", "identifier": "NotebookApp.init_webapp", "docstring": "initialize tornado webapp and httpserver", "docstring_tokens": ["initialize", "tornado", "webapp", "and", "httpserver"], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 274285}
{"url": "https://github.com/marrabld/planarradpy/blob/5095d1cb98d4f67a7c3108c9282f2d59253e89a8/libplanarradpy/planrad.py#L496-L502", "sha": "5095d1cb98d4f67a7c3108c9282f2d59253e89a8", "docstring_summary": "Calculates the total absorption from water, phytoplankton and CDOM", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "lg", ".", "info", "(", "'Building total absorption'", ")", "arg_0", ".", "a", "=", "arg_0", ".", "a_water", "+", "arg_0", ".", "a_cdom", "+", "arg_0", ".", "a_phi"], "function": "def Func(arg_0):\n        \"\"\"Calculates the total absorption from water, phytoplankton and CDOM\n\n        a = awater + acdom + aphi\n        \"\"\"\n        lg.info('Building total absorption')\n        arg_0.a = arg_0.a_water + arg_0.a_cdom + arg_0.a_phi", "path": "libplanarradpy/planrad.py", "identifier": "BioOpticalParameters.build_a", "docstring": "Calculates the total absorption from water, phytoplankton and CDOM\n\n        a = awater + acdom + aphi", "docstring_tokens": ["Calculates", "the", "total", "absorption", "from", "water", "phytoplankton", "and", "CDOM"], "nwo": "marrabld/planarradpy", "score": 0.21302904236143622, "idx": 268077}
{"url": "https://github.com/CalebBell/thermo/blob/3857ed023a3e64fd3039a32d53576c24990ef1c3/thermo/identifiers.py#L35-L81", "sha": "3857ed023a3e64fd3039a32d53576c24990ef1c3", "docstring_summary": "Checks if a CAS number is valid. Returns False if the parser cannot \n    parse the given string..", "language": "python", "parameters": "(CASRN)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "try", ":", "arg_1", "=", "arg_0", "[", "-", "1", "]", "arg_0", "=", "arg_0", "[", ":", ":", "-", "1", "]", "[", "1", ":", "]", "arg_2", "=", "0", "arg_3", "=", "1", "for", "arg_4", "in", "arg_0", ":", "if", "arg_4", "==", "'-'", ":", "pass", "else", ":", "arg_2", "+=", "arg_3", "*", "int", "(", "arg_4", ")", "arg_3", "+=", "1", "return", "(", "arg_2", "%", "10", "==", "int", "(", "arg_1", ")", ")", "except", ":", "return", "False"], "function": "def Func(arg_0):\n    '''Checks if a CAS number is valid. Returns False if the parser cannot \n    parse the given string..\n\n    Parameters\n    ----------\n    CASRN : string\n        A three-piece, dash-separated set of numbers\n\n    Returns\n    -------\n    result : bool\n        Boolean value if CASRN was valid. If parsing fails, return False also.\n\n    Notes\n    -----\n    Check method is according to Chemical Abstract Society. However, no lookup\n    to their service is performed; therefore, this function cannot detect\n    false positives.\n\n    Function also does not support additional separators, apart from '-'.\n    \n    CAS numbers up to the series 1 XXX XXX-XX-X are now being issued.\n    \n    A long can hold CAS numbers up to 2 147 483-64-7\n\n    Examples\n    --------\n    >>> Func('7732-18-5')\n    True\n    >>> Func('77332-18-5')\n    False\n    '''\n    try:\n        arg_1 = arg_0[-1]\n        arg_0 = arg_0[::-1][1:]\n        arg_2 = 0\n        arg_3 = 1\n        for arg_4 in arg_0:\n            if arg_4 == '-':\n                pass\n            else:\n                arg_2 += arg_3*int(arg_4)\n                arg_3 += 1\n        return (arg_2 % 10 == int(arg_1))\n    except:\n        return False", "path": "thermo/identifiers.py", "identifier": "checkCAS", "docstring": "Checks if a CAS number is valid. Returns False if the parser cannot \n    parse the given string..\n\n    Parameters\n    ----------\n    CASRN : string\n        A three-piece, dash-separated set of numbers\n\n    Returns\n    -------\n    result : bool\n        Boolean value if CASRN was valid. If parsing fails, return False also.\n\n    Notes\n    -----\n    Check method is according to Chemical Abstract Society. However, no lookup\n    to their service is performed; therefore, this function cannot detect\n    false positives.\n\n    Function also does not support additional separators, apart from '-'.\n    \n    CAS numbers up to the series 1 XXX XXX-XX-X are now being issued.\n    \n    A long can hold CAS numbers up to 2 147 483-64-7\n\n    Examples\n    --------\n    >>> checkCAS('7732-18-5')\n    True\n    >>> checkCAS('77332-18-5')\n    False", "docstring_tokens": ["Checks", "if", "a", "CAS", "number", "is", "valid", ".", "Returns", "False", "if", "the", "parser", "cannot", "parse", "the", "given", "string", ".."], "nwo": "CalebBell/thermo", "score": 0.7491901936017268, "idx": 266760}
{"url": "https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/classes.py#L742-L754", "sha": "2bf5c61a3ff6ae90613b81679de42c0f19aea600", "docstring_summary": "init visit variable _accessed", "language": "python", "parameters": "(self, node)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_0", ".", "_check_bases_classes", "(", "arg_1", ")", "if", "arg_1", ".", "type", "==", "\"class\"", "and", "has_known_bases", "(", "arg_1", ")", ":", "try", ":", "arg_1", ".", "local_attr", "(", "\"__init__\"", ")", "except", "astroid", ".", "NotFoundError", ":", "arg_0", ".", "add_message", "(", "\"no-init\"", ",", "args", "=", "arg_1", ",", "arg_1", "=", "arg_1", ")", "arg_0", ".", "_check_slots", "(", "arg_1", ")", "arg_0", ".", "_check_proper_bases", "(", "arg_1", ")", "arg_0", ".", "_check_consistent_mro", "(", "arg_1", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"init visit variable _accessed\n        \"\"\"\n        arg_0._check_bases_classes(arg_1)\n        # if not an exception or a metaclass\n        if arg_1.type == \"class\" and has_known_bases(arg_1):\n            try:\n                arg_1.local_attr(\"__init__\")\n            except astroid.NotFoundError:\n                arg_0.add_message(\"no-init\", args=arg_1, arg_1=arg_1)\n        arg_0._check_slots(arg_1)\n        arg_0._check_proper_bases(arg_1)\n        arg_0._check_consistent_mro(arg_1)", "path": "pylint/checkers/classes.py", "identifier": "ClassChecker.visit_classdef", "docstring": "init visit variable _accessed", "docstring_tokens": ["init", "visit", "variable", "_accessed"], "nwo": "PyCQA/pylint", "score": 0.7960905782143469, "idx": 265803}
{"url": "https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/internal/tensorshape_util.py#L144-L160", "sha": "e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5", "docstring_summary": "Returns a list of dimension sizes, or `None` if `rank` is unknown.", "language": "python", "parameters": "(x)", "return_statement": "return None if r is None else list(map(tf.compat.dimension_value, r))", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "if", "isinstance", "(", "arg_0", ",", "tf", ".", "TensorShape", ")", ":", "return", "arg_0", ".", "Func", "arg_1", "=", "tf", ".", "TensorShape", "(", "arg_0", ")", ".", "Func", "return", "None", "if", "arg_1", "is", "None", "else", "list", "(", "map", "(", "tf", ".", "compat", ".", "dimension_value", ",", "arg_1", ")", ")"], "function": "def Func(arg_0):\n  \"\"\"Returns a list of dimension sizes, or `None` if `rank` is unknown.\n\n  For more details, see `help(tf.TensorShape.Func)`.\n\n  Args:\n    x: object representing a shape; convertible to `tf.TensorShape`.\n\n  Returns:\n    shape_as_list: list of sizes or `None` values representing each\n      dimensions size if known. A size is `tf.Dimension` if input is a\n      `tf.TensorShape` and an `int` otherwise.\n  \"\"\"\n  if isinstance(arg_0, tf.TensorShape):\n    return arg_0.Func\n  arg_1 = tf.TensorShape(arg_0).Func\n  return None if arg_1 is None else list(map(tf.compat.dimension_value, arg_1))", "path": "tensorflow_probability/python/internal/tensorshape_util.py", "identifier": "dims", "docstring": "Returns a list of dimension sizes, or `None` if `rank` is unknown.\n\n  For more details, see `help(tf.TensorShape.dims)`.\n\n  Args:\n    x: object representing a shape; convertible to `tf.TensorShape`.\n\n  Returns:\n    shape_as_list: list of sizes or `None` values representing each\n      dimensions size if known. A size is `tf.Dimension` if input is a\n      `tf.TensorShape` and an `int` otherwise.", "docstring_tokens": ["Returns", "a", "list", "of", "dimension", "sizes", "or", "None", "if", "rank", "is", "unknown", "."], "nwo": "tensorflow/probability", "score": 0.9937575147981225, "idx": 277422}
{"url": "https://github.com/seenaburns/Tungsten/blob/9e865c77a11c512464f226a6b025bc43b798a8be/tungsten/core.py#L18-L45", "sha": "9e865c77a11c512464f226a6b025bc43b798a8be", "docstring_summary": "Query Wolfram Alpha and return a Result object", "language": "python", "parameters": "(self, input = '', params = {})", "return_statement": "return Result(xml = r.text)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "''", ",", "arg_2", "=", "{", "}", ")", ":", "arg_3", "=", "{", "'input'", ":", "arg_1", ",", "'appid'", ":", "arg_0", ".", "appid", "}", "for", "arg_4", ",", "arg_5", "in", "arg_2", ".", "items", "(", ")", ":", "if", "isinstance", "(", "arg_5", ",", "(", "list", ",", "tuple", ")", ")", ":", "arg_3", "[", "arg_4", "]", "=", "','", ".", "join", "(", "arg_5", ")", "else", ":", "arg_3", "[", "arg_4", "]", "=", "arg_5", "try", ":", "arg_6", "=", "requests", ".", "get", "(", "\"http://api.wolframalpha.com/v2/Func\"", ",", "arg_2", "=", "arg_3", ")", "if", "arg_6", ".", "status_code", "!=", "200", ":", "raise", "Exception", "(", "'Invalid response status code: %s'", "%", "(", "arg_6", ".", "status_code", ")", ")", "if", "arg_6", ".", "encoding", "!=", "'utf-8'", ":", "raise", "Exception", "(", "'Invalid encoding: %s'", "%", "(", "arg_6", ".", "encoding", ")", ")", "except", "Exception", ",", "e", ":", "return", "Result", "(", "error", "=", "e", ")", "return", "Result", "(", "xml", "=", "arg_6", ".", "text", ")"], "function": "def Func(arg_0, arg_1 = '', arg_2 = {}):\n        \"\"\"Query Wolfram Alpha and return a Result object\"\"\"\n        # Get and construct Func parameters\n        # Default parameters\n        arg_3 = {'input': arg_1,\n                    'appid': arg_0.appid}\n        # Additional parameters (from params), formatted for url\n        for arg_4, arg_5 in arg_2.items():\n            # Check if value is list or tuple type (needs to be comma joined)\n            if isinstance(arg_5, (list, tuple)):\n                arg_3[arg_4] = ','.join(arg_5)\n            else:\n                arg_3[arg_4] = arg_5\n\n        # Catch any issues with connecting to Wolfram Alpha API\n        try:\n            arg_6 = requests.get(\"http://api.wolframalpha.com/v2/Func\", arg_2=arg_3)\n\n            # Raise Exception (to be returned as error)\n            if arg_6.status_code != 200:\n                raise Exception('Invalid response status code: %s' % (arg_6.status_code))\n            if arg_6.encoding != 'utf-8':\n                raise Exception('Invalid encoding: %s' % (arg_6.encoding))\n\n        except Exception, e:\n            return Result(error = e)\n\n        return Result(xml = arg_6.text)", "path": "tungsten/core.py", "identifier": "Tungsten.query", "docstring": "Query Wolfram Alpha and return a Result object", "docstring_tokens": ["Query", "Wolfram", "Alpha", "and", "return", "a", "Result", "object"], "nwo": "seenaburns/Tungsten", "score": 0.17385480483333982, "idx": 271092}
{"url": "https://github.com/refenv/cijoe/blob/21d7b2ed4ff68e0a1457e7df2db27f6334f1a379/modules/cij/__init__.py#L136-L142", "sha": "21d7b2ed4ff68e0a1457e7df2db27f6334f1a379", "docstring_summary": "Define the list of 'exported' variables with 'prefix' with values from 'env'", "language": "python", "parameters": "(prefix, exported, env)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "for", "arg_3", "in", "arg_1", ":", "arg_4", "[", "\"_\"", ".", "join", "(", "[", "arg_0", ",", "arg_3", "]", ")", "]", "=", "arg_2", "[", "arg_3", "]"], "function": "def Func(arg_0, arg_1, arg_2):\n    \"\"\"\n    Define the list of 'exported' variables with 'prefix' with values from 'env'\n    \"\"\"\n\n    for arg_3 in arg_1:\n        arg_4[\"_\".join([arg_0, arg_3])] = arg_2[arg_3]", "path": "modules/cij/__init__.py", "identifier": "env_export", "docstring": "Define the list of 'exported' variables with 'prefix' with values from 'env'", "docstring_tokens": ["Define", "the", "list", "of", "exported", "variables", "with", "prefix", "with", "values", "from", "env"], "nwo": "refenv/cijoe", "score": 0.665287191474368, "idx": 271728}
{"url": "https://github.com/Ex-Mente/auxi.0/blob/2dcdae74154f136f8ca58289fe5b20772f215046/auxi/modelling/process/materials/thermo.py#L1588-L1595", "sha": "2dcdae74154f136f8ca58289fe5b20772f215046", "docstring_summary": "Create a complete copy of the stream.", "language": "python", "parameters": "(self)", "return_statement": "return result", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "copy", ".", "copy", "(", "arg_0", ")", "arg_1", ".", "_compound_mfrs", "=", "copy", ".", "deepcopy", "(", "arg_0", ".", "_compound_mfrs", ")", "return", "arg_1"], "function": "def Func(arg_0):\n        \"\"\"Create a complete copy of the stream.\n\n        :returns: A new MaterialStream object.\"\"\"\n\n        arg_1 = copy.copy(arg_0)\n        arg_1._compound_mfrs = copy.deepcopy(arg_0._compound_mfrs)\n        return arg_1", "path": "auxi/modelling/process/materials/thermo.py", "identifier": "MaterialStream.clone", "docstring": "Create a complete copy of the stream.\n\n        :returns: A new MaterialStream object.", "docstring_tokens": ["Create", "a", "complete", "copy", "of", "the", "stream", "."], "nwo": "Ex-Mente/auxi.0", "score": 0.2778869743536733, "idx": 278816}
{"url": "https://github.com/mseclab/PyJFuzz/blob/f777067076f62c9ab74ffea6e90fd54402b7a1b4/pyjfuzz/core/pjf_executor.py#L51-L73", "sha": "f777067076f62c9ab74ffea6e90fd54402b7a1b4", "docstring_summary": "Spawn a new process using subprocess", "language": "python", "parameters": "(self, cmd, stdin_content=\"\", stdin=False, shell=False, timeout=2)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "\"\"", ",", "arg_3", "=", "False", ",", "arg_4", "=", "False", ",", "arg_5", "=", "2", ")", ":", "try", ":", "if", "type", "(", "arg_1", ")", "!=", "list", ":", "raise", "PJFInvalidType", "(", "type", "(", "arg_1", ")", ",", "list", ")", "if", "type", "(", "arg_2", ")", "!=", "str", ":", "raise", "PJFInvalidType", "(", "type", "(", "arg_2", ")", ",", "str", ")", "if", "type", "(", "arg_3", ")", "!=", "bool", ":", "raise", "PJFInvalidType", "(", "type", "(", "arg_3", ")", ",", "bool", ")", "arg_0", ".", "_in", "=", "arg_2", "try", ":", "arg_0", ".", "process", "=", "subprocess", ".", "Popen", "(", "arg_1", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", ",", "arg_3", "=", "PIPE", ",", "arg_4", "=", "arg_4", ")", "arg_0", ".", "finish_read", "(", "arg_5", ",", "arg_2", ",", "arg_3", ")", "if", "arg_0", ".", "process", ".", "poll", "(", ")", "is", "not", "None", ":", "arg_0", ".", "close", "(", ")", "except", "KeyboardInterrupt", ":", "return", "except", "OSError", ":", "raise", "PJFProcessExecutionError", "(", "\"Binary <%s> does not exist\"", "%", "arg_1", "[", "0", "]", ")", "except", "Exception", "as", "e", ":", "raise", "PJFBaseException", "(", "e", ".", "message", "if", "hasattr", "(", "e", ",", "\"message\"", ")", "else", "str", "(", "e", ")", ")"], "function": "def Func(arg_0, arg_1, arg_2=\"\", arg_3=False, arg_4=False, arg_5=2):\n        \"\"\"\n        Spawn a new process using subprocess\n        \"\"\"\n        try:\n            if type(arg_1) != list:\n                raise PJFInvalidType(type(arg_1), list)\n            if type(arg_2) != str:\n                raise PJFInvalidType(type(arg_2), str)\n            if type(arg_3) != bool:\n                raise PJFInvalidType(type(arg_3), bool)\n            arg_0._in = arg_2\n            try:\n                arg_0.process = subprocess.Popen(arg_1, stdout=PIPE, stderr=PIPE, arg_3=PIPE, arg_4=arg_4)\n                arg_0.finish_read(arg_5, arg_2, arg_3)\n                if arg_0.process.poll() is not None:\n                    arg_0.close()\n            except KeyboardInterrupt:\n                return\n        except OSError:\n            raise PJFProcessExecutionError(\"Binary <%s> does not exist\" % arg_1[0])\n        except Exception as e:\n            raise PJFBaseException(e.message if hasattr(e, \"message\") else str(e))", "path": "pyjfuzz/core/pjf_executor.py", "identifier": "PJFExecutor.spawn", "docstring": "Spawn a new process using subprocess", "docstring_tokens": ["Spawn", "a", "new", "process", "using", "subprocess"], "nwo": "mseclab/PyJFuzz", "score": 0.7046043146469614, "idx": 261705}
{"url": "https://github.com/spdx/tools-python/blob/301d72f6ae57c832c1da7f6402fa49b192de6810/spdx/parsers/rdf.py#L956-L988", "sha": "301d72f6ae57c832c1da7f6402fa49b192de6810", "docstring_summary": "Parses the External Document ID, SPDX Document URI and Checksum.", "language": "python", "parameters": "(self, ext_doc_ref_term)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "for", "arg_2", ",", "arg_3", ",", "arg_4", "in", "arg_0", ".", "graph", ".", "triples", "(", "(", "arg_1", ",", "arg_0", ".", "spdx_namespace", "[", "'externalDocumentId'", "]", ",", "None", ")", ")", ":", "try", ":", "arg_0", ".", "builder", ".", "set_ext_doc_id", "(", "arg_0", ".", "doc", ",", "six", ".", "text_type", "(", "arg_4", ")", ")", "except", "SPDXValueError", ":", "arg_0", ".", "value_error", "(", "'EXT_DOC_REF_VALUE'", ",", "'External Document ID'", ")", "break", "for", "arg_2", ",", "arg_3", ",", "arg_4", "in", "arg_0", ".", "graph", ".", "triples", "(", "(", "arg_1", ",", "arg_0", ".", "spdx_namespace", "[", "'spdxDocument'", "]", ",", "None", ")", ")", ":", "try", ":", "arg_0", ".", "builder", ".", "set_spdx_doc_uri", "(", "arg_0", ".", "doc", ",", "six", ".", "text_type", "(", "arg_4", ")", ")", "except", "SPDXValueError", ":", "arg_0", ".", "value_error", "(", "'EXT_DOC_REF_VALUE'", ",", "'SPDX Document URI'", ")", "break", "for", "arg_2", ",", "arg_3", ",", "arg_5", "in", "arg_0", ".", "graph", ".", "triples", "(", "(", "arg_1", ",", "arg_0", ".", "spdx_namespace", "[", "'checksum'", "]", ",", "None", ")", ")", ":", "for", "arg_6", ",", "arg_6", ",", "arg_7", "in", "arg_0", ".", "graph", ".", "triples", "(", "(", "arg_5", ",", "arg_0", ".", "spdx_namespace", "[", "'checksumValue'", "]", ",", "None", ")", ")", ":", "try", ":", "arg_0", ".", "builder", ".", "set_chksum", "(", "arg_0", ".", "doc", ",", "six", ".", "text_type", "(", "arg_7", ")", ")", "except", "SPDXValueError", ":", "arg_0", ".", "value_error", "(", "'EXT_DOC_REF_VALUE'", ",", "'Checksum'", ")", "break"], "function": "def Func(arg_0, arg_1):\n        \"\"\"\n        Parses the External Document ID, SPDX Document URI and Checksum.\n        \"\"\"\n        for arg_2, arg_3, arg_4 in arg_0.graph.triples(\n                (arg_1,\n                 arg_0.spdx_namespace['externalDocumentId'],\n                 None)):\n            try:\n                arg_0.builder.set_ext_doc_id(arg_0.doc, six.text_type(arg_4))\n            except SPDXValueError:\n                arg_0.value_error('EXT_DOC_REF_VALUE', 'External Document ID')\n                break\n\n        for arg_2, arg_3, arg_4 in arg_0.graph.triples(\n                (arg_1,\n                 arg_0.spdx_namespace['spdxDocument'],\n                 None)):\n            try:\n                arg_0.builder.set_spdx_doc_uri(arg_0.doc, six.text_type(arg_4))\n            except SPDXValueError:\n                arg_0.value_error('EXT_DOC_REF_VALUE', 'SPDX Document URI')\n                break\n\n        for arg_2, arg_3, arg_5 in arg_0.graph.triples(\n                (arg_1, arg_0.spdx_namespace['checksum'], None)):\n            for arg_6, arg_6, arg_7 in arg_0.graph.triples(\n                    (arg_5, arg_0.spdx_namespace['checksumValue'], None)):\n                try:\n                    arg_0.builder.set_chksum(arg_0.doc, six.text_type(arg_7))\n                except SPDXValueError:\n                    arg_0.value_error('EXT_DOC_REF_VALUE', 'Checksum')\n                    break", "path": "spdx/parsers/rdf.py", "identifier": "Parser.parse_ext_doc_ref", "docstring": "Parses the External Document ID, SPDX Document URI and Checksum.", "docstring_tokens": ["Parses", "the", "External", "Document", "ID", "SPDX", "Document", "URI", "and", "Checksum", "."], "nwo": "spdx/tools-python", "score": 0.8936869982558252, "idx": 272481}
{"url": "https://github.com/oscarbranson/latools/blob/cd25a650cfee318152f234d992708511f7047fbe/latools/helpers/helpers.py#L239-L260", "sha": "cd25a650cfee318152f234d992708511f7047fbe", "docstring_summary": "Consecutively numbers contiguous booleans in array.", "language": "python", "parameters": "(bool_array, nstart=0)", "return_statement": "return ns", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "0", ")", ":", "arg_2", "=", "bool_2_indices", "(", "arg_0", ")", "arg_3", "=", "np", ".", "full", "(", "arg_0", ".", "size", ",", "arg_1", ",", "dtype", "=", "int", ")", "for", "arg_4", ",", "arg_5", "in", "enumerate", "(", "arg_2", ")", ":", "arg_3", "[", "arg_5", "[", "0", "]", ":", "arg_5", "[", "-", "1", "]", "+", "1", "]", "=", "arg_1", "+", "arg_4", "+", "1", "return", "arg_3"], "function": "def Func(arg_0, arg_1=0):\n    \"\"\"\n    Consecutively numbers contiguous booleans in array.\n\n    i.e. a boolean sequence, and resulting numbering\n    T F T T T F T F F F T T F\n    0-1 1 1 - 2 ---3 3 -\n\n    where ' - '\n\n    Parameters\n    ----------\n    bool_array : array_like\n        Array of booleans.\n    nstart : int\n        The number of the first boolean group.\n    \"\"\"\n    arg_2 = bool_2_indices(arg_0)\n    arg_3 = np.full(arg_0.size, arg_1, dtype=int)\n    for arg_4, arg_5 in enumerate(arg_2):\n        arg_3[arg_5[0]:arg_5[-1] + 1] = arg_1 + arg_4 + 1\n    return arg_3", "path": "latools/helpers/helpers.py", "identifier": "enumerate_bool", "docstring": "Consecutively numbers contiguous booleans in array.\n\n    i.e. a boolean sequence, and resulting numbering\n    T F T T T F T F F F T T F\n    0-1 1 1 - 2 ---3 3 -\n\n    where ' - '\n\n    Parameters\n    ----------\n    bool_array : array_like\n        Array of booleans.\n    nstart : int\n        The number of the first boolean group.", "docstring_tokens": ["Consecutively", "numbers", "contiguous", "booleans", "in", "array", "."], "nwo": "oscarbranson/latools", "score": 0.2827006957945985, "idx": 267282}
{"url": "https://github.com/LuminosoInsight/luminoso-api-client-python/blob/3bedf2a454aee39214c11fbf556ead3eecc27881/luminoso_api/v5_download.py#L95-L138", "sha": "3bedf2a454aee39214c11fbf556ead3eecc27881", "docstring_summary": "Handle arguments for the 'lumi-download' command.", "language": "python", "parameters": "(argv)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "DESCRIPTION", ",", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ")", "arg_1", ".", "add_argument", "(", "'-b'", ",", "'--base-url'", ",", "default", "=", "URL_BASE", ",", "help", "=", "'API root url, default: %s'", "%", "URL_BASE", ",", ")", "arg_1", ".", "add_argument", "(", "'-e'", ",", "'--expanded'", ",", "help", "=", "\"Include Luminoso's analysis of each document, such as terms and\"", "' document vectors'", ",", "action", "=", "'store_true'", ",", ")", "arg_1", ".", "add_argument", "(", "'-t'", ",", "'--token'", ",", "help", "=", "'API authentication token'", ")", "arg_1", ".", "add_argument", "(", "'-s'", ",", "'--save-token'", ",", "action", "=", "'store_true'", ",", "help", "=", "'save --token for --base-url to ~/.luminoso/tokens.json'", ",", ")", "arg_1", ".", "add_argument", "(", "'project_id'", ",", "help", "=", "'The ID of the project in the Daylight API'", ")", "arg_1", ".", "add_argument", "(", "'output_file'", ",", "nargs", "=", "'?'", ",", "default", "=", "None", ",", "help", "=", "'The JSON lines (.jsons) file to write to'", ")", "arg_2", "=", "arg_1", ".", "parse_args", "(", "arg_0", ")", "if", "arg_2", ".", "save_token", ":", "if", "not", "arg_2", ".", "token", ":", "raise", "ValueError", "(", "\"error: no token provided\"", ")", "LuminosoClient", ".", "save_token", "(", "arg_2", ".", "token", ",", "domain", "=", "urlparse", "(", "arg_2", ".", "base_url", ")", ".", "netloc", ")", "arg_3", "=", "LuminosoClient", ".", "connect", "(", "url", "=", "arg_2", ".", "base_url", ",", "token", "=", "arg_2", ".", "token", ")", "arg_4", "=", "arg_3", ".", "client_for_path", "(", "'projects/{}'", ".", "format", "(", "arg_2", ".", "project_id", ")", ")", "download_docs", "(", "arg_4", ",", "arg_2", ".", "output_file", ",", "arg_2", ".", "expanded", ")"], "function": "def Func(arg_0):\n    \"\"\"\n    Handle arguments for the 'lumi-download' command.\n    \"\"\"\n    arg_1 = argparse.ArgumentParser(\n        description=DESCRIPTION,\n        formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n    arg_1.add_argument(\n        '-b',\n        '--base-url',\n        default=URL_BASE,\n        help='API root url, default: %s' % URL_BASE,\n    )\n    arg_1.add_argument(\n        '-e', '--expanded',\n        help=\"Include Luminoso's analysis of each document, such as terms and\"\n             ' document vectors',\n        action='store_true',\n    )\n    arg_1.add_argument('-t', '--token', help='API authentication token')\n    arg_1.add_argument(\n        '-s',\n        '--save-token',\n        action='store_true',\n        help='save --token for --base-url to ~/.luminoso/tokens.json',\n    )\n    arg_1.add_argument(\n        'project_id', help='The ID of the project in the Daylight API'\n    )\n    arg_1.add_argument(\n        'output_file', nargs='?', default=None,\n        help='The JSON lines (.jsons) file to write to'\n    )\n    arg_2 = arg_1.parse_args(arg_0)\n    if arg_2.save_token:\n        if not arg_2.token:\n            raise ValueError(\"error: no token provided\")\n        LuminosoClient.save_token(arg_2.token,\n                                  domain=urlparse(arg_2.base_url).netloc)\n\n    arg_3 = LuminosoClient.connect(url=arg_2.base_url, token=arg_2.token)\n    arg_4 = arg_3.client_for_path('projects/{}'.format(arg_2.project_id))\n    download_docs(arg_4, arg_2.output_file, arg_2.expanded)", "path": "luminoso_api/v5_download.py", "identifier": "_main", "docstring": "Handle arguments for the 'lumi-download' command.", "docstring_tokens": ["Handle", "arguments", "for", "the", "lumi", "-", "download", "command", "."], "nwo": "LuminosoInsight/luminoso-api-client-python", "score": 0.568966879505561, "idx": 261783}
{"url": "https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/adapter/mongo/hpo.py#L126-L144", "sha": "90a551e2e1653a319e654c2405c2866f93d0ebb9", "docstring_summary": "Return all disease terms that overlaps a gene", "language": "python", "parameters": "(self, hgnc_id=None)", "return_statement": "return list(self.disease_term_collection.find(query))", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ")", ":", "arg_2", "=", "{", "}", "if", "arg_1", ":", "LOG", ".", "debug", "(", "\"Fetching all diseases for gene %s\"", ",", "arg_1", ")", "arg_2", "[", "'genes'", "]", "=", "arg_1", "else", ":", "LOG", ".", "info", "(", "\"Fetching all disease terms\"", ")", "return", "list", "(", "arg_0", ".", "disease_term_collection", ".", "find", "(", "arg_2", ")", ")"], "function": "def Func(arg_0, arg_1=None):\n        \"\"\"Return all disease terms that overlaps a gene\n\n            If no gene, return all disease terms\n\n        Args:\n            hgnc_id(int)\n\n        Returns:\n            iterable(dict): A list with all disease terms that match\n        \"\"\"\n        arg_2 = {}\n        if arg_1:\n            LOG.debug(\"Fetching all diseases for gene %s\", arg_1)\n            arg_2['genes'] = arg_1\n        else:\n            LOG.info(\"Fetching all disease terms\")\n\n        return list(arg_0.disease_term_collection.find(arg_2))", "path": "scout/adapter/mongo/hpo.py", "identifier": "HpoHandler.disease_terms", "docstring": "Return all disease terms that overlaps a gene\n\n            If no gene, return all disease terms\n\n        Args:\n            hgnc_id(int)\n\n        Returns:\n            iterable(dict): A list with all disease terms that match", "docstring_tokens": ["Return", "all", "disease", "terms", "that", "overlaps", "a", "gene"], "nwo": "Clinical-Genomics/scout", "score": 0.41124813484918504, "idx": 277971}
{"url": "https://github.com/calston/tensor/blob/7c0c99708b5dbff97f3895f705e11996b608549d/tensor/logs/follower.py#L88-L95", "sha": "7c0c99708b5dbff97f3895f705e11996b608549d", "docstring_summary": "Returns a big list of all log lines since the last run", "language": "python", "parameters": "(self, max_lines=None)", "return_statement": "return rows", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ")", ":", "arg_2", "=", "[", "]", "arg_0", ".", "Func_fn", "(", "lambda", "row", ":", "arg_2", ".", "append", "(", "row", ")", ",", "arg_1", "=", "arg_1", ")", "return", "arg_2"], "function": "def Func(arg_0, arg_1=None):\n        \"\"\"Returns a big list of all log lines since the last run\n        \"\"\"\n        arg_2 = []\n\n        arg_0.Func_fn(lambda row: arg_2.append(row), arg_1=arg_1)\n\n        return arg_2", "path": "tensor/logs/follower.py", "identifier": "LogFollower.get", "docstring": "Returns a big list of all log lines since the last run", "docstring_tokens": ["Returns", "a", "big", "list", "of", "all", "log", "lines", "since", "the", "last", "run"], "nwo": "calston/tensor", "score": 0.2718259314615454, "idx": 264891}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/terminal/console/interactiveshell.py#L220-L233", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "method to wait for a kernel to be ready", "language": "python", "parameters": "(self, timeout=None)", "return_statement": "return True", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ")", ":", "arg_2", "=", "time", ".", "time", "(", ")", "arg_0", ".", "km", ".", "hb_channel", ".", "unpause", "(", ")", "while", "True", ":", "arg_0", ".", "run_cell", "(", "'1'", ",", "False", ")", "if", "arg_0", ".", "km", ".", "hb_channel", ".", "is_beating", "(", ")", ":", "break", "else", ":", "if", "arg_1", "is", "not", "None", "and", "(", "time", ".", "time", "(", ")", "-", "arg_2", ")", ">", "arg_1", ":", "return", "False", "return", "True"], "function": "def Func(arg_0, arg_1=None):\n        \"\"\"method to wait for a kernel to be ready\"\"\"\n        arg_2 = time.time()\n        arg_0.km.hb_channel.unpause()\n        while True:\n            arg_0.run_cell('1', False)\n            if arg_0.km.hb_channel.is_beating():\n                # heart failure was not the reason this returned\n                break\n            else:\n                # heart failed\n                if arg_1 is not None and (time.time() - arg_2) > arg_1:\n                    return False\n        return True", "path": "environment/lib/python2.7/site-packages/IPython/frontend/terminal/console/interactiveshell.py", "identifier": "ZMQTerminalInteractiveShell.wait_for_kernel", "docstring": "method to wait for a kernel to be ready", "docstring_tokens": ["method", "to", "wait", "for", "a", "kernel", "to", "be", "ready"], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 279739}
{"url": "https://github.com/its-rigs/Trolly/blob/483dc94c352df40dc05ead31820b059b2545cf82/trolly/organisation.py#L78-L90", "sha": "483dc94c352df40dc05ead31820b059b2545cf82", "docstring_summary": "Add a member to the board using the id. Membership type can be\n        normal or admin. Returns JSON of all members if successful or raises an\n        Unauthorised exception if not.", "language": "python", "parameters": "(self, member_id, membership_type='normal')", "return_statement": "return self.fetch_json(\n            uri_path=self.base_uri + '/members/%s' % member_id,\n            http_method='PUT',\n            query_params={\n                'type': membership_type\n            }\n        )", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "'normal'", ")", ":", "return", "arg_0", ".", "fetch_json", "(", "uri_path", "=", "arg_0", ".", "base_uri", "+", "'/members/%s'", "%", "arg_1", ",", "http_method", "=", "'PUT'", ",", "query_params", "=", "{", "'type'", ":", "arg_2", "}", ")"], "function": "def Func(arg_0, arg_1, arg_2='normal'):\n        '''\n        Add a member to the board using the id. Membership type can be\n        normal or admin. Returns JSON of all members if successful or raises an\n        Unauthorised exception if not.\n        '''\n        return arg_0.fetch_json(\n            uri_path=arg_0.base_uri + '/members/%s' % arg_1,\n            http_method='PUT',\n            query_params={\n                'type': arg_2\n            }\n        )", "path": "trolly/organisation.py", "identifier": "Organisation.add_member_by_id", "docstring": "Add a member to the board using the id. Membership type can be\n        normal or admin. Returns JSON of all members if successful or raises an\n        Unauthorised exception if not.", "docstring_tokens": ["Add", "a", "member", "to", "the", "board", "using", "the", "id", ".", "Membership", "type", "can", "be", "normal", "or", "admin", ".", "Returns", "JSON", "of", "all", "members", "if", "successful", "or", "raises", "an", "Unauthorised", "exception", "if", "not", "."], "nwo": "its-rigs/Trolly", "score": 0.28433842921098695, "idx": 272356}
{"url": "https://github.com/willkg/markus/blob/0cfbe67fb7ccfa7488b0120d21ddc0cdc1f8ed33/markus/backends/logging.py#L82-L84", "sha": "0cfbe67fb7ccfa7488b0120d21ddc0cdc1f8ed33", "docstring_summary": "Report a timing.", "language": "python", "parameters": "(self, stat, value, tags=None)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", "=", "None", ")", ":", "arg_0", ".", "_log", "(", "'Func'", ",", "arg_1", ",", "arg_2", ",", "arg_3", ")"], "function": "def Func(arg_0, arg_1, arg_2, arg_3=None):\n        \"\"\"Report a Func.\"\"\"\n        arg_0._log('Func', arg_1, arg_2, arg_3)", "path": "markus/backends/logging.py", "identifier": "LoggingMetrics.timing", "docstring": "Report a timing.", "docstring_tokens": ["Report", "a", "timing", "."], "nwo": "willkg/markus", "score": 0.5049367824870141, "idx": 279698}
{"url": "https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdflite.py#L61-L73", "sha": "ac2501f30d6619eae9dea5644717575ca9263d0a", "docstring_summary": "Convenience function to add property info, can set any attribute and leave the others blank, it won't over-write\r\n            previously set items.", "language": "python", "parameters": "(self, title=None, subject=None, author=None, keywords=None, creator=None)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ",", "arg_2", "=", "None", ",", "arg_3", "=", "None", ",", "arg_4", "=", "None", ",", "arg_5", "=", "None", ")", ":", "arg_6", "=", "{", "\"title\"", ":", "arg_1", ",", "\"subject\"", ":", "arg_2", ",", "\"author\"", ":", "arg_3", ",", "\"keywords\"", ":", "arg_4", ",", "\"creator\"", ":", "arg_5", "}", "for", "arg_7", ",", "arg_8", "in", "arg_6", ".", "iteritems", "(", ")", ":", "if", "hasattr", "(", "arg_0", ",", "arg_7", ")", ":", "if", "arg_8", ":", "setattr", "(", "arg_0", ",", "arg_7", ",", "arg_8", ")", "else", ":", "setattr", "(", "arg_0", ",", "arg_7", ",", "None", ")"], "function": "def Func(arg_0, arg_1=None, arg_2=None, arg_3=None, arg_4=None, arg_5=None):\r\n        \"\"\" Convenience function to add property info, can set any attribute and leave the others blank, it won't over-write\r\n            previously set items. \"\"\"\r\n        arg_6 = {\"title\": arg_1, \"subject\": arg_2,\r\n                     \"author\": arg_3, \"keywords\": arg_4,\r\n                     \"creator\": arg_5}\r\n\r\n        for arg_7, arg_8 in arg_6.iteritems():\r\n            if hasattr(arg_0, arg_7):\r\n                if arg_8:\r\n                    setattr(arg_0, arg_7, arg_8)\r\n            else:\r\n                setattr(arg_0, arg_7, None)", "path": "pypdflite/pdflite.py", "identifier": "PDFLite.set_information", "docstring": "Convenience function to add property info, can set any attribute and leave the others blank, it won't over-write\r\n            previously set items.", "docstring_tokens": ["Convenience", "function", "to", "add", "property", "info", "can", "set", "any", "attribute", "and", "leave", "the", "others", "blank", "it", "won", "t", "over", "-", "write", "previously", "set", "items", "."], "nwo": "katerina7479/pypdflite", "score": 0.1792979536242127, "idx": 269896}
{"url": "https://github.com/dhellmann/csvcat/blob/d08c0df3af2b1cec739521e6d5bb2b1ad868c591/csvcat/main.py#L44-L51", "sha": "d08c0df3af2b1cec739521e6d5bb2b1ad868c591", "docstring_summary": "Return only the part of the row which should be printed.", "language": "python", "parameters": "(columns, row)", "return_statement": "return tuple(row[c] for c in columns)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "if", "not", "arg_0", ":", "return", "arg_1", "return", "tuple", "(", "arg_1", "[", "arg_2", "]", "for", "arg_2", "in", "arg_0", ")"], "function": "def Func(arg_0, arg_1):\n    \"\"\"Return only the part of the row which should be printed.\n    \"\"\"\n    if not arg_0:\n        return arg_1\n\n    # Extract the column values, in the order specified.\n    return tuple(arg_1[arg_2] for arg_2 in arg_0)", "path": "csvcat/main.py", "identifier": "_get_printable_columns", "docstring": "Return only the part of the row which should be printed.", "docstring_tokens": ["Return", "only", "the", "part", "of", "the", "row", "which", "should", "be", "printed", "."], "nwo": "dhellmann/csvcat", "score": 0.14991498758945482, "idx": 272702}
{"url": "https://github.com/jhermann/rituals/blob/1534f50d81e19bbbe799e2eba0acdefbce047c06/src/rituals/util/scm/git.py#L47-L74", "sha": "1534f50d81e19bbbe799e2eba0acdefbce047c06", "docstring_summary": "Check for uncommitted changes, return `True` if everything is clean.", "language": "python", "parameters": "(self, quiet=False)", "return_statement": "return unchanged", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "False", ")", ":", "arg_0", ".", "run", "(", "'git update-index -q --ignore-submodules --refresh'", ",", "**", "RUN_KWARGS", ")", "arg_2", "=", "True", "try", ":", "arg_0", ".", "run", "(", "'git diff-files --quiet --ignore-submodules --'", ",", "report_error", "=", "False", ",", "**", "RUN_KWARGS", ")", "except", "exceptions", ".", "Failure", ":", "arg_2", "=", "False", "if", "not", "arg_1", ":", "notify", ".", "warning", "(", "'You have unstaged changes!'", ")", "arg_0", ".", "run", "(", "'git diff-files --name-status -r --ignore-submodules -- >&2'", ",", "**", "RUN_KWARGS", ")", "try", ":", "arg_0", ".", "run", "(", "'git diff-index --cached --quiet HEAD --ignore-submodules --'", ",", "report_error", "=", "False", ",", "**", "RUN_KWARGS", ")", "except", "exceptions", ".", "Failure", ":", "arg_2", "=", "False", "if", "not", "arg_1", ":", "notify", ".", "warning", "(", "'Your index contains uncommitted changes!'", ")", "arg_0", ".", "run", "(", "'git diff-index --cached --name-status -r --ignore-submodules HEAD -- >&2'", ",", "**", "RUN_KWARGS", ")", "return", "arg_2"], "function": "def Func(arg_0, arg_1=False):\n        \"\"\" Check for uncommitted changes, return `True` if everything is clean.\n\n            Inspired by http://stackoverflow.com/questions/3878624/.\n        \"\"\"\n        # Update the index\n        arg_0.run('git update-index -q --ignore-submodules --refresh', **RUN_KWARGS)\n        arg_2 = True\n\n        # Disallow unstaged changes in the working tree\n        try:\n            arg_0.run('git diff-files --quiet --ignore-submodules --', report_error=False, **RUN_KWARGS)\n        except exceptions.Failure:\n            arg_2 = False\n            if not arg_1:\n                notify.warning('You have unstaged changes!')\n                arg_0.run('git diff-files --name-status -r --ignore-submodules -- >&2', **RUN_KWARGS)\n\n        # Disallow uncommitted changes in the index\n        try:\n            arg_0.run('git diff-index --cached --quiet HEAD --ignore-submodules --', report_error=False, **RUN_KWARGS)\n        except exceptions.Failure:\n            arg_2 = False\n            if not arg_1:\n                notify.warning('Your index contains uncommitted changes!')\n                arg_0.run('git diff-index --cached --name-status -r --ignore-submodules HEAD -- >&2', **RUN_KWARGS)\n\n        return arg_2", "path": "src/rituals/util/scm/git.py", "identifier": "GitProvider.workdir_is_clean", "docstring": "Check for uncommitted changes, return `True` if everything is clean.\n\n            Inspired by http://stackoverflow.com/questions/3878624/.", "docstring_tokens": ["Check", "for", "uncommitted", "changes", "return", "True", "if", "everything", "is", "clean", "."], "nwo": "jhermann/rituals", "score": 0.3756179881544838, "idx": 276155}
{"url": "https://github.com/greenbender/pynntp/blob/991a76331cdf5d8f9dbf5b18f6e29adc80749a2f/nntp/nntp.py#L1272-L1275", "sha": "991a76331cdf5d8f9dbf5b18f6e29adc80749a2f", "docstring_summary": "XPAT command.", "language": "python", "parameters": "(self, header, id_range, *pattern)", "return_statement": "return [x for x in self.xpat_gen(header, id_range, *pattern)]", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "*", "arg_3", ")", ":", "return", "[", "arg_4", "for", "arg_4", "in", "arg_0", ".", "Func_gen", "(", "arg_1", ",", "arg_2", ",", "*", "arg_3", ")", "]"], "function": "def Func(arg_0, arg_1, arg_2, *arg_3):\n        \"\"\"XPAT command.\n        \"\"\"\n        return [arg_4 for arg_4 in arg_0.Func_gen(arg_1, arg_2, *arg_3)]", "path": "nntp/nntp.py", "identifier": "NNTPClient.xpat", "docstring": "XPAT command.", "docstring_tokens": ["XPAT", "command", "."], "nwo": "greenbender/pynntp", "score": 0.17821439704321745, "idx": 275250}
{"url": "https://github.com/Ex-Mente/auxi.0/blob/2dcdae74154f136f8ca58289fe5b20772f215046/auxi/modelling/financial/des.py#L264-L277", "sha": "2dcdae74154f136f8ca58289fe5b20772f215046", "docstring_summary": "Create an account in the general ledger structure.", "language": "python", "parameters": "(self, name, number, account_type)", "return_statement": "return new_acc", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ")", ":", "arg_4", "=", "GeneralLedgerAccount", "(", "arg_1", ",", "None", ",", "arg_2", ",", "arg_3", ")", "arg_0", ".", "accounts", ".", "append", "(", "arg_4", ")", "return", "arg_4"], "function": "def Func(arg_0, arg_1, arg_2, arg_3):\n        \"\"\"\n        Create an account in the general ledger structure.\n\n        :param name: The account name.\n        :param number: The account number.\n        :param account_type: The account type.\n\n        :returns: The created account.\n        \"\"\"\n\n        arg_4 = GeneralLedgerAccount(arg_1, None, arg_2, arg_3)\n        arg_0.accounts.append(arg_4)\n        return arg_4", "path": "auxi/modelling/financial/des.py", "identifier": "GeneralLedgerStructure._create_account_", "docstring": "Create an account in the general ledger structure.\n\n        :param name: The account name.\n        :param number: The account number.\n        :param account_type: The account type.\n\n        :returns: The created account.", "docstring_tokens": ["Create", "an", "account", "in", "the", "general", "ledger", "structure", "."], "nwo": "Ex-Mente/auxi.0", "score": 0.2778869743536733, "idx": 273772}
{"url": "https://github.com/edx/edx-enterprise/blob/aea91379ab0a87cd3bc798961fce28b60ee49a80/integrated_channels/integrated_channel/tasks.py#L50-L74", "sha": "aea91379ab0a87cd3bc798961fce28b60ee49a80", "docstring_summary": "Task to send learner data to each linked integrated channel.", "language": "python", "parameters": "(username, channel_code, channel_pk)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "arg_3", "=", "time", ".", "time", "(", ")", "arg_4", "=", "User", ".", "objects", ".", "get", "(", "arg_0", "=", "arg_0", ")", "arg_5", "=", "INTEGRATED_CHANNEL_CHOICES", "[", "arg_1", "]", ".", "objects", ".", "get", "(", "pk", "=", "arg_2", ")", "LOGGER", ".", "info", "(", "'Processing learners for integrated channel using configuration: [%s]'", ",", "arg_5", ")", "arg_5", ".", "Func", "(", "arg_4", ")", "arg_6", "=", "time", ".", "time", "(", ")", "-", "arg_3", "LOGGER", ".", "info", "(", "'Learner data transmission task for integrated channel configuration [%s] took [%s] seconds'", ",", "arg_5", ",", "arg_6", ")"], "function": "def Func(arg_0, arg_1, arg_2):\n    \"\"\"\n    Task to send learner data to each linked integrated channel.\n\n    Arguments:\n        username (str): The username of the User to be used for making API requests for learner data.\n        channel_code (str): Capitalized identifier for the integrated channel\n        channel_pk (str): Primary key for identifying integrated channel\n\n    \"\"\"\n    arg_3 = time.time()\n    arg_4 = User.objects.get(arg_0=arg_0)\n    arg_5 = INTEGRATED_CHANNEL_CHOICES[arg_1].objects.get(pk=arg_2)\n    LOGGER.info('Processing learners for integrated channel using configuration: [%s]', arg_5)\n\n    # Note: learner data transmission code paths don't raise any uncaught exception, so we don't need a broad\n    # try-except block here.\n    arg_5.Func(arg_4)\n\n    arg_6 = time.time() - arg_3\n    LOGGER.info(\n        'Learner data transmission task for integrated channel configuration [%s] took [%s] seconds',\n        arg_5,\n        arg_6\n    )", "path": "integrated_channels/integrated_channel/tasks.py", "identifier": "transmit_learner_data", "docstring": "Task to send learner data to each linked integrated channel.\n\n    Arguments:\n        username (str): The username of the User to be used for making API requests for learner data.\n        channel_code (str): Capitalized identifier for the integrated channel\n        channel_pk (str): Primary key for identifying integrated channel", "docstring_tokens": ["Task", "to", "send", "learner", "data", "to", "each", "linked", "integrated", "channel", "."], "nwo": "edx/edx-enterprise", "score": 0.6522400190762081, "idx": 272902}
{"url": "https://github.com/deepmipt/DeepPavlov/blob/f3e4a69a3764d25d2f5bad4f1f1aebc872b00f9c/deeppavlov/agents/rich_content/default_rich_content.py#L152-L170", "sha": "f3e4a69a3764d25d2f5bad4f1f1aebc872b00f9c", "docstring_summary": "Returns json compatible state of the ButtonsFrame instance.", "language": "python", "parameters": "(self)", "return_statement": "return self.control_json", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", "->", "dict", ":", "arg_1", "=", "{", "}", "if", "arg_0", ".", "text", ":", "arg_1", "[", "'text'", "]", "=", "arg_0", ".", "text", "arg_1", "[", "'controls'", "]", "=", "[", "control", ".", "Func", "(", ")", "for", "control", "in", "arg_0", ".", "content", "]", "arg_0", ".", "control_Func", "[", "'content'", "]", "=", "arg_1", "return", "arg_0", ".", "control_Func"], "function": "def Func(arg_0) -> dict:\n        \"\"\"Returns Func compatible state of the ButtonsFrame instance.\n\n        Returns Func compatible state of the ButtonsFrame instance including\n        all nested buttons.\n\n        Returns:\n            control_Func: Json representation of ButtonsFrame state.\n        \"\"\"\n        arg_1 = {}\n\n        if arg_0.text:\n            arg_1['text'] = arg_0.text\n\n        arg_1['controls'] = [control.Func() for control in arg_0.content]\n\n        arg_0.control_Func['content'] = arg_1\n\n        return arg_0.control_Func", "path": "deeppavlov/agents/rich_content/default_rich_content.py", "identifier": "ButtonsFrame.json", "docstring": "Returns json compatible state of the ButtonsFrame instance.\n\n        Returns json compatible state of the ButtonsFrame instance including\n        all nested buttons.\n\n        Returns:\n            control_json: Json representation of ButtonsFrame state.", "docstring_tokens": ["Returns", "json", "compatible", "state", "of", "the", "ButtonsFrame", "instance", "."], "nwo": "deepmipt/DeepPavlov", "score": 0.9928107156012591, "idx": 274573}
{"url": "https://github.com/GeoffAtHome/lightwave/blob/2fab4ee8c9f14dd97dffd4b8cd70b217e884e581/lightwave/lightwave.py#L56-L63", "sha": "2fab4ee8c9f14dd97dffd4b8cd70b217e884e581", "docstring_summary": "Scale brightness from 0..255 to 1..32.", "language": "python", "parameters": "(self, device_id, name, brightness)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", ")", ":", "arg_4", "=", "round", "(", "(", "arg_3", "*", "31", ")", "/", "255", ")", "+", "1", "arg_5", "=", "\"!%sFdP%d|Lights %d|%s\"", "%", "(", "arg_1", ",", "arg_4", ",", "arg_4", ",", "arg_2", ")", "arg_0", ".", "_send_message", "(", "arg_5", ")"], "function": "def Func(arg_0, arg_1, arg_2, arg_3):\n        \"\"\"Scale brightness from 0..255 to 1..32.\"\"\"\n        arg_4 = round((arg_3 * 31) / 255) + 1\n        # F1 = Light on and F0 = light off. FdP[0..32] is brightness. 32 is\n        # full. We want that when turning the light on.\n        arg_5 = \"!%sFdP%d|Lights %d|%s\" % (\n            arg_1, arg_4, arg_4, arg_2)\n        arg_0._send_message(arg_5)", "path": "lightwave/lightwave.py", "identifier": "LWLink.turn_on_with_brightness", "docstring": "Scale brightness from 0..255 to 1..32.", "docstring_tokens": ["Scale", "brightness", "from", "0", "..", "255", "to", "1", "..", "32", "."], "nwo": "GeoffAtHome/lightwave", "score": 0.14991498758945482, "idx": 271683}
{"url": "https://github.com/PiotrDabkowski/Js2Py/blob/c0fa43f5679cf91ca8986c5747fcb07a433dc584/js2py/evaljs.py#L60-L81", "sha": "c0fa43f5679cf91ca8986c5747fcb07a433dc584", "docstring_summary": "Translates input JS file to python and saves the it to the output path.\n    It appends some convenience code at the end so that it is easy to import JS objects.", "language": "python", "parameters": "(input_path, output_path)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_2", "=", "get_file_contents", "(", "arg_0", ")", "arg_3", "=", "translate_js", "(", "arg_2", ")", "arg_4", "=", "os", ".", "path", ".", "basename", "(", "arg_1", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "arg_5", "=", "'__all__ = [%s]\\n\\n# Don\\'t look below, you will not understand this Python code :) I don\\'t.\\n\\n'", "%", "repr", "(", "arg_4", ")", "arg_6", "=", "'\\n\\n# Add lib to the module scope\\n%s = var.to_python()'", "%", "arg_4", "arg_7", "=", "arg_5", "+", "arg_3", "+", "arg_6", "write_file_contents", "(", "arg_1", ",", "arg_7", ")"], "function": "def Func(arg_0, arg_1):\n    '''\n    Translates input JS file to python and saves the it to the output path.\n    It appends some convenience code at the end so that it is easy to import JS objects.\n\n    For example we have a file 'example.js' with:   var a = function(x) {return x}\n    Func('example.js', 'example.py')\n\n    Now example.py can be easily importend and used:\n    >>> from example import example\n    >>> example.a(30)\n    30\n    '''\n    arg_2 = get_file_contents(arg_0)\n\n    arg_3 = translate_js(arg_2)\n    arg_4 = os.path.basename(arg_1).split('.')[0]\n    arg_5 = '__all__ = [%s]\\n\\n# Don\\'t look below, you will not understand this Python code :) I don\\'t.\\n\\n' % repr(\n        arg_4)\n    arg_6 = '\\n\\n# Add lib to the module scope\\n%s = var.to_python()' % arg_4\n    arg_7 = arg_5 + arg_3 + arg_6\n    write_file_contents(arg_1, arg_7)", "path": "js2py/evaljs.py", "identifier": "translate_file", "docstring": "Translates input JS file to python and saves the it to the output path.\n    It appends some convenience code at the end so that it is easy to import JS objects.\n\n    For example we have a file 'example.js' with:   var a = function(x) {return x}\n    translate_file('example.js', 'example.py')\n\n    Now example.py can be easily importend and used:\n    >>> from example import example\n    >>> example.a(30)\n    30", "docstring_tokens": ["Translates", "input", "JS", "file", "to", "python", "and", "saves", "the", "it", "to", "the", "output", "path", ".", "It", "appends", "some", "convenience", "code", "at", "the", "end", "so", "that", "it", "is", "easy", "to", "import", "JS", "objects", "."], "nwo": "PiotrDabkowski/Js2Py", "score": 0.9574891118982609, "idx": 275409}
{"url": "https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/parameter.py#L990-L1028", "sha": "97ad3e80d46dbdea02deeb98ea41f05a19565826", "docstring_summary": "Explores the parameter according to the iterable.", "language": "python", "parameters": "(self, explore_iterable)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "if", "arg_0", ".", "v_locked", ":", "raise", "pex", ".", "ParameterLockedException", "(", "'Parameter `%s` is locked!'", "%", "arg_0", ".", "v_full_name", ")", "if", "arg_0", ".", "f_has_range", "(", ")", ":", "raise", "TypeError", "(", "'Your parameter `%s` is already explored, '", "'cannot Func it further!'", "%", "arg_0", ".", "_name", ")", "if", "arg_0", ".", "_data", "is", "None", ":", "raise", "TypeError", "(", "'Your parameter `%s` has no default value, please specify one '", "'via `f_set` before exploration. '", "%", "arg_0", ".", "v_full_name", ")", "arg_2", "=", "arg_0", ".", "_data_sanity_checks", "(", "arg_1", ")", "arg_0", ".", "Funcd_range", "=", "arg_2", "arg_0", ".", "Funcd", "=", "True", "arg_0", ".", "f_lock", "(", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"Explores the parameter according to the iterable.\n\n        Raises ParameterLockedException if the parameter is locked.\n        Raises TypeError if the parameter does not support the data,\n        the types of the data in the iterable are not the same as the type of the default value,\n        or the parameter has already an exploration range.\n\n        Note that the parameter will iterate over the whole iterable once and store\n        the individual data values into a tuple. Thus, the whole exploration range is\n        explicitly stored in memory.\n\n        :param explore_iterable: An iterable specifying the exploration range\n\n        For example:\n\n        >>> param.Func([3.0,2.0,1.0])\n        >>> param.f_get_range()\n        (3.0, 2.0, 1.0)\n\n        :raises TypeError,ParameterLockedException\n\n        \"\"\"\n        if arg_0.v_locked:\n            raise pex.ParameterLockedException('Parameter `%s` is locked!' % arg_0.v_full_name)\n\n        if arg_0.f_has_range():\n            raise TypeError('Your parameter `%s` is already explored, '\n                            'cannot Func it further!' % arg_0._name)\n\n        if arg_0._data is None:\n            raise TypeError('Your parameter `%s` has no default value, please specify one '\n                            'via `f_set` before exploration. ' % arg_0.v_full_name)\n\n        arg_2 = arg_0._data_sanity_checks(arg_1)\n\n        arg_0.Funcd_range = arg_2\n        arg_0.Funcd = True\n        arg_0.f_lock()", "path": "pypet/parameter.py", "identifier": "Parameter._explore", "docstring": "Explores the parameter according to the iterable.\n\n        Raises ParameterLockedException if the parameter is locked.\n        Raises TypeError if the parameter does not support the data,\n        the types of the data in the iterable are not the same as the type of the default value,\n        or the parameter has already an exploration range.\n\n        Note that the parameter will iterate over the whole iterable once and store\n        the individual data values into a tuple. Thus, the whole exploration range is\n        explicitly stored in memory.\n\n        :param explore_iterable: An iterable specifying the exploration range\n\n        For example:\n\n        >>> param._explore([3.0,2.0,1.0])\n        >>> param.f_get_range()\n        (3.0, 2.0, 1.0)\n\n        :raises TypeError,ParameterLockedException", "docstring_tokens": ["Explores", "the", "parameter", "according", "to", "the", "iterable", "."], "nwo": "SmokinCaterpillar/pypet", "score": 0.3804160374473955, "idx": 279886}
{"url": "https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/typecheck.py#L498-L503", "sha": "2bf5c61a3ff6ae90613b81679de42c0f19aea600", "docstring_summary": "Check if the given node has a parent of the given type.", "language": "python", "parameters": "(node, node_type, statement)", "return_statement": "return isinstance(parent, node_type)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "arg_3", "=", "arg_0", ".", "parent", "while", "not", "isinstance", "(", "arg_3", ",", "arg_1", ")", "and", "arg_2", ".", "parent_of", "(", "arg_3", ")", ":", "arg_3", "=", "arg_3", ".", "parent", "return", "isinstance", "(", "arg_3", ",", "arg_1", ")"], "function": "def Func(arg_0, arg_1, arg_2):\n    \"\"\"Check if the given node has a parent of the given type.\"\"\"\n    arg_3 = arg_0.parent\n    while not isinstance(arg_3, arg_1) and arg_2.parent_of(arg_3):\n        arg_3 = arg_3.parent\n    return isinstance(arg_3, arg_1)", "path": "pylint/checkers/typecheck.py", "identifier": "_has_parent_of_type", "docstring": "Check if the given node has a parent of the given type.", "docstring_tokens": ["Check", "if", "the", "given", "node", "has", "a", "parent", "of", "the", "given", "type", "."], "nwo": "PyCQA/pylint", "score": 0.7960905782143469, "idx": 269826}
{"url": "https://github.com/yinkaisheng/Python-UIAutomation-for-Windows/blob/2cc91060982cc8b777152e698d677cc2989bf263/uiautomation/uiautomation.py#L7472-L7478", "sha": "2cc91060982cc8b777152e698d677cc2989bf263", "docstring_summary": "Call IUIAutomation ElementFromPoint x,y. May return None if mouse is over cmd's title bar icon.\n    Return `Control` subclass or None.", "language": "python", "parameters": "(x: int, y: int)", "return_statement": "return Control.CreateControlFromElement(element)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ":", "arg_1", ",", "arg_2", ":", "arg_1", ")", "->", "Control", ":", "arg_3", "=", "_AutomationClient", ".", "instance", "(", ")", ".", "IUIAutomation", ".", "ElementFromPoint", "(", "ctypes", ".", "wintypes", ".", "POINT", "(", "arg_0", ",", "arg_2", ")", ")", "return", "Control", ".", "CreateControlFromElement", "(", "arg_3", ")"], "function": "def Func(arg_0: arg_1, arg_2: arg_1) -> Control:\n    \"\"\"\n    Call IUIAutomation ElementFromPoint x,y. May return None if mouse is over cmd's title bar icon.\n    Return `Control` subclass or None.\n    \"\"\"\n    arg_3 = _AutomationClient.instance().IUIAutomation.ElementFromPoint(ctypes.wintypes.POINT(arg_0, arg_2))\n    return Control.CreateControlFromElement(arg_3)", "path": "uiautomation/uiautomation.py", "identifier": "ControlFromPoint", "docstring": "Call IUIAutomation ElementFromPoint x,y. May return None if mouse is over cmd's title bar icon.\n    Return `Control` subclass or None.", "docstring_tokens": ["Call", "IUIAutomation", "ElementFromPoint", "x", "y", ".", "May", "return", "None", "if", "mouse", "is", "over", "cmd", "s", "title", "bar", "icon", ".", "Return", "Control", "subclass", "or", "None", "."], "nwo": "yinkaisheng/Python-UIAutomation-for-Windows", "score": 0.9769561204852005, "idx": 270423}
{"url": "https://github.com/sergedomk/fiql_parser/blob/499dd7cd0741603530ce5f3803d92813e74ac9c3/fiql_parser/expression.py#L199-L214", "sha": "499dd7cd0741603530ce5f3803d92813e74ac9c3", "docstring_summary": "Update the ``Expression`` by joining the specified additional\n        ``elements`` using an \"AND\" ``Operator``", "language": "python", "parameters": "(self, *elements)", "return_statement": "return expression", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "*", "arg_1", ")", ":", "arg_2", "=", "arg_0", ".", "add_operator", "(", "Operator", "(", "';'", ")", ")", "for", "arg_3", "in", "arg_1", ":", "arg_2", ".", "add_element", "(", "arg_3", ")", "return", "arg_2"], "function": "def Func(arg_0, *arg_1):\n        \"\"\"Update the ``Expression`` by joining the specified additional\n        ``elements`` using an \"AND\" ``Operator``\n\n        Args:\n            *elements (BaseExpression): The ``Expression`` and/or\n                ``Constraint`` elements which the \"AND\" ``Operator`` applies\n                to.\n\n        Returns:\n            Expression: ``self`` or related ``Expression``.\n        \"\"\"\n        arg_2 = arg_0.add_operator(Operator(';'))\n        for arg_3 in arg_1:\n            arg_2.add_element(arg_3)\n        return arg_2", "path": "fiql_parser/expression.py", "identifier": "Expression.op_and", "docstring": "Update the ``Expression`` by joining the specified additional\n        ``elements`` using an \"AND\" ``Operator``\n\n        Args:\n            *elements (BaseExpression): The ``Expression`` and/or\n                ``Constraint`` elements which the \"AND\" ``Operator`` applies\n                to.\n\n        Returns:\n            Expression: ``self`` or related ``Expression``.", "docstring_tokens": ["Update", "the", "Expression", "by", "joining", "the", "specified", "additional", "elements", "using", "an", "AND", "Operator"], "nwo": "sergedomk/fiql_parser", "score": 0.35580137387943567, "idx": 267337}
{"url": "https://github.com/lord63/five.py/blob/d7970d5059af9e2f6648f3867649694799415d00/five/five.py#L63-L69", "sha": "d7970d5059af9e2f6648f3867649694799415d00", "docstring_summary": "Speak loudly! FIVE! Use upper case!", "language": "python", "parameters": "(self, lang='englist')", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "'englist'", ")", ":", "arg_2", "=", "getattr", "(", "arg_0", ",", "arg_1", ",", "None", ")", "if", "arg_2", ":", "return", "arg_2", "(", ")", ".", "upper", "(", ")", "else", ":", "return", "arg_0", ".", "english", "(", ")", ".", "upper", "(", ")"], "function": "def Func(arg_0, arg_1='englist'):\n        \"\"\"Speak Funcly! FIVE! Use upper case!\"\"\"\n        arg_2 = getattr(arg_0, arg_1, None)\n        if arg_2:\n            return arg_2().upper()\n        else:\n            return arg_0.english().upper()", "path": "five/five.py", "identifier": "Five.loud", "docstring": "Speak loudly! FIVE! Use upper case!", "docstring_tokens": ["Speak", "loudly!", "FIVE!", "Use", "upper", "case!"], "nwo": "lord63/five.py", "score": 0.138843686048881, "idx": 278292}
{"url": "https://github.com/peri-source/peri/blob/61beed5deaaf978ab31ed716e8470d86ba639867/scripts/does_matter/common.py#L129-L138", "sha": "61beed5deaaf978ab31ed716e8470d86ba639867", "docstring_summary": "Translate an image in fourier-space with plane waves", "language": "python", "parameters": "(image, dx)", "return_statement": "return np.real(np.fft.ifftn(q))", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_2", "=", "arg_0", ".", "shape", "[", "0", "]", "arg_3", "=", "2", "*", "np", ".", "pi", "*", "np", ".", "fft", ".", "fftfreq", "(", "arg_2", ")", "arg_4", ",", "arg_5", ",", "arg_6", "=", "np", ".", "meshgrid", "(", "*", "(", "arg_3", ",", ")", "*", "3", ",", "indexing", "=", "'ij'", ")", "arg_7", "=", "np", ".", "array", "(", "[", "arg_4", ",", "arg_5", ",", "arg_6", "]", ")", ".", "T", "arg_8", "=", "np", ".", "fft", ".", "fftn", "(", "arg_0", ")", "*", "np", ".", "exp", "(", "-", "1.j", "*", "(", "arg_7", "*", "arg_1", ")", ".", "sum", "(", "axis", "=", "-", "1", ")", ")", ".", "T", "return", "np", ".", "real", "(", "np", ".", "fft", ".", "ifftn", "(", "arg_8", ")", ")"], "function": "def Func(arg_0, arg_1):\n    \"\"\" Translate an image in fourier-space with plane waves \"\"\"\n    arg_2 = arg_0.shape[0]\n\n    arg_3 = 2*np.pi*np.fft.fftfreq(arg_2)\n    arg_4,arg_5,arg_6 = np.meshgrid(*(arg_3,)*3, indexing='ij')\n    arg_7 = np.array([arg_4,arg_5,arg_6]).T\n\n    arg_8 = np.fft.fftn(arg_0)*np.exp(-1.j*(arg_7*arg_1).sum(axis=-1)).T\n    return np.real(np.fft.ifftn(arg_8))", "path": "scripts/does_matter/common.py", "identifier": "translate_fourier", "docstring": "Translate an image in fourier-space with plane waves", "docstring_tokens": ["Translate", "an", "image", "in", "fourier", "-", "space", "with", "plane", "waves"], "nwo": "peri-source/peri", "score": 0.2727920376977753, "idx": 278281}
{"url": "https://github.com/lepture/flask-oauthlib/blob/9e6f152a5bb360e7496210da21561c3e6d41b0e1/flask_oauthlib/contrib/oauth2.py#L43-L52", "sha": "9e6f152a5bb360e7496210da21561c3e6d41b0e1", "docstring_summary": "Removes itself from the cache", "language": "python", "parameters": "(self)", "return_statement": "return None", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "log", ".", "debug", "(", "\"Deleting grant %s for client %s\"", "%", "(", "arg_0", ".", "code", ",", "arg_0", ".", "client_id", ")", ")", "arg_0", ".", "_cache", ".", "Func", "(", "arg_0", ".", "key", ")", "return", "None"], "function": "def Func(arg_0):\n        \"\"\"Removes itself from the cache\n\n        Note: This is required by the oauthlib\n        \"\"\"\n        log.debug(\n            \"Deleting grant %s for client %s\" % (arg_0.code, arg_0.client_id)\n        )\n        arg_0._cache.Func(arg_0.key)\n        return None", "path": "flask_oauthlib/contrib/oauth2.py", "identifier": "Grant.delete", "docstring": "Removes itself from the cache\n\n        Note: This is required by the oauthlib", "docstring_tokens": ["Removes", "itself", "from", "the", "cache"], "nwo": "lepture/flask-oauthlib", "score": 0.7824232869066697, "idx": 272937}
{"url": "https://github.com/dbcli/cli_helpers/blob/3ebd891ac0c02bad061182dbcb54a47fb21980ae/cli_helpers/config.py#L119-L122", "sha": "3ebd891ac0c02bad061182dbcb54a47fb21980ae", "docstring_summary": "Get a list of absolute paths to the system config files.", "language": "python", "parameters": "(self)", "return_statement": "return [os.path.join(f, self.filename) for f in get_system_config_dirs(\n            self.app_name, self.app_author)]", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "return", "[", "os", ".", "path", ".", "join", "(", "arg_1", ",", "arg_0", ".", "filename", ")", "for", "arg_1", "in", "get_system_config_dirs", "(", "arg_0", ".", "app_name", ",", "arg_0", ".", "app_author", ")", "]"], "function": "def Func(arg_0):\n        \"\"\"Get a list of absolute paths to the system config files.\"\"\"\n        return [os.path.join(arg_1, arg_0.filename) for arg_1 in get_system_config_dirs(\n            arg_0.app_name, arg_0.app_author)]", "path": "cli_helpers/config.py", "identifier": "Config.system_config_files", "docstring": "Get a list of absolute paths to the system config files.", "docstring_tokens": ["Get", "a", "list", "of", "absolute", "paths", "to", "the", "system", "config", "files", "."], "nwo": "dbcli/cli_helpers", "score": 0.43979569135490515, "idx": 262587}
{"url": "https://github.com/Devoxin/Lavalink.py/blob/63f55c3d726d24c4cfd3674d3cd6aab6f5be110d/lavalink/PlayerManager.py#L166-L168", "sha": "63f55c3d726d24c4cfd3674d3cd6aab6f5be110d", "docstring_summary": "Seeks to a given position in the track.", "language": "python", "parameters": "(self, pos: int)", "return_statement": "", "argument_list": "", "function_tokens": ["async", "def", "Func", "(", "arg_0", ",", "arg_1", ":", "arg_2", ")", ":", "await", "arg_0", ".", "_lavalink", ".", "ws", ".", "send", "(", "op", "=", "'Func'", ",", "guildId", "=", "arg_0", ".", "guild_id", ",", "position", "=", "arg_1", ")"], "function": "async def Func(arg_0, arg_1: arg_2):\r\n        \"\"\" Seeks to a given position in the track. \"\"\"\r\n        await arg_0._lavalink.ws.send(op='Func', guildId=arg_0.guild_id, position=arg_1)", "path": "lavalink/PlayerManager.py", "identifier": "DefaultPlayer.seek", "docstring": "Seeks to a given position in the track.", "docstring_tokens": ["Seeks", "to", "a", "given", "position", "in", "the", "track", "."], "nwo": "Devoxin/Lavalink.py", "score": 0.6942938383447541, "idx": 262062}
{"url": "https://github.com/chrisjrn/registrasion/blob/461d5846c6f9f3b7099322a94f5d9911564448e4/registrasion/controllers/conditions.py#L311-L332", "sha": "461d5846c6f9f3b7099322a94f5d9911564448e4", "docstring_summary": "Returns all of the items from queryset which are enabled by a user\n        being a presenter or copresenter of a non-cancelled proposal.", "language": "python", "parameters": "(self, queryset, user)", "return_statement": "return queryset.filter(user_is_presenter | user_is_copresenter)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ")", ":", "arg_1", "=", "arg_1", ".", "filter", "(", "proposal_kind__proposalbase__presentation__cancelled", "=", "False", ")", "arg_3", "=", "arg_2", "arg_4", "=", "Q", "(", "is_presenter", "=", "True", ",", "proposal_kind__proposalbase__presentation__speaker__user", "=", "arg_3", ",", ")", "arg_5", "=", "Q", "(", "is_copresenter", "=", "True", ",", "proposal_kind__proposalbase__presentation__additional_speakers__user", "=", "arg_3", ",", ")", "return", "arg_1", ".", "filter", "(", "arg_4", "|", "arg_5", ")"], "function": "def Func(arg_0, arg_1, arg_2):\n        ''' Returns all of the items from queryset which are enabled by a user\n        being a presenter or copresenter of a non-cancelled proposal. '''\n\n        # Filter out cancelled proposals\n        arg_1 = arg_1.filter(\n            proposal_kind__proposalbase__presentation__cancelled=False\n        )\n\n        arg_3 = arg_2\n        # User is a presenter\n        arg_4 = Q(\n            is_presenter=True,\n            proposal_kind__proposalbase__presentation__speaker__user=arg_3,\n        )\n        # User is a copresenter\n        arg_5 = Q(\n            is_copresenter=True,\n            proposal_kind__proposalbase__presentation__additional_speakers__user=arg_3,  # NOQA\n        )\n\n        return arg_1.filter(arg_4 | arg_5)", "path": "registrasion/controllers/conditions.py", "identifier": "SpeakerConditionController.pre_filter", "docstring": "Returns all of the items from queryset which are enabled by a user\n        being a presenter or copresenter of a non-cancelled proposal.", "docstring_tokens": ["Returns", "all", "of", "the", "items", "from", "queryset", "which", "are", "enabled", "by", "a", "user", "being", "a", "presenter", "or", "copresenter", "of", "a", "non", "-", "cancelled", "proposal", "."], "nwo": "chrisjrn/registrasion", "score": 0.2778869743536733, "idx": 269174}
{"url": "https://github.com/zomux/deepy/blob/090fbad22a08a809b12951cd0d4984f5bd432698/deepy/trainers/base.py#L254-L263", "sha": "090fbad22a08a809b12951cd0d4984f5bd432698", "docstring_summary": "Run one training iteration.", "language": "python", "parameters": "(self, epoch, train_set, train_size=None)", "return_statement": "return costs", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", ",", "arg_3", "=", "None", ")", ":", "arg_0", ".", "network", ".", "train_logger", ".", "record_epoch", "(", "arg_1", "+", "1", ")", "arg_4", "=", "arg_0", ".", "train_step", "(", "arg_2", ",", "arg_3", ")", "if", "not", "arg_1", "%", "arg_0", ".", "config", ".", "monitor_frequency", ":", "arg_0", ".", "report", "(", "dict", "(", "arg_4", ")", ",", "\"train\"", ",", "arg_1", ")", "arg_0", ".", "last_run_costs", "=", "arg_4", "return", "arg_4"], "function": "def Func(arg_0, arg_1, arg_2, arg_3=None):\n        \"\"\"\n        Run one training iteration.\n        \"\"\"\n        arg_0.network.train_logger.record_epoch(arg_1 + 1)\n        arg_4 = arg_0.train_step(arg_2, arg_3)\n        if not arg_1 % arg_0.config.monitor_frequency:\n            arg_0.report(dict(arg_4), \"train\", arg_1)\n        arg_0.last_run_costs = arg_4\n        return arg_4", "path": "deepy/trainers/base.py", "identifier": "NeuralTrainer._run_train", "docstring": "Run one training iteration.", "docstring_tokens": ["Run", "one", "training", "iteration", "."], "nwo": "zomux/deepy", "score": 0.562122088286705, "idx": 277765}
{"url": "https://github.com/opencast/pyCA/blob/c89b168d4780d157e1b3f7676628c1b131956a88/pyca/ui/jsonapi.py#L84-L106", "sha": "c89b168d4780d157e1b3f7676628c1b131956a88", "docstring_summary": "Delete a specific event identified by its uid. Note that only recorded\n    events can be deleted. Events in the buffer for upcoming events are\n    regularly replaced anyway and a manual removal could have unpredictable\n    effects.", "language": "python", "parameters": "(uid)", "return_statement": "return make_response('', 204)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "logger", ".", "info", "(", "'deleting event %s via api'", ",", "arg_0", ")", "arg_1", "=", "get_session", "(", ")", "arg_2", "=", "arg_1", ".", "query", "(", "RecordedEvent", ")", ".", "filter", "(", "RecordedEvent", ".", "uid", "==", "arg_0", ")", "if", "not", "arg_2", ".", "count", "(", ")", ":", "return", "make_error_response", "(", "'No event with specified uid'", ",", "404", ")", "arg_3", "=", "request", ".", "args", ".", "get", "(", "'hard'", ",", "'false'", ")", "if", "arg_3", "==", "'true'", ":", "logger", ".", "info", "(", "'deleting recorded files at %s'", ",", "arg_2", "[", "0", "]", ".", "directory", "(", ")", ")", "shutil", ".", "rmtree", "(", "arg_2", "[", "0", "]", ".", "directory", "(", ")", ")", "arg_2", ".", "delete", "(", ")", "arg_1", ".", "commit", "(", ")", "return", "make_response", "(", "''", ",", "204", ")"], "function": "def Func(arg_0):\n    '''Delete a specific event identified by its uid. Note that only recorded\n    events can be deleted. Events in the buffer for upcoming events are\n    regularly replaced anyway and a manual removal could have unpredictable\n    effects.\n\n    Use ?hard=true parameter to delete the recorded files on disk as well.\n\n    Returns 204 if the action was successful.\n    Returns 404 if event does not exist\n    '''\n    logger.info('deleting event %s via api', arg_0)\n    arg_1 = get_session()\n    arg_2 = arg_1.query(RecordedEvent).filter(RecordedEvent.uid == arg_0)\n    if not arg_2.count():\n        return make_error_response('No event with specified uid', 404)\n    arg_3 = request.args.get('hard', 'false')\n    if arg_3 == 'true':\n        logger.info('deleting recorded files at %s', arg_2[0].directory())\n        shutil.rmtree(arg_2[0].directory())\n    arg_2.delete()\n    arg_1.commit()\n    return make_response('', 204)", "path": "pyca/ui/jsonapi.py", "identifier": "delete_event", "docstring": "Delete a specific event identified by its uid. Note that only recorded\n    events can be deleted. Events in the buffer for upcoming events are\n    regularly replaced anyway and a manual removal could have unpredictable\n    effects.\n\n    Use ?hard=true parameter to delete the recorded files on disk as well.\n\n    Returns 204 if the action was successful.\n    Returns 404 if event does not exist", "docstring_tokens": ["Delete", "a", "specific", "event", "identified", "by", "its", "uid", ".", "Note", "that", "only", "recorded", "events", "can", "be", "deleted", ".", "Events", "in", "the", "buffer", "for", "upcoming", "events", "are", "regularly", "replaced", "anyway", "and", "a", "manual", "removal", "could", "have", "unpredictable", "effects", "."], "nwo": "opencast/pyCA", "score": 0.38750565733100095, "idx": 279649}
{"url": "https://github.com/Erotemic/ubelt/blob/db802f3ad8abba025db74b54f86e6892b8927325/ubelt/util_hash.py#L181-L223", "sha": "db802f3ad8abba025db74b54f86e6892b8927325", "docstring_summary": "Convert a string-based key into a hasher class", "language": "python", "parameters": "(hasher)", "return_statement": "return hasher", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "if", "xxhash", "is", "not", "None", ":", "if", "arg_0", "in", "{", "'xxh32'", ",", "'xx32'", ",", "'xxhash'", "}", ":", "return", "xxhash", ".", "xxh32", "if", "arg_0", "in", "{", "'xxh64'", ",", "'xx64'", "}", ":", "return", "xxhash", ".", "xxh64", "if", "arg_0", "is", "NoParam", "or", "arg_0", "==", "'default'", ":", "arg_0", "=", "DEFAULT_HASHER", "elif", "isinstance", "(", "arg_0", ",", "six", ".", "string_types", ")", ":", "if", "arg_0", "not", "in", "hashlib", ".", "algorithms_available", ":", "raise", "KeyError", "(", "'unknown hasher: {}'", ".", "format", "(", "arg_0", ")", ")", "else", ":", "arg_0", "=", "getattr", "(", "hashlib", ",", "arg_0", ")", "elif", "isinstance", "(", "arg_0", ",", "HASH", ")", ":", "return", "lambda", ":", "arg_0", "return", "arg_0"], "function": "def Func(arg_0):\n    \"\"\"\n    Convert a string-based key into a hasher class\n\n    Notes:\n        In terms of speed on 64bit systems, sha1 is the fastest followed by md5\n        and sha512. The slowest algorithm is sha256. If xxhash is installed\n        the fastest algorithm is xxh64.\n\n    Example:\n        >>> assert Func(NoParam) is DEFAULT_HASHER\n        >>> assert Func('sha1') is hashlib.sha1\n        >>> assert Func('sha256') is hashlib.sha256\n        >>> assert Func('sha512') is hashlib.sha512\n        >>> assert Func('md5') is hashlib.md5\n        >>> assert Func(hashlib.sha1) is hashlib.sha1\n        >>> assert Func(hashlib.sha1())().name == 'sha1'\n        >>> import pytest\n        >>> assert pytest.raises(KeyError, Func, '42')\n        >>> #assert pytest.raises(TypeError, Func, object)\n        >>> if xxhash:\n        >>>     assert Func('xxh64') is xxhash.xxh64\n        >>>     assert Func('xxh32') is xxhash.xxh32\n    \"\"\"\n    if xxhash is not None:  # pragma: nobranch\n        if arg_0 in {'xxh32', 'xx32', 'xxhash'}:\n            return xxhash.xxh32\n        if arg_0 in {'xxh64', 'xx64'}:\n            return xxhash.xxh64\n\n    if arg_0 is NoParam or arg_0 == 'default':\n        arg_0 = DEFAULT_HASHER\n    elif isinstance(arg_0, six.string_types):\n        if arg_0 not in hashlib.algorithms_available:\n            raise KeyError('unknown hasher: {}'.format(arg_0))\n        else:\n            arg_0 = getattr(hashlib, arg_0)\n    elif isinstance(arg_0, HASH):\n        # by default the result of this function is a class we will make an\n        # instance of, if we already have an instance, wrap it in a callable\n        # so the external syntax does not need to change.\n        return lambda: arg_0\n    return arg_0", "path": "ubelt/util_hash.py", "identifier": "_rectify_hasher", "docstring": "Convert a string-based key into a hasher class\n\n    Notes:\n        In terms of speed on 64bit systems, sha1 is the fastest followed by md5\n        and sha512. The slowest algorithm is sha256. If xxhash is installed\n        the fastest algorithm is xxh64.\n\n    Example:\n        >>> assert _rectify_hasher(NoParam) is DEFAULT_HASHER\n        >>> assert _rectify_hasher('sha1') is hashlib.sha1\n        >>> assert _rectify_hasher('sha256') is hashlib.sha256\n        >>> assert _rectify_hasher('sha512') is hashlib.sha512\n        >>> assert _rectify_hasher('md5') is hashlib.md5\n        >>> assert _rectify_hasher(hashlib.sha1) is hashlib.sha1\n        >>> assert _rectify_hasher(hashlib.sha1())().name == 'sha1'\n        >>> import pytest\n        >>> assert pytest.raises(KeyError, _rectify_hasher, '42')\n        >>> #assert pytest.raises(TypeError, _rectify_hasher, object)\n        >>> if xxhash:\n        >>>     assert _rectify_hasher('xxh64') is xxhash.xxh64\n        >>>     assert _rectify_hasher('xxh32') is xxhash.xxh32", "docstring_tokens": ["Convert", "a", "string", "-", "based", "key", "into", "a", "hasher", "class"], "nwo": "Erotemic/ubelt", "score": 0.9423075079767973, "idx": 267566}
{"url": "https://github.com/macacajs/wd.py/blob/6d3c52060013e01a67cd52b68b5230b387427bad/macaca/webdriver.py#L262-L277", "sha": "6d3c52060013e01a67cd52b68b5230b387427bad", "docstring_summary": "Switch to the given window.", "language": "python", "parameters": "(self, window_name)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_2", "=", "{", "'name'", ":", "arg_1", "}", "arg_0", ".", "_execute", "(", "Command", ".", "SWITCH_TO_WINDOW", ",", "arg_2", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"Switch to the given window.\n\n        Support:\n            Web(WebView)\n\n        Args:\n            window_name(str): The window to change focus to.\n\n        Returns:\n            WebDriver Object.\n        \"\"\"\n        arg_2 = {\n            'name': arg_1\n        }\n        arg_0._execute(Command.SWITCH_TO_WINDOW, arg_2)", "path": "macaca/webdriver.py", "identifier": "WebDriver.switch_to_window", "docstring": "Switch to the given window.\n\n        Support:\n            Web(WebView)\n\n        Args:\n            window_name(str): The window to change focus to.\n\n        Returns:\n            WebDriver Object.", "docstring_tokens": ["Switch", "to", "the", "given", "window", "."], "nwo": "macacajs/wd.py", "score": 0.3182350344440769, "idx": 275582}
{"url": "https://github.com/Jajcus/pyxmpp2/blob/14a40a3950910a9cd008b55f0d8905aa0186ce18/pyxmpp2/ext/muc/muc.py#L324-L354", "sha": "14a40a3950910a9cd008b55f0d8905aa0186ce18", "docstring_summary": "Update user information.", "language": "python", "parameters": "(self,presence)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_0", ".", "presence", "=", "MucPresence", "(", "arg_1", ")", "arg_2", "=", "arg_1", ".", "get_type", "(", ")", "if", "arg_2", "==", "\"unavailable\"", ":", "arg_0", ".", "role", "=", "\"none\"", "arg_0", ".", "affiliation", "=", "\"none\"", "arg_0", ".", "room_jid", "=", "arg_0", ".", "presence", ".", "get_from", "(", ")", "arg_0", ".", "nick", "=", "arg_0", ".", "room_jid", ".", "resource", "arg_7", "=", "arg_0", ".", "presence", ".", "get_muc_child", "(", ")", "if", "isinstance", "(", "arg_7", ",", "MucUserX", ")", ":", "arg_8", "=", "arg_7", ".", "get_items", "(", ")", "for", "arg_9", "in", "arg_8", ":", "if", "not", "isinstance", "(", "arg_9", ",", "MucItem", ")", ":", "continue", "if", "arg_9", ".", "role", ":", "arg_0", ".", "role", "=", "arg_9", ".", "role", "if", "arg_9", ".", "affiliation", ":", "arg_0", ".", "affiliation", "=", "arg_9", ".", "affiliation", "if", "arg_9", ".", "jid", ":", "arg_0", ".", "real_jid", "=", "arg_9", ".", "jid", "if", "arg_9", ".", "nick", ":", "arg_0", ".", "new_nick", "=", "arg_9", ".", "nick", "break"], "function": "def Func(arg_0,arg_1):\n        \"\"\"\n        Update user information.\n\n        :Parameters:\n            - `presence`: a presence stanza with user information update.\n        :Types:\n            - `presence`: `MucPresence`\n        \"\"\"\n        arg_0.presence=MucPresence(arg_1)\n        arg_2=arg_1.get_type()\n        if arg_2==\"unavailable\":\n            arg_0.role=\"none\"\n            arg_0.affiliation=\"none\"\n        arg_0.room_jid=arg_0.presence.get_from()\n        arg_0.nick=arg_0.room_jid.resource\n        arg_7=arg_0.presence.get_muc_child()\n        if isinstance(arg_7,MucUserX):\n            arg_8=arg_7.get_items()\n            for arg_9 in arg_8:\n                if not isinstance(arg_9,MucItem):\n                    continue\n                if arg_9.role:\n                    arg_0.role=arg_9.role\n                if arg_9.affiliation:\n                    arg_0.affiliation=arg_9.affiliation\n                if arg_9.jid:\n                    arg_0.real_jid=arg_9.jid\n                if arg_9.nick:\n                    arg_0.new_nick=arg_9.nick\n                break", "path": "pyxmpp2/ext/muc/muc.py", "identifier": "MucRoomUser.update_presence", "docstring": "Update user information.\n\n        :Parameters:\n            - `presence`: a presence stanza with user information update.\n        :Types:\n            - `presence`: `MucPresence`", "docstring_tokens": ["Update", "user", "information", "."], "nwo": "Jajcus/pyxmpp2", "score": 0.4106374656686744, "idx": 270449}
{"url": "https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/services/server/auth/slugs.py#L62-L108", "sha": "b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e", "docstring_summary": "Query the configured SLUGS service with the provided credentials.", "language": "python", "parameters": "(self,\n                     connection_certificate=None,\n                     connection_info=None,\n                     request_credentials=None)", "return_statement": "return user_id, response.json().get('groups')", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "None", ",", "arg_2", "=", "None", ",", "arg_3", "=", "None", ")", ":", "if", "(", "arg_0", ".", "users_url", "is", "None", ")", "or", "(", "arg_0", ".", "groups_url", "is", "None", ")", ":", "raise", "exceptions", ".", "ConfigurationError", "(", "\"The SLUGS URL must be specified.\"", ")", "arg_4", "=", "utils", ".", "get_client_identity_from_certificate", "(", "arg_1", ")", "try", ":", "arg_5", "=", "requests", ".", "get", "(", "arg_0", ".", "users_url", ".", "format", "(", "arg_4", ")", ")", "except", "Exception", ":", "raise", "exceptions", ".", "ConfigurationError", "(", "\"A connection could not be established using the SLUGS URL.\"", ")", "if", "arg_5", ".", "status_code", "==", "404", ":", "raise", "exceptions", ".", "PermissionDenied", "(", "\"Unrecognized user ID: {}\"", ".", "format", "(", "arg_4", ")", ")", "arg_5", "=", "requests", ".", "get", "(", "arg_0", ".", "groups_url", ".", "format", "(", "arg_4", ")", ")", "if", "arg_5", ".", "status_code", "==", "404", ":", "raise", "exceptions", ".", "PermissionDenied", "(", "\"Group information could not be retrieved for user ID: \"", "\"{}\"", ".", "format", "(", "arg_4", ")", ")", "return", "arg_4", ",", "arg_5", ".", "json", "(", ")", ".", "get", "(", "'groups'", ")"], "function": "def Func(arg_0,\n                     arg_1=None,\n                     arg_2=None,\n                     arg_3=None):\n        \"\"\"\n        Query the configured SLUGS service with the provided credentials.\n\n        Args:\n            connection_certificate (cryptography.x509.Certificate): An X.509\n                certificate object obtained from the connection being\n                Funcd. Required for SLUGS authentication.\n            connection_info (tuple): A tuple of information pertaining to the\n                connection being Funcd, including the source IP address\n                and a timestamp (e.g., ('127.0.0.1', 1519759267.467451)).\n                Optional, defaults to None. Ignored for SLUGS authentication.\n            request_credentials (list): A list of KMIP Credential structures\n                containing credential information to use for authentication.\n                Optional, defaults to None. Ignored for SLUGS authentication.\n        \"\"\"\n        if (arg_0.users_url is None) or (arg_0.groups_url is None):\n            raise exceptions.ConfigurationError(\n                \"The SLUGS URL must be specified.\"\n            )\n\n        arg_4 = utils.get_client_identity_from_certificate(\n            arg_1\n        )\n\n        try:\n            arg_5 = requests.get(arg_0.users_url.format(arg_4))\n        except Exception:\n            raise exceptions.ConfigurationError(\n                \"A connection could not be established using the SLUGS URL.\"\n            )\n        if arg_5.status_code == 404:\n            raise exceptions.PermissionDenied(\n                \"Unrecognized user ID: {}\".format(arg_4)\n            )\n\n        arg_5 = requests.get(arg_0.groups_url.format(arg_4))\n        if arg_5.status_code == 404:\n            raise exceptions.PermissionDenied(\n                \"Group information could not be retrieved for user ID: \"\n                \"{}\".format(arg_4)\n            )\n\n        return arg_4, arg_5.json().get('groups')", "path": "kmip/services/server/auth/slugs.py", "identifier": "SLUGSConnector.authenticate", "docstring": "Query the configured SLUGS service with the provided credentials.\n\n        Args:\n            connection_certificate (cryptography.x509.Certificate): An X.509\n                certificate object obtained from the connection being\n                authenticated. Required for SLUGS authentication.\n            connection_info (tuple): A tuple of information pertaining to the\n                connection being authenticated, including the source IP address\n                and a timestamp (e.g., ('127.0.0.1', 1519759267.467451)).\n                Optional, defaults to None. Ignored for SLUGS authentication.\n            request_credentials (list): A list of KMIP Credential structures\n                containing credential information to use for authentication.\n                Optional, defaults to None. Ignored for SLUGS authentication.", "docstring_tokens": ["Query", "the", "configured", "SLUGS", "service", "with", "the", "provided", "credentials", "."], "nwo": "OpenKMIP/PyKMIP", "score": 0.7283203957767634, "idx": 279351}
{"url": "https://github.com/iotaledger/iota.lib.py/blob/97cdd1e241498446b46157b79b2a1ea2ec6d387a/iota/api.py#L1046-L1084", "sha": "97cdd1e241498446b46157b79b2a1ea2ec6d387a", "docstring_summary": "Attaches transaction trytes to the Tangle, then broadcasts and\n        stores them.", "language": "python", "parameters": "(self, trytes, depth=3, min_weight_magnitude=None)", "return_statement": "return extended.SendTrytesCommand(self.adapter)(\n            trytes=trytes,\n            depth=depth,\n            minWeightMagnitude=min_weight_magnitude,\n        )", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "3", ",", "arg_3", "=", "None", ")", ":", "if", "arg_3", "is", "None", ":", "arg_3", "=", "arg_0", ".", "default_min_weight_magnitude", "return", "extended", ".", "SendTrytesCommand", "(", "arg_0", ".", "adapter", ")", "(", "arg_1", "=", "arg_1", ",", "arg_2", "=", "arg_2", ",", "minWeightMagnitude", "=", "arg_3", ",", ")"], "function": "def Func(arg_0, arg_1, arg_2=3, arg_3=None):\n        # type: (Iterable[TransactionTrytes], int, Optional[int]) -> dict\n        \"\"\"\n        Attaches transaction trytes to the Tangle, then broadcasts and\n        stores them.\n\n        :param trytes:\n            Transaction encoded as a tryte sequence.\n\n        :param depth:\n            Depth at which to attach the bundle.\n            Defaults to 3.\n\n        :param min_weight_magnitude:\n            Min weight magnitude, used by the node to calibrate Proof of\n            Work.\n\n            If not provided, a default value will be used.\n\n        :return:\n            Dict with the following structure::\n\n                {\n                    'trytes': List[TransactionTrytes],\n                        Raw trytes that were published to the Tangle.\n                }\n\n        References:\n\n        - https://github.com/iotaledger/wiki/blob/master/api-proposal.md#sendtrytes\n        \"\"\"\n        if arg_3 is None:\n            arg_3 = arg_0.default_min_weight_magnitude\n\n        return extended.SendTrytesCommand(arg_0.adapter)(\n            arg_1=arg_1,\n            arg_2=arg_2,\n            minWeightMagnitude=arg_3,\n        )", "path": "iota/api.py", "identifier": "Iota.send_trytes", "docstring": "Attaches transaction trytes to the Tangle, then broadcasts and\n        stores them.\n\n        :param trytes:\n            Transaction encoded as a tryte sequence.\n\n        :param depth:\n            Depth at which to attach the bundle.\n            Defaults to 3.\n\n        :param min_weight_magnitude:\n            Min weight magnitude, used by the node to calibrate Proof of\n            Work.\n\n            If not provided, a default value will be used.\n\n        :return:\n            Dict with the following structure::\n\n                {\n                    'trytes': List[TransactionTrytes],\n                        Raw trytes that were published to the Tangle.\n                }\n\n        References:\n\n        - https://github.com/iotaledger/wiki/blob/master/api-proposal.md#sendtrytes", "docstring_tokens": ["Attaches", "transaction", "trytes", "to", "the", "Tangle", "then", "broadcasts", "and", "stores", "them", "."], "nwo": "iotaledger/iota.lib.py", "score": 0.7132834846011566, "idx": 278210}
{"url": "https://github.com/opencobra/cobrapy/blob/9d1987cdb3a395cf4125a3439c3b002ff2be2009/cobra/flux_analysis/phenotype_phase_plane.py#L22-L130", "sha": "9d1987cdb3a395cf4125a3439c3b002ff2be2009", "docstring_summary": "Calculate the objective value conditioned on all combinations of\n    fluxes for a set of chosen reactions", "language": "python", "parameters": "(model, reactions, objective=None, carbon_sources=None,\n                        points=20, threshold=None)", "return_statement": "return grid", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "None", ",", "arg_3", "=", "None", ",", "arg_4", "=", "20", ",", "arg_5", "=", "None", ")", ":", "arg_1", "=", "arg_0", ".", "reactions", ".", "get_by_any", "(", "arg_1", ")", "arg_2", "=", "arg_0", ".", "solver", ".", "objective", "if", "arg_2", "is", "None", "else", "arg_2", "arg_6", "=", "dict", "(", ")", "if", "arg_3", "is", "None", ":", "arg_7", "=", "find_carbon_sources", "(", "arg_0", ")", "else", ":", "arg_7", "=", "arg_0", ".", "reactions", ".", "get_by_any", "(", "arg_3", ")", "if", "arg_7", "is", "None", ":", "arg_6", "[", "'carbon_source'", "]", "=", "None", "elif", "hasattr", "(", "arg_7", ",", "'id'", ")", ":", "arg_6", "[", "'carbon_source'", "]", "=", "arg_7", ".", "id", "else", ":", "arg_6", "[", "'carbon_source'", "]", "=", "', '", ".", "join", "(", "rxn", ".", "id", "for", "rxn", "in", "arg_7", ")", "arg_5", "=", "normalize_cutoff", "(", "arg_0", ",", "arg_5", ")", "arg_8", "=", "arg_4", "**", "len", "(", "arg_1", ")", "for", "arg_9", "in", "(", "'minimum'", ",", "'maximum'", ")", ":", "arg_6", "[", "'flux_{}'", ".", "format", "(", "arg_9", ")", "]", "=", "full", "(", "arg_8", ",", "nan", ",", "dtype", "=", "float", ")", "arg_6", "[", "'carbon_yield_{}'", ".", "format", "(", "arg_9", ")", "]", "=", "full", "(", "arg_8", ",", "nan", ",", "dtype", "=", "float", ")", "arg_6", "[", "'mass_yield_{}'", ".", "format", "(", "arg_9", ")", "]", "=", "full", "(", "arg_8", ",", "nan", ",", "dtype", "=", "float", ")", "arg_11", "=", "pd", ".", "DataFrame", "(", "arg_6", ")", "with", "arg_0", ":", "arg_0", ".", "objective", "=", "arg_2", "arg_12", "=", "list", "(", "sutil", ".", "linear_reaction_coefficients", "(", "arg_0", ")", ")", "if", "len", "(", "arg_12", ")", "!=", "1", ":", "raise", "ValueError", "(", "'cannot calculate yields for objectives with '", "'multiple reactions'", ")", "arg_13", "=", "arg_12", "[", "0", "]", "arg_14", "=", "fva", "(", "arg_0", ",", "arg_1", ",", "fraction_of_optimum", "=", "0", ")", "arg_14", "[", "arg_14", ".", "abs", "(", ")", "<", "arg_5", "]", "=", "0.0", "arg_4", "=", "list", "(", "product", "(", "*", "[", "linspace", "(", "arg_14", ".", "at", "[", "rxn", ".", "id", ",", "\"minimum\"", "]", ",", "arg_14", ".", "at", "[", "rxn", ".", "id", ",", "\"maximum\"", "]", ",", "arg_4", ",", "endpoint", "=", "True", ")", "for", "rxn", "in", "arg_1", "]", ")", ")", "arg_16", "=", "pd", ".", "DataFrame", "(", "arg_4", ",", "columns", "=", "[", "rxn", ".", "id", "for", "rxn", "in", "arg_1", "]", ")", "arg_11", "=", "pd", ".", "concat", "(", "[", "arg_11", ",", "arg_16", "]", ",", "axis", "=", "1", ",", "copy", "=", "False", ")", "add_envelope", "(", "arg_0", ",", "arg_1", ",", "arg_11", ",", "arg_7", ",", "arg_13", ",", "arg_5", ")", "return", "arg_11"], "function": "def Func(arg_0, arg_1, arg_2=None, arg_3=None,\n                        arg_4=20, arg_5=None):\n    \"\"\"Calculate the objective value conditioned on all combinations of\n    fluxes for a set of chosen reactions\n\n    The production envelope can be used to analyze a model's ability to\n    produce a given compound conditional on the fluxes for another set of\n    reactions, such as the uptake rates. The model is alternately optimized\n    with respect to minimizing and maximizing the objective and the\n    obtained fluxes are recorded. Ranges to compute production is set to the\n    effective\n    bounds, i.e., the minimum / maximum fluxes that can be obtained given\n    current reaction bounds.\n\n    Parameters\n    ----------\n    model : cobra.Model\n        The model to compute the production envelope for.\n    reactions : list or string\n        A list of reactions, reaction identifiers or a single reaction.\n    objective : string, dict, model.solver.interface.Objective, optional\n        The objective (reaction) to use for the production envelope. Use the\n        model's current objective if left missing.\n    carbon_sources : list or string, optional\n       One or more reactions or reaction identifiers that are the source of\n       carbon for computing carbon (mol carbon in output over mol carbon in\n       input) and mass yield (gram product over gram output). Only objectives\n       with a carbon containing input and output metabolite is supported.\n       Will identify active carbon sources in the medium if none are specified.\n    points : int, optional\n       The number of points to calculate production for.\n    threshold : float, optional\n        A cut-off under which flux values will be considered to be zero\n        (default model.tolerance).\n\n    Returns\n    -------\n    pandas.DataFrame\n        A data frame with one row per evaluated point and\n\n        - reaction id : one column per input reaction indicating the flux at\n          each given point,\n        - carbon_source: identifiers of carbon exchange reactions\n\n        A column for the maximum and minimum each for the following types:\n\n        - flux: the objective flux\n        - carbon_yield: if carbon source is defined and the product is a\n          single metabolite (mol carbon product per mol carbon feeding source)\n        - mass_yield: if carbon source is defined and the product is a\n          single metabolite (gram product per 1 g of feeding source)\n\n    Examples\n    --------\n    >>> import cobra.test\n    >>> from cobra.flux_analysis import Func\n    >>> model = cobra.test.create_test_model(\"textbook\")\n    >>> Func(model, [\"EX_glc__D_e\", \"EX_o2_e\"])\n\n    \"\"\"\n\n    arg_1 = arg_0.reactions.get_by_any(arg_1)\n    arg_2 = arg_0.solver.objective if arg_2 is None else arg_2\n    arg_6 = dict()\n\n    if arg_3 is None:\n        arg_7 = find_carbon_sources(arg_0)\n    else:\n        arg_7 = arg_0.reactions.get_by_any(arg_3)\n\n    if arg_7 is None:\n        arg_6['carbon_source'] = None\n    elif hasattr(arg_7, 'id'):\n        arg_6['carbon_source'] = arg_7.id\n    else:\n        arg_6['carbon_source'] = ', '.join(rxn.id for rxn in arg_7)\n\n    arg_5 = normalize_cutoff(arg_0, arg_5)\n\n    arg_8 = arg_4 ** len(arg_1)\n\n    for arg_9 in ('minimum', 'maximum'):\n        arg_6['flux_{}'.format(arg_9)] = full(arg_8, nan, dtype=float)\n        arg_6['carbon_yield_{}'.format(arg_9)] = full(\n            arg_8, nan, dtype=float)\n        arg_6['mass_yield_{}'.format(arg_9)] = full(\n            arg_8, nan, dtype=float)\n\n    arg_11 = pd.DataFrame(arg_6)\n\n    with arg_0:\n        arg_0.objective = arg_2\n        arg_12 = list(sutil.linear_reaction_coefficients(arg_0))\n\n        if len(arg_12) != 1:\n            raise ValueError('cannot calculate yields for objectives with '\n                             'multiple reactions')\n        arg_13 = arg_12[0]\n        arg_14 = fva(arg_0, arg_1, fraction_of_optimum=0)\n        arg_14[arg_14.abs() < arg_5] = 0.0\n        arg_4 = list(product(*[\n            linspace(arg_14.at[rxn.id, \"minimum\"],\n                     arg_14.at[rxn.id, \"maximum\"],\n                     arg_4, endpoint=True) for rxn in arg_1]))\n        arg_16 = pd.DataFrame(arg_4, columns=[rxn.id for rxn in arg_1])\n        arg_11 = pd.concat([arg_11, arg_16], axis=1, copy=False)\n        add_envelope(arg_0, arg_1, arg_11, arg_7, arg_13, arg_5)\n\n    return arg_11", "path": "cobra/flux_analysis/phenotype_phase_plane.py", "identifier": "production_envelope", "docstring": "Calculate the objective value conditioned on all combinations of\n    fluxes for a set of chosen reactions\n\n    The production envelope can be used to analyze a model's ability to\n    produce a given compound conditional on the fluxes for another set of\n    reactions, such as the uptake rates. The model is alternately optimized\n    with respect to minimizing and maximizing the objective and the\n    obtained fluxes are recorded. Ranges to compute production is set to the\n    effective\n    bounds, i.e., the minimum / maximum fluxes that can be obtained given\n    current reaction bounds.\n\n    Parameters\n    ----------\n    model : cobra.Model\n        The model to compute the production envelope for.\n    reactions : list or string\n        A list of reactions, reaction identifiers or a single reaction.\n    objective : string, dict, model.solver.interface.Objective, optional\n        The objective (reaction) to use for the production envelope. Use the\n        model's current objective if left missing.\n    carbon_sources : list or string, optional\n       One or more reactions or reaction identifiers that are the source of\n       carbon for computing carbon (mol carbon in output over mol carbon in\n       input) and mass yield (gram product over gram output). Only objectives\n       with a carbon containing input and output metabolite is supported.\n       Will identify active carbon sources in the medium if none are specified.\n    points : int, optional\n       The number of points to calculate production for.\n    threshold : float, optional\n        A cut-off under which flux values will be considered to be zero\n        (default model.tolerance).\n\n    Returns\n    -------\n    pandas.DataFrame\n        A data frame with one row per evaluated point and\n\n        - reaction id : one column per input reaction indicating the flux at\n          each given point,\n        - carbon_source: identifiers of carbon exchange reactions\n\n        A column for the maximum and minimum each for the following types:\n\n        - flux: the objective flux\n        - carbon_yield: if carbon source is defined and the product is a\n          single metabolite (mol carbon product per mol carbon feeding source)\n        - mass_yield: if carbon source is defined and the product is a\n          single metabolite (gram product per 1 g of feeding source)\n\n    Examples\n    --------\n    >>> import cobra.test\n    >>> from cobra.flux_analysis import production_envelope\n    >>> model = cobra.test.create_test_model(\"textbook\")\n    >>> production_envelope(model, [\"EX_glc__D_e\", \"EX_o2_e\"])", "docstring_tokens": ["Calculate", "the", "objective", "value", "conditioned", "on", "all", "combinations", "of", "fluxes", "for", "a", "set", "of", "chosen", "reactions"], "nwo": "opencobra/cobrapy", "score": 0.7616079334549548, "idx": 276141}
{"url": "https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/database.py#L253-L268", "sha": "cdf69cbde120199171f7158e1c33635753e6e2f5", "docstring_summary": "Return the current content of the inactive-db.json file.", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "if", "PyFunceble", ".", "CONFIGURATION", "[", "\"inactive_database\"", "]", ":", "arg_0", ".", "_reformat_historical_formating_error", "(", ")", "if", "PyFunceble", ".", "path", ".", "isfile", "(", "arg_0", ".", "inactive_db_path", ")", ":", "arg_0", ".", "_merge", "(", ")"], "function": "def Func(arg_0):\n        \"\"\"\n        Return the current content of the inactive-db.json file.\n        \"\"\"\n\n        if PyFunceble.CONFIGURATION[\"inactive_database\"]:\n            # The database subsystem is activated.\n\n            # We get, format and initiate the historical database file.\n            arg_0._reformat_historical_formating_error()\n\n            if PyFunceble.path.isfile(arg_0.inactive_db_path):\n                # The database file exist.\n\n                # We merge our current database into already initiated one.\n                arg_0._merge()", "path": "PyFunceble/database.py", "identifier": "Inactive._retrieve", "docstring": "Return the current content of the inactive-db.json file.", "docstring_tokens": ["Return", "the", "current", "content", "of", "the", "inactive", "-", "db", ".", "json", "file", "."], "nwo": "funilrys/PyFunceble", "score": 0.7376187981798944, "idx": 275606}
{"url": "https://github.com/rabitt/pysox/blob/eae89bde74567136ec3f723c3e6b369916d9b837/sox/file_info.py#L301-L330", "sha": "eae89bde74567136ec3f723c3e6b369916d9b837", "docstring_summary": "Get a dictionary of file information", "language": "python", "parameters": "(filepath)", "return_statement": "return info_dictionary", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "{", "'channels'", ":", "channels", "(", "arg_0", ")", ",", "'sample_rate'", ":", "sample_rate", "(", "arg_0", ")", ",", "'bitrate'", ":", "bitrate", "(", "arg_0", ")", ",", "'duration'", ":", "duration", "(", "arg_0", ")", ",", "'num_samples'", ":", "num_samples", "(", "arg_0", ")", ",", "'encoding'", ":", "encoding", "(", "arg_0", ")", ",", "'silent'", ":", "silent", "(", "arg_0", ")", "}", "return", "arg_1"], "function": "def Func(arg_0):\n    '''Get a dictionary of file Funcrmation\n\n    Parameters\n    ----------\n    filepath : str\n        File path.\n\n    Returns:\n    --------\n    Func_dictionary : dict\n        Dictionary of file Funcrmation. Fields are:\n            * channels\n            * sample_rate\n            * bitrate\n            * duration\n            * num_samples\n            * encoding\n            * silent\n    '''\n    arg_1 = {\n        'channels': channels(arg_0),\n        'sample_rate': sample_rate(arg_0),\n        'bitrate': bitrate(arg_0),\n        'duration': duration(arg_0),\n        'num_samples': num_samples(arg_0),\n        'encoding': encoding(arg_0),\n        'silent': silent(arg_0)\n    }\n    return arg_1", "path": "sox/file_info.py", "identifier": "info", "docstring": "Get a dictionary of file information\n\n    Parameters\n    ----------\n    filepath : str\n        File path.\n\n    Returns:\n    --------\n    info_dictionary : dict\n        Dictionary of file information. Fields are:\n            * channels\n            * sample_rate\n            * bitrate\n            * duration\n            * num_samples\n            * encoding\n            * silent", "docstring_tokens": ["Get", "a", "dictionary", "of", "file", "information"], "nwo": "rabitt/pysox", "score": 0.7121540461632563, "idx": 275458}
{"url": "https://github.com/google/grumpy/blob/3ec87959189cfcdeae82eb68a47648ac25ceb10b/third_party/stdlib/difflib.py#L1311-L1389", "sha": "3ec87959189cfcdeae82eb68a47648ac25ceb10b", "docstring_summary": "r\"\"\"\n    Compare two sequences of lines; generate the delta as a context diff.", "language": "python", "parameters": "(a, b, fromfile='', tofile='',\n                 fromfiledate='', tofiledate='', n=3, lineterm='\\n')", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ",", "arg_2", "=", "''", ",", "arg_3", "=", "''", ",", "arg_4", "=", "''", ",", "arg_5", "=", "''", ",", "arg_6", "=", "3", ",", "arg_7", "=", "'\\n'", ")", ":", "arg_8", "=", "dict", "(", "insert", "=", "'+ '", ",", "delete", "=", "'- '", ",", "replace", "=", "'! '", ",", "equal", "=", "'  '", ")", "arg_9", "=", "False", "for", "arg_10", "in", "SequenceMatcher", "(", "None", ",", "arg_0", ",", "arg_1", ")", ".", "get_grouped_opcodes", "(", "arg_6", ")", ":", "if", "not", "arg_9", ":", "arg_9", "=", "True", "arg_11", "=", "'\\t%s'", "%", "(", "arg_4", ")", "if", "arg_4", "else", "''", "arg_12", "=", "'\\t%s'", "%", "(", "arg_5", ")", "if", "arg_5", "else", "''", "yield", "'*** %s%s%s'", "%", "(", "arg_2", ",", "arg_11", ",", "arg_7", ")", "yield", "'--- %s%s%s'", "%", "(", "arg_3", ",", "arg_12", ",", "arg_7", ")", "arg_13", ",", "arg_14", "=", "arg_10", "[", "0", "]", ",", "arg_10", "[", "-", "1", "]", "yield", "'***************'", "+", "arg_7", "arg_15", "=", "_format_range_context", "(", "arg_13", "[", "1", "]", ",", "arg_14", "[", "2", "]", ")", "yield", "'*** %s ****%s'", "%", "(", "arg_15", ",", "arg_7", ")", "if", "any", "(", "arg_16", "in", "(", "'replace'", ",", "'delete'", ")", "for", "arg_16", ",", "arg_17", ",", "arg_17", ",", "arg_17", ",", "arg_17", "in", "arg_10", ")", ":", "for", "arg_16", ",", "arg_18", ",", "arg_19", ",", "arg_17", ",", "arg_17", "in", "arg_10", ":", "if", "arg_16", "!=", "'insert'", ":", "for", "arg_20", "in", "arg_0", "[", "arg_18", ":", "arg_19", "]", ":", "yield", "arg_8", "[", "arg_16", "]", "+", "arg_20", "arg_21", "=", "_format_range_context", "(", "arg_13", "[", "3", "]", ",", "arg_14", "[", "4", "]", ")", "yield", "'--- %s ----%s'", "%", "(", "arg_21", ",", "arg_7", ")", "if", "any", "(", "arg_16", "in", "(", "'replace'", ",", "'insert'", ")", "for", "arg_16", ",", "arg_17", ",", "arg_17", ",", "arg_17", ",", "arg_17", "in", "arg_10", ")", ":", "for", "arg_16", ",", "arg_17", ",", "arg_17", ",", "arg_22", ",", "arg_23", "in", "arg_10", ":", "if", "arg_16", "!=", "'delete'", ":", "for", "arg_20", "in", "arg_1", "[", "arg_22", ":", "arg_23", "]", ":", "yield", "arg_8", "[", "arg_16", "]", "+", "arg_20"], "function": "def Func(arg_0, arg_1, arg_2='', arg_3='',\n                 arg_4='', arg_5='', arg_6=3, arg_7='\\n'):\n    r\"\"\"\n    Compare two sequences of lines; generate the delta as a context diff.\n\n    Context diffs are a compact way of showing line changes and a few\n    lines of context.  The number of context lines is set by 'n' which\n    defaults to three.\n\n    By default, the diff control lines (those with *** or ---) are\n    created with a trailing newline.  This is helpful so that inputs\n    created from file.readlines() result in diffs that are suitable for\n    file.writelines() since both the inputs and outputs have trailing\n    newlines.\n\n    For inputs that do not have trailing newlines, set the lineterm\n    argument to \"\" so that the output will be uniformly newline free.\n\n    The context diff format normally has a header for filenames and\n    modification times.  Any or all of these may be specified using\n    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.\n    The modification times are normally expressed in the ISO 8601 format.\n    If not specified, the strings default to blanks.\n\n    Example:\n\n    >>> print ''.join(Func('one\\ntwo\\nthree\\nfour\\n'.splitlines(1),\n    ...       'zero\\none\\ntree\\nfour\\n'.splitlines(1), 'Original', 'Current')),\n    *** Original\n    --- Current\n    ***************\n    *** 1,4 ****\n      one\n    ! two\n    ! three\n      four\n    --- 1,4 ----\n    + zero\n      one\n    ! tree\n      four\n    \"\"\"\n\n    arg_8 = dict(insert='+ ', delete='- ', replace='! ', equal='  ')\n    arg_9 = False\n    for arg_10 in SequenceMatcher(None,arg_0,arg_1).get_grouped_opcodes(arg_6):\n        if not arg_9:\n            arg_9 = True\n            # fromdate = '\\t{}'.format(fromfiledate) if fromfiledate else ''\n            arg_11 = '\\t%s' % (arg_4) if arg_4 else ''\n            # todate = '\\t{}'.format(tofiledate) if tofiledate else ''\n            arg_12 = '\\t%s' % (arg_5) if arg_5 else ''\n            # yield '*** {}{}{}'.format(fromfile, fromdate, lineterm)\n            yield '*** %s%s%s' % (arg_2, arg_11, arg_7)\n            # yield '--- {}{}{}'.format(tofile, todate, lineterm)\n            yield '--- %s%s%s' % (arg_3, arg_12, arg_7)\n\n        arg_13, arg_14 = arg_10[0], arg_10[-1]\n        yield '***************' + arg_7\n\n        arg_15 = _format_range_context(arg_13[1], arg_14[2])\n        # yield '*** {} ****{}'.format(file1_range, lineterm)\n        yield '*** %s ****%s' % (arg_15, arg_7)\n\n        if any(arg_16 in ('replace', 'delete') for arg_16, arg_17, arg_17, arg_17, arg_17 in arg_10):\n            for arg_16, arg_18, arg_19, arg_17, arg_17 in arg_10:\n                if arg_16 != 'insert':\n                    for arg_20 in arg_0[arg_18:arg_19]:\n                        yield arg_8[arg_16] + arg_20\n\n        arg_21 = _format_range_context(arg_13[3], arg_14[4])\n        # yield '--- {} ----{}'.format(file2_range, lineterm)\n        yield '--- %s ----%s' % (arg_21, arg_7)\n\n        if any(arg_16 in ('replace', 'insert') for arg_16, arg_17, arg_17, arg_17, arg_17 in arg_10):\n            for arg_16, arg_17, arg_17, arg_22, arg_23 in arg_10:\n                if arg_16 != 'delete':\n                    for arg_20 in arg_1[arg_22:arg_23]:\n                        yield arg_8[arg_16] + arg_20", "path": "third_party/stdlib/difflib.py", "identifier": "context_diff", "docstring": "r\"\"\"\n    Compare two sequences of lines; generate the delta as a context diff.\n\n    Context diffs are a compact way of showing line changes and a few\n    lines of context.  The number of context lines is set by 'n' which\n    defaults to three.\n\n    By default, the diff control lines (those with *** or ---) are\n    created with a trailing newline.  This is helpful so that inputs\n    created from file.readlines() result in diffs that are suitable for\n    file.writelines() since both the inputs and outputs have trailing\n    newlines.\n\n    For inputs that do not have trailing newlines, set the lineterm\n    argument to \"\" so that the output will be uniformly newline free.\n\n    The context diff format normally has a header for filenames and\n    modification times.  Any or all of these may be specified using\n    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.\n    The modification times are normally expressed in the ISO 8601 format.\n    If not specified, the strings default to blanks.\n\n    Example:\n\n    >>> print ''.join(context_diff('one\\ntwo\\nthree\\nfour\\n'.splitlines(1),\n    ...       'zero\\none\\ntree\\nfour\\n'.splitlines(1), 'Original', 'Current')),\n    *** Original\n    --- Current\n    ***************\n    *** 1,4 ****\n      one\n    ! two\n    ! three\n      four\n    --- 1,4 ----\n    + zero\n      one\n    ! tree\n      four", "docstring_tokens": ["r", "Compare", "two", "sequences", "of", "lines", ";", "generate", "the", "delta", "as", "a", "context", "diff", "."], "nwo": "google/grumpy", "score": 0.9826819915211343, "idx": 265083}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/terminal/ipapp.py#L212-L224", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "This has to be in a method, for TerminalIPythonApp to be available.", "language": "python", "parameters": "(self)", "return_statement": "return [\n            InteractiveShellApp, # ShellApp comes before TerminalApp, because\n            self.__class__,      # it will also affect subclasses (e.g. QtConsole)\n            TerminalInteractiveShell,\n            PromptManager,\n            HistoryManager,\n            ProfileDir,\n            PlainTextFormatter,\n            IPCompleter,\n            ScriptMagics,\n        ]", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "return", "[", "InteractiveShellApp", ",", "arg_0", ".", "__class__", ",", "TerminalInteractiveShell", ",", "PromptManager", ",", "HistoryManager", ",", "ProfileDir", ",", "PlainTextFormatter", ",", "IPCompleter", ",", "ScriptMagics", ",", "]"], "function": "def Func(arg_0):\n        \"\"\"This has to be in a method, for TerminalIPythonApp to be available.\"\"\"\n        return [\n            InteractiveShellApp, # ShellApp comes before TerminalApp, because\n            arg_0.__class__,      # it will also affect subclasses (e.g. QtConsole)\n            TerminalInteractiveShell,\n            PromptManager,\n            HistoryManager,\n            ProfileDir,\n            PlainTextFormatter,\n            IPCompleter,\n            ScriptMagics,\n        ]", "path": "environment/lib/python2.7/site-packages/IPython/frontend/terminal/ipapp.py", "identifier": "TerminalIPythonApp._classes_default", "docstring": "This has to be in a method, for TerminalIPythonApp to be available.", "docstring_tokens": ["This", "has", "to", "be", "in", "a", "method", "for", "TerminalIPythonApp", "to", "be", "available", "."], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 269259}
{"url": "https://github.com/plivo/plivohelper-python/blob/a2f706d69e2138fbb973f792041341f662072d26/plivohelper.py#L153-L158", "sha": "a2f706d69e2138fbb973f792041341f662072d26", "docstring_summary": "REST Call Helper", "language": "python", "parameters": "(self, call_params)", "return_statement": "return self.request(path, method, call_params)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", ")", ":", "arg_2", "=", "'/'", "+", "arg_0", ".", "api_version", "+", "'/Call/'", "arg_3", "=", "'POST'", "return", "arg_0", ".", "request", "(", "arg_2", ",", "arg_3", ",", "arg_1", ")"], "function": "def Func(arg_0, arg_1):\n        \"\"\"REST Call Helper\n        \"\"\"\n        arg_2 = '/' + arg_0.api_version + '/Call/'\n        arg_3 = 'POST'\n        return arg_0.request(arg_2, arg_3, arg_1)", "path": "plivohelper.py", "identifier": "REST.call", "docstring": "REST Call Helper", "docstring_tokens": ["REST", "Call", "Helper"], "nwo": "plivo/plivohelper-python", "score": 0.3381286165491821, "idx": 278576}
{"url": "https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/extensions/standard/barrier.py#L30-L53", "sha": "d4f58d903bc96341b816f7c35df936d6421267d1", "docstring_summary": "Apply barrier to circuit.\n    If qargs is None, applies to all the qbits.\n    Args is a list of QuantumRegister or single qubits.\n    For QuantumRegister, applies barrier to all the qubits in that register.", "language": "python", "parameters": "(self, *qargs)", "return_statement": "return self.append(Barrier(len(qubits)), qubits, [])", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "*", "arg_1", ")", ":", "arg_2", "=", "[", "]", "arg_1", "=", "_convert_to_bits", "(", "arg_1", ",", "[", "qbit", "for", "arg_3", "in", "arg_0", ".", "qregs", "for", "qbit", "in", "arg_3", "]", ")", "if", "not", "arg_1", ":", "for", "arg_3", "in", "arg_0", ".", "qregs", ":", "for", "arg_4", "in", "range", "(", "arg_3", ".", "size", ")", ":", "arg_2", ".", "append", "(", "(", "arg_3", ",", "arg_4", ")", ")", "for", "arg_5", "in", "arg_1", ":", "if", "isinstance", "(", "arg_5", ",", "(", "QuantumRegister", ",", "list", ")", ")", ":", "if", "isinstance", "(", "arg_5", ",", "QuantumRegister", ")", ":", "arg_2", ".", "extend", "(", "[", "(", "arg_5", ",", "arg_4", ")", "for", "arg_4", "in", "range", "(", "arg_5", ".", "size", ")", "]", ")", "else", ":", "arg_2", ".", "extend", "(", "arg_5", ")", "else", ":", "arg_2", ".", "append", "(", "arg_5", ")", "return", "arg_0", ".", "append", "(", "Barrier", "(", "len", "(", "arg_2", ")", ")", ",", "arg_2", ",", "[", "]", ")"], "function": "def Func(arg_0, *arg_1):\n    \"\"\"Apply Func to circuit.\n    If qargs is None, applies to all the qbits.\n    Args is a list of QuantumRegister or single qubits.\n    For QuantumRegister, applies Func to all the qubits in that register.\"\"\"\n    arg_2 = []\n\n    arg_1 = _convert_to_bits(arg_1, [qbit for arg_3 in arg_0.qregs for qbit in arg_3])\n\n    if not arg_1:  # None\n        for arg_3 in arg_0.qregs:\n            for arg_4 in range(arg_3.size):\n                arg_2.append((arg_3, arg_4))\n\n    for arg_5 in arg_1:\n        if isinstance(arg_5, (QuantumRegister, list)):\n            if isinstance(arg_5, QuantumRegister):\n                arg_2.extend([(arg_5, arg_4) for arg_4 in range(arg_5.size)])\n            else:\n                arg_2.extend(arg_5)\n        else:\n            arg_2.append(arg_5)\n\n    return arg_0.append(Barrier(len(arg_2)), arg_2, [])", "path": "qiskit/extensions/standard/barrier.py", "identifier": "barrier", "docstring": "Apply barrier to circuit.\n    If qargs is None, applies to all the qbits.\n    Args is a list of QuantumRegister or single qubits.\n    For QuantumRegister, applies barrier to all the qubits in that register.", "docstring_tokens": ["Apply", "barrier", "to", "circuit", ".", "If", "qargs", "is", "None", "applies", "to", "all", "the", "qbits", ".", "Args", "is", "a", "list", "of", "QuantumRegister", "or", "single", "qubits", ".", "For", "QuantumRegister", "applies", "barrier", "to", "all", "the", "qubits", "in", "that", "register", "."], "nwo": "Qiskit/qiskit-terra", "score": 0.9746485763042565, "idx": 264520}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/share/doc/ipython/examples/parallel/pi/pidigits.py#L55-L62", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "Add up a list of freq counts to get the total counts.", "language": "python", "parameters": "(freqlist)", "return_statement": "return allfreqs", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "arg_1", "=", "np", ".", "zeros_like", "(", "arg_0", "[", "0", "]", ")", "for", "arg_2", "in", "arg_0", ":", "arg_1", "+=", "arg_2", "return", "arg_1"], "function": "def Func(arg_0):\n    \"\"\"\n    Add up a list of freq counts to get the total counts.\n    \"\"\"\n    arg_1 = np.zeros_like(arg_0[0])\n    for arg_2 in arg_0:\n        arg_1 += arg_2\n    return arg_1", "path": "environment/share/doc/ipython/examples/parallel/pi/pidigits.py", "identifier": "reduce_freqs", "docstring": "Add up a list of freq counts to get the total counts.", "docstring_tokens": ["Add", "up", "a", "list", "of", "freq", "counts", "to", "get", "the", "total", "counts", "."], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 279903}
{"url": "https://github.com/opencobra/cobrapy/blob/9d1987cdb3a395cf4125a3439c3b002ff2be2009/cobra/io/sbml.py#L156-L226", "sha": "9d1987cdb3a395cf4125a3439c3b002ff2be2009", "docstring_summary": "Reads SBML model from given filename.", "language": "python", "parameters": "(filename, number=float, f_replace=F_REPLACE,\n                    set_missing_bounds=False, **kwargs)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "arg_1", "=", "arg_2", ",", "arg_3", "=", "arg_4", ",", "arg_5", "=", "False", ",", "**", "arg_6", ")", ":", "try", ":", "arg_7", "=", "_get_doc_from_filename", "(", "arg_0", ")", "return", "_sbml_to_model", "(", "arg_7", ",", "arg_1", "=", "arg_1", ",", "arg_3", "=", "arg_3", ",", "arg_5", "=", "arg_5", ",", "**", "arg_6", ")", "except", "IOError", "as", "e", ":", "raise", "e", "except", "Exception", ":", "LOGGER", ".", "error", "(", "traceback", ".", "print_exc", "(", ")", ")", "raise", "CobraSBMLError", "(", "\"Something went wrong reading the SBML model. Most likely the SBML\"", "\" model is not valid. Please check that your model is valid using \"", "\"the `cobra.io.sbml.validate_sbml_model` function or via the \"", "\"online validator at http://sbml.org/validator .\\n\"", "\"\\t`(model, errors) = validate_sbml_model(filename)`\"", "\"\\nIf the model is valid and cannot be read please open an issue \"", "\"at https://github.com/opencobra/cobrapy/issues .\"", ")"], "function": "def Func(arg_0, arg_1=arg_2, arg_3=arg_4,\n                    arg_5=False, **arg_6):\n    \"\"\"Reads SBML model from given filename.\n\n    If the given filename ends with the suffix ''.gz'' (for example,\n    ''myfile.xml.gz'),' the file is assumed to be compressed in gzip\n    format and will be automatically decompressed upon reading. Similarly,\n    if the given filename ends with ''.zip'' or ''.bz2',' the file is\n    assumed to be compressed in zip or bzip2 format (respectively).  Files\n    whose names lack these suffixes will be read uncompressed.  Note that\n    if the file is in zip format but the archive contains more than one\n    file, only the first file in the archive will be read and the rest\n    ignored.\n\n    To read a gzip/zip file, libSBML needs to be configured and linked\n    with the zlib library at compile time.  It also needs to be linked\n    with the bzip2 library to read files in bzip2 format.  (Both of these\n    are the default configurations for libSBML.)\n\n    This function supports SBML with FBC-v1 and FBC-v2. FBC-v1 models\n    are converted to FBC-v2 models before reading.\n\n    The parser tries to fall back to information in notes dictionaries\n    if information is not available in the FBC packages, e.g.,\n    CHARGE, FORMULA on species, or GENE_ASSOCIATION, SUBSYSTEM on reactions.\n\n    Parameters\n    ----------\n    filename : path to SBML file, or SBML string, or SBML file handle\n        SBML which is read into cobra model\n    number: data type of stoichiometry: {float, int}\n        In which data type should the stoichiometry be parsed.\n    f_replace : dict of replacement functions for id replacement\n        Dictionary of replacement functions for gene, specie, and reaction.\n        By default the following id changes are performed on import:\n        clip G_ from genes, clip M_ from species, clip R_ from reactions\n        If no replacements should be performed, set f_replace={}, None\n    set_missing_bounds : boolean flag to set missing bounds\n        Missing bounds are set to default bounds in configuration.\n\n    Returns\n    -------\n    cobra.core.Model\n\n    Notes\n    -----\n    Provided file handles cannot be opened in binary mode, i.e., use\n        with open(path, \"r\" as f):\n            Func(f)\n    File handles to compressed files are not supported yet.\n    \"\"\"\n    try:\n        arg_7 = _get_doc_from_filename(arg_0)\n        return _sbml_to_model(arg_7,\n                              arg_1=arg_1,\n                              arg_3=arg_3,\n                              arg_5=arg_5,\n                              **arg_6)\n    except IOError as e:\n        raise e\n\n    except Exception:\n        LOGGER.error(traceback.print_exc())\n        raise CobraSBMLError(\n            \"Something went wrong reading the SBML model. Most likely the SBML\"\n            \" model is not valid. Please check that your model is valid using \"\n            \"the `cobra.io.sbml.validate_sbml_model` function or via the \"\n            \"online validator at http://sbml.org/validator .\\n\"\n            \"\\t`(model, errors) = validate_sbml_model(filename)`\"\n            \"\\nIf the model is valid and cannot be read please open an issue \"\n            \"at https://github.com/opencobra/cobrapy/issues .\")", "path": "cobra/io/sbml.py", "identifier": "read_sbml_model", "docstring": "Reads SBML model from given filename.\n\n    If the given filename ends with the suffix ''.gz'' (for example,\n    ''myfile.xml.gz'),' the file is assumed to be compressed in gzip\n    format and will be automatically decompressed upon reading. Similarly,\n    if the given filename ends with ''.zip'' or ''.bz2',' the file is\n    assumed to be compressed in zip or bzip2 format (respectively).  Files\n    whose names lack these suffixes will be read uncompressed.  Note that\n    if the file is in zip format but the archive contains more than one\n    file, only the first file in the archive will be read and the rest\n    ignored.\n\n    To read a gzip/zip file, libSBML needs to be configured and linked\n    with the zlib library at compile time.  It also needs to be linked\n    with the bzip2 library to read files in bzip2 format.  (Both of these\n    are the default configurations for libSBML.)\n\n    This function supports SBML with FBC-v1 and FBC-v2. FBC-v1 models\n    are converted to FBC-v2 models before reading.\n\n    The parser tries to fall back to information in notes dictionaries\n    if information is not available in the FBC packages, e.g.,\n    CHARGE, FORMULA on species, or GENE_ASSOCIATION, SUBSYSTEM on reactions.\n\n    Parameters\n    ----------\n    filename : path to SBML file, or SBML string, or SBML file handle\n        SBML which is read into cobra model\n    number: data type of stoichiometry: {float, int}\n        In which data type should the stoichiometry be parsed.\n    f_replace : dict of replacement functions for id replacement\n        Dictionary of replacement functions for gene, specie, and reaction.\n        By default the following id changes are performed on import:\n        clip G_ from genes, clip M_ from species, clip R_ from reactions\n        If no replacements should be performed, set f_replace={}, None\n    set_missing_bounds : boolean flag to set missing bounds\n        Missing bounds are set to default bounds in configuration.\n\n    Returns\n    -------\n    cobra.core.Model\n\n    Notes\n    -----\n    Provided file handles cannot be opened in binary mode, i.e., use\n        with open(path, \"r\" as f):\n            read_sbml_model(f)\n    File handles to compressed files are not supported yet.", "docstring_tokens": ["Reads", "SBML", "model", "from", "given", "filename", "."], "nwo": "opencobra/cobrapy", "score": 0.7616079334549548, "idx": 277945}
{"url": "https://github.com/pybel/pybel-tools/blob/3491adea0ac4ee60f57275ef72f9b73da6dbfe0c/src/pybel_tools/filters/edge_filters.py#L157-L160", "sha": "3491adea0ac4ee60f57275ef72f9b73da6dbfe0c", "docstring_summary": "Pass for nodes that have the given namespace.", "language": "python", "parameters": "(node: BaseEntity, namespace: str)", "return_statement": "return ns is not None and ns == namespace", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ":", "arg_1", ",", "arg_2", ":", "arg_3", ")", "->", "bool", ":", "arg_4", "=", "arg_0", ".", "get", "(", "NAMESPACE", ")", "return", "arg_4", "is", "not", "None", "and", "arg_4", "==", "arg_2"], "function": "def Func(arg_0: arg_1, arg_2: arg_3) -> bool:\n    \"\"\"Pass for nodes that have the given namespace.\"\"\"\n    arg_4 = arg_0.get(NAMESPACE)\n    return arg_4 is not None and arg_4 == arg_2", "path": "src/pybel_tools/filters/edge_filters.py", "identifier": "node_has_namespace", "docstring": "Pass for nodes that have the given namespace.", "docstring_tokens": ["Pass", "for", "nodes", "that", "have", "the", "given", "namespace", "."], "nwo": "pybel/pybel-tools", "score": 0.27946077266739355, "idx": 277996}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/core/shellapp.py#L313-L324", "sha": "075dc74d1ee62a8c6b7a8bf2b271364f01629d1e", "docstring_summary": "Run files from IPythonApp.exec_files", "language": "python", "parameters": "(self)", "return_statement": "", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ")", ":", "if", "not", "arg_0", ".", "exec_files", ":", "return", "arg_0", ".", "log", ".", "debug", "(", "\"Running files in IPythonApp.exec_files...\"", ")", "try", ":", "for", "arg_1", "in", "arg_0", ".", "exec_files", ":", "arg_0", ".", "_exec_file", "(", "arg_1", ")", "except", ":", "arg_0", ".", "log", ".", "warn", "(", "\"Unknown error in handling IPythonApp.exec_files:\"", ")", "arg_0", ".", "shell", ".", "showtraceback", "(", ")"], "function": "def Func(arg_0):\n        \"\"\"Run files from IPythonApp.exec_files\"\"\"\n        if not arg_0.exec_files:\n            return\n\n        arg_0.log.debug(\"Running files in IPythonApp.exec_files...\")\n        try:\n            for arg_1 in arg_0.exec_files:\n                arg_0._exec_file(arg_1)\n        except:\n            arg_0.log.warn(\"Unknown error in handling IPythonApp.exec_files:\")\n            arg_0.shell.showtraceback()", "path": "environment/lib/python2.7/site-packages/IPython/core/shellapp.py", "identifier": "InteractiveShellApp._run_exec_files", "docstring": "Run files from IPythonApp.exec_files", "docstring_tokens": ["Run", "files", "from", "IPythonApp", ".", "exec_files"], "nwo": "cloud9ers/gurumate", "score": 0.0, "idx": 263455}
{"url": "https://github.com/SectorLabs/django-postgres-extra/blob/eef2ed5504d225858d4e4f5d77a838082ca6053e/psqlextra/manager/manager.py#L91-L118", "sha": "eef2ed5504d225858d4e4f5d77a838082ca6053e", "docstring_summary": "Updates all rows that match the filter.", "language": "python", "parameters": "(self, **fields)", "return_statement": "return len(rows)", "argument_list": "", "function_tokens": ["def", "Func", "(", "arg_0", ",", "**", "arg_1", ")", ":", "arg_0", ".", "_for_write", "=", "True", "if", "django", ".", "VERSION", ">=", "(", "2", ",", "0", ")", ":", "arg_3", "=", "arg_0", ".", "query", ".", "chain", "(", "UpdateQuery", ")", "else", ":", "arg_3", "=", "arg_0", ".", "query", ".", "clone", "(", "UpdateQuery", ")", "arg_3", ".", "_annotations", "=", "None", "arg_3", ".", "add_Func_values", "(", "arg_1", ")", "arg_5", "=", "django", ".", "db", ".", "connections", "[", "arg_0", ".", "db", "]", "arg_6", "=", "PostgresReturningUpdateCompiler", "(", "arg_3", ",", "arg_5", ",", "arg_0", ".", "db", ")", "with", "transaction", ".", "atomic", "(", "using", "=", "arg_0", ".", "db", ",", "savepoint", "=", "False", ")", ":", "arg_7", "=", "arg_6", ".", "execute_sql", "(", "CURSOR", ")", "arg_0", ".", "_result_cache", "=", "None", "for", "arg_9", "in", "arg_7", ":", "signals", ".", "Func", ".", "send", "(", "arg_0", ".", "model", ",", "pk", "=", "arg_9", "[", "0", "]", ")", "return", "len", "(", "arg_7", ")"], "function": "def Func(arg_0, **arg_1):\n        \"\"\"Updates all rows that match the filter.\"\"\"\n\n        # build up the query to execute\n        arg_0._for_write = True\n        if django.VERSION >= (2, 0):\n            arg_3 = arg_0.query.chain(UpdateQuery)\n        else:\n            arg_3 = arg_0.query.clone(UpdateQuery)\n        arg_3._annotations = None\n        arg_3.add_Func_values(arg_1)\n\n        # build the compiler for for the query\n        arg_5 = django.db.connections[arg_0.db]\n        arg_6 = PostgresReturningUpdateCompiler(arg_3, arg_5, arg_0.db)\n\n        # execute the query\n        with transaction.atomic(using=arg_0.db, savepoint=False):\n            arg_7 = arg_6.execute_sql(CURSOR)\n        arg_0._result_cache = None\n\n        # send out a signal for each row\n        for arg_9 in arg_7:\n            signals.Func.send(arg_0.model, pk=arg_9[0])\n\n        # the original Func(..) returns the amount of rows\n        # affected, let's do the same\n        return len(arg_7)", "path": "psqlextra/manager/manager.py", "identifier": "PostgresQuerySet.update", "docstring": "Updates all rows that match the filter.", "docstring_tokens": ["Updates", "all", "rows", "that", "match", "the", "filter", "."], "nwo": "SectorLabs/django-postgres-extra", "score": 0.938393672171891, "idx": 271478}
