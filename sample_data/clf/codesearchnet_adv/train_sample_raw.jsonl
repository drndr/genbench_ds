{"repo": "BlueBrain/NeuroM", "path": "neurom/morphmath.py", "func_name": "vector", "original_string": "def vector(p1, p2):\n    '''compute vector between two 3D points\n\n    Args:\n        p1, p2: indexable objects with\n        indices 0, 1, 2 corresponding to 3D cartesian coordinates.\n\n    Returns:\n        3-vector from p1 - p2\n    '''\n    return np.subtract(p1[COLS.XYZ], p2[COLS.XYZ])", "language": "python", "code": "def vector(p1, p2):\n    '''compute vector between two 3D points\n\n    Args:\n        p1, p2: indexable objects with\n        indices 0, 1, 2 corresponding to 3D cartesian coordinates.\n\n    Returns:\n        3-vector from p1 - p2\n    '''\n    return np.subtract(p1[COLS.XYZ], p2[COLS.XYZ])", "code_tokens": ["def", "vector", "(", "p1", ",", "p2", ")", ":", "return", "np", ".", "subtract", "(", "p1", "[", "COLS", ".", "XYZ", "]", ",", "p2", "[", "COLS", ".", "XYZ", "]", ")"], "docstring": "compute vector between two 3D points\n\n    Args:\n        p1, p2: indexable objects with\n        indices 0, 1, 2 corresponding to 3D cartesian coordinates.\n\n    Returns:\n        3-vector from p1 - p2", "docstring_tokens": ["compute", "vector", "between", "two", "3D", "points"], "sha": "254bb73535b20053d175bc4725bade662177d12b", "url": "https://github.com/BlueBrain/NeuroM/blob/254bb73535b20053d175bc4725bade662177d12b/neurom/morphmath.py#L38-L48", "partition": "train", "idx": 235528}
{"repo": "tchellomello/python-arlo", "path": "pyarlo/base_station.py", "func_name": "ArloBaseStation.get_available_modes", "original_string": "def get_available_modes(self):\n        \"\"\"Return a list of available mode objects for an Arlo user.\"\"\"\n        resource = \"modes\"\n        resource_event = self.publish_and_get_event(resource)\n        if resource_event:\n            properties = resource_event.get(\"properties\")\n            return properties.get(\"modes\")\n\n        return None", "language": "python", "code": "def get_available_modes(self):\n        \"\"\"Return a list of available mode objects for an Arlo user.\"\"\"\n        resource = \"modes\"\n        resource_event = self.publish_and_get_event(resource)\n        if resource_event:\n            properties = resource_event.get(\"properties\")\n            return properties.get(\"modes\")\n\n        return None", "code_tokens": ["def", "get_available_modes", "(", "self", ")", ":", "resource", "=", "\"modes\"", "resource_event", "=", "self", ".", "publish_and_get_event", "(", "resource", ")", "if", "resource_event", ":", "properties", "=", "resource_event", ".", "get", "(", "\"properties\"", ")", "return", "properties", ".", "get", "(", "\"modes\"", ")", "return", "None"], "docstring": "Return a list of available mode objects for an Arlo user.", "docstring_tokens": ["Return", "a", "list", "of", "available", "mode", "objects", "for", "an", "Arlo", "user", "."], "sha": "db70aeb81705309c56ad32bbab1094f6cd146524", "url": "https://github.com/tchellomello/python-arlo/blob/db70aeb81705309c56ad32bbab1094f6cd146524/pyarlo/base_station.py#L371-L379", "partition": "train", "idx": 239989}
{"repo": "DLR-RM/RAFCON", "path": "source/rafcon/core/states/execution_state.py", "func_name": "ExecutionState.run", "original_string": "def run(self):\n        \"\"\" This defines the sequence of actions that are taken when the execution state is executed\n\n        :return:\n        \"\"\"\n        if self.is_root_state:\n            self.execution_history.push_call_history_item(self, CallType.EXECUTE, None, self.input_data)\n\n        logger.debug(\"Running {0}{1}\".format(self, \" (backwards)\" if self.backward_execution else \"\"))\n        if self.backward_execution:\n            self.setup_backward_run()\n        else:\n            self.setup_run()\n\n        try:\n            outcome = self._execute(self.input_data, self.output_data, self.backward_execution)\n            self.state_execution_status = StateExecutionStatus.WAIT_FOR_NEXT_STATE\n\n            if self.backward_execution:\n                # outcome handling is not required as we are in backward mode and the execution order is fixed\n                result = self.finalize()\n            else:\n                # check output data\n                self.check_output_data_type()\n                result = self.finalize(outcome)\n\n            if self.is_root_state:\n                self.execution_history.push_return_history_item(self, CallType.EXECUTE, None, self.output_data)\n            return result\n        except Exception as e:\n            exc_type, exc_value, exc_traceback = sys.exc_info()\n            formatted_exc = traceback.format_exception(exc_type, exc_value, exc_traceback)\n            truncated_exc = []\n            for line in formatted_exc:\n                if os.path.join(\"rafcon\", \"core\") not in line:\n                    truncated_exc.append(line)\n            logger.error(\"{0} had an internal error: {1}: {2}\\n{3}\".format(self, type(e).__name__, e,\n                                                                           ''.join(truncated_exc)))\n            # write error to the output_data of the state\n            self.output_data[\"error\"] = e\n            self.state_execution_status = StateExecutionStatus.WAIT_FOR_NEXT_STATE\n            return self.finalize(Outcome(-1, \"aborted\"))", "language": "python", "code": "def run(self):\n        \"\"\" This defines the sequence of actions that are taken when the execution state is executed\n\n        :return:\n        \"\"\"\n        if self.is_root_state:\n            self.execution_history.push_call_history_item(self, CallType.EXECUTE, None, self.input_data)\n\n        logger.debug(\"Running {0}{1}\".format(self, \" (backwards)\" if self.backward_execution else \"\"))\n        if self.backward_execution:\n            self.setup_backward_run()\n        else:\n            self.setup_run()\n\n        try:\n            outcome = self._execute(self.input_data, self.output_data, self.backward_execution)\n            self.state_execution_status = StateExecutionStatus.WAIT_FOR_NEXT_STATE\n\n            if self.backward_execution:\n                # outcome handling is not required as we are in backward mode and the execution order is fixed\n                result = self.finalize()\n            else:\n                # check output data\n                self.check_output_data_type()\n                result = self.finalize(outcome)\n\n            if self.is_root_state:\n                self.execution_history.push_return_history_item(self, CallType.EXECUTE, None, self.output_data)\n            return result\n        except Exception as e:\n            exc_type, exc_value, exc_traceback = sys.exc_info()\n            formatted_exc = traceback.format_exception(exc_type, exc_value, exc_traceback)\n            truncated_exc = []\n            for line in formatted_exc:\n                if os.path.join(\"rafcon\", \"core\") not in line:\n                    truncated_exc.append(line)\n            logger.error(\"{0} had an internal error: {1}: {2}\\n{3}\".format(self, type(e).__name__, e,\n                                                                           ''.join(truncated_exc)))\n            # write error to the output_data of the state\n            self.output_data[\"error\"] = e\n            self.state_execution_status = StateExecutionStatus.WAIT_FOR_NEXT_STATE\n            return self.finalize(Outcome(-1, \"aborted\"))", "code_tokens": ["def", "run", "(", "self", ")", ":", "if", "self", ".", "is_root_state", ":", "self", ".", "execution_history", ".", "push_call_history_item", "(", "self", ",", "CallType", ".", "EXECUTE", ",", "None", ",", "self", ".", "input_data", ")", "logger", ".", "debug", "(", "\"Running {0}{1}\"", ".", "format", "(", "self", ",", "\" (backwards)\"", "if", "self", ".", "backward_execution", "else", "\"\"", ")", ")", "if", "self", ".", "backward_execution", ":", "self", ".", "setup_backward_run", "(", ")", "else", ":", "self", ".", "setup_run", "(", ")", "try", ":", "outcome", "=", "self", ".", "_execute", "(", "self", ".", "input_data", ",", "self", ".", "output_data", ",", "self", ".", "backward_execution", ")", "self", ".", "state_execution_status", "=", "StateExecutionStatus", ".", "WAIT_FOR_NEXT_STATE", "if", "self", ".", "backward_execution", ":", "# outcome handling is not required as we are in backward mode and the execution order is fixed", "result", "=", "self", ".", "finalize", "(", ")", "else", ":", "# check output data", "self", ".", "check_output_data_type", "(", ")", "result", "=", "self", ".", "finalize", "(", "outcome", ")", "if", "self", ".", "is_root_state", ":", "self", ".", "execution_history", ".", "push_return_history_item", "(", "self", ",", "CallType", ".", "EXECUTE", ",", "None", ",", "self", ".", "output_data", ")", "return", "result", "except", "Exception", "as", "e", ":", "exc_type", ",", "exc_value", ",", "exc_traceback", "=", "sys", ".", "exc_info", "(", ")", "formatted_exc", "=", "traceback", ".", "format_exception", "(", "exc_type", ",", "exc_value", ",", "exc_traceback", ")", "truncated_exc", "=", "[", "]", "for", "line", "in", "formatted_exc", ":", "if", "os", ".", "path", ".", "join", "(", "\"rafcon\"", ",", "\"core\"", ")", "not", "in", "line", ":", "truncated_exc", ".", "append", "(", "line", ")", "logger", ".", "error", "(", "\"{0} had an internal error: {1}: {2}\\n{3}\"", ".", "format", "(", "self", ",", "type", "(", "e", ")", ".", "__name__", ",", "e", ",", "''", ".", "join", "(", "truncated_exc", ")", ")", ")", "# write error to the output_data of the state", "self", ".", "output_data", "[", "\"error\"", "]", "=", "e", "self", ".", "state_execution_status", "=", "StateExecutionStatus", ".", "WAIT_FOR_NEXT_STATE", "return", "self", ".", "finalize", "(", "Outcome", "(", "-", "1", ",", "\"aborted\"", ")", ")"], "docstring": "This defines the sequence of actions that are taken when the execution state is executed\n\n        :return:", "docstring_tokens": ["This", "defines", "the", "sequence", "of", "actions", "that", "are", "taken", "when", "the", "execution", "state", "is", "executed"], "sha": "24942ef1a904531f49ab8830a1dbb604441be498", "url": "https://github.com/DLR-RM/RAFCON/blob/24942ef1a904531f49ab8830a1dbb604441be498/source/rafcon/core/states/execution_state.py#L132-L173", "partition": "train", "idx": 40652}
{"repo": "MoseleyBioinformaticsLab/ctfile", "path": "ctfile/ctfile.py", "func_name": "Ctab.delete_atom", "original_string": "def delete_atom(self, *atom_numbers):\n        \"\"\"Delete atoms by atom number.\n\n        :param str atom_numbers: \n        :return: None.\n        :rtype: :py:obj:`None`\n        \"\"\"\n        for atom_number in atom_numbers:\n            deletion_atom = self.atom_by_number(atom_number=atom_number)\n\n            # update atom numbers\n            for atom in self.atoms:\n                if int(atom.atom_number) > int(atom_number):\n                    atom.atom_number = str(int(atom.atom_number) - 1)\n\n            # find index of a bond to remove and update ctab data dict with new atom numbers\n            for index, bond in enumerate(self.bonds):\n                bond.update_atom_numbers()\n                if atom_number in {bond.first_atom_number, bond.second_atom_number}:\n                    self.bonds.remove(bond)\n\n            # remove atom from neighbors list\n            for atom in self.atoms:\n                if deletion_atom in atom.neighbors:\n                    atom.neighbors.remove(deletion_atom)\n\n            self.atoms.remove(deletion_atom)", "language": "python", "code": "def delete_atom(self, *atom_numbers):\n        \"\"\"Delete atoms by atom number.\n\n        :param str atom_numbers: \n        :return: None.\n        :rtype: :py:obj:`None`\n        \"\"\"\n        for atom_number in atom_numbers:\n            deletion_atom = self.atom_by_number(atom_number=atom_number)\n\n            # update atom numbers\n            for atom in self.atoms:\n                if int(atom.atom_number) > int(atom_number):\n                    atom.atom_number = str(int(atom.atom_number) - 1)\n\n            # find index of a bond to remove and update ctab data dict with new atom numbers\n            for index, bond in enumerate(self.bonds):\n                bond.update_atom_numbers()\n                if atom_number in {bond.first_atom_number, bond.second_atom_number}:\n                    self.bonds.remove(bond)\n\n            # remove atom from neighbors list\n            for atom in self.atoms:\n                if deletion_atom in atom.neighbors:\n                    atom.neighbors.remove(deletion_atom)\n\n            self.atoms.remove(deletion_atom)", "code_tokens": ["def", "delete_atom", "(", "self", ",", "*", "atom_numbers", ")", ":", "for", "atom_number", "in", "atom_numbers", ":", "deletion_atom", "=", "self", ".", "atom_by_number", "(", "atom_number", "=", "atom_number", ")", "# update atom numbers", "for", "atom", "in", "self", ".", "atoms", ":", "if", "int", "(", "atom", ".", "atom_number", ")", ">", "int", "(", "atom_number", ")", ":", "atom", ".", "atom_number", "=", "str", "(", "int", "(", "atom", ".", "atom_number", ")", "-", "1", ")", "# find index of a bond to remove and update ctab data dict with new atom numbers", "for", "index", ",", "bond", "in", "enumerate", "(", "self", ".", "bonds", ")", ":", "bond", ".", "update_atom_numbers", "(", ")", "if", "atom_number", "in", "{", "bond", ".", "first_atom_number", ",", "bond", ".", "second_atom_number", "}", ":", "self", ".", "bonds", ".", "remove", "(", "bond", ")", "# remove atom from neighbors list", "for", "atom", "in", "self", ".", "atoms", ":", "if", "deletion_atom", "in", "atom", ".", "neighbors", ":", "atom", ".", "neighbors", ".", "remove", "(", "deletion_atom", ")", "self", ".", "atoms", ".", "remove", "(", "deletion_atom", ")"], "docstring": "Delete atoms by atom number.\n\n        :param str atom_numbers: \n        :return: None.\n        :rtype: :py:obj:`None`", "docstring_tokens": ["Delete", "atoms", "by", "atom", "number", "."], "sha": "eae864126cd9102207df5d363a3222256a0f1396", "url": "https://github.com/MoseleyBioinformaticsLab/ctfile/blob/eae864126cd9102207df5d363a3222256a0f1396/ctfile/ctfile.py#L522-L548", "partition": "train", "idx": 9522}
{"repo": "scopus-api/scopus", "path": "scopus/abstract_retrieval.py", "func_name": "AbstractRetrieval.idxterms", "original_string": "def idxterms(self):\n        \"\"\"List of index terms.\"\"\"\n        try:\n            terms = listify(self._json.get(\"idxterms\", {}).get('mainterm', []))\n        except AttributeError:  # idxterms is empty\n            return None\n        try:\n            return [d['$'] for d in terms]\n        except AttributeError:\n            return None", "language": "python", "code": "def idxterms(self):\n        \"\"\"List of index terms.\"\"\"\n        try:\n            terms = listify(self._json.get(\"idxterms\", {}).get('mainterm', []))\n        except AttributeError:  # idxterms is empty\n            return None\n        try:\n            return [d['$'] for d in terms]\n        except AttributeError:\n            return None", "code_tokens": ["def", "idxterms", "(", "self", ")", ":", "try", ":", "terms", "=", "listify", "(", "self", ".", "_json", ".", "get", "(", "\"idxterms\"", ",", "{", "}", ")", ".", "get", "(", "'mainterm'", ",", "[", "]", ")", ")", "except", "AttributeError", ":", "# idxterms is empty", "return", "None", "try", ":", "return", "[", "d", "[", "'$'", "]", "for", "d", "in", "terms", "]", "except", "AttributeError", ":", "return", "None"], "docstring": "List of index terms.", "docstring_tokens": ["List", "of", "index", "terms", "."], "sha": "27ce02dd3095bfdab9d3e8475543d7c17767d1ab", "url": "https://github.com/scopus-api/scopus/blob/27ce02dd3095bfdab9d3e8475543d7c17767d1ab/scopus/abstract_retrieval.py#L305-L314", "partition": "train", "idx": 203586}
{"repo": "google/openhtf", "path": "openhtf/core/phase_group.py", "func_name": "PhaseGroup.load_code_info", "original_string": "def load_code_info(self):\n    \"\"\"Load coded info for all contained phases.\"\"\"\n    return PhaseGroup(\n        setup=load_code_info(self.setup),\n        main=load_code_info(self.main),\n        teardown=load_code_info(self.teardown),\n        name=self.name)", "language": "python", "code": "def load_code_info(self):\n    \"\"\"Load coded info for all contained phases.\"\"\"\n    return PhaseGroup(\n        setup=load_code_info(self.setup),\n        main=load_code_info(self.main),\n        teardown=load_code_info(self.teardown),\n        name=self.name)", "code_tokens": ["def", "load_code_info", "(", "self", ")", ":", "return", "PhaseGroup", "(", "setup", "=", "load_code_info", "(", "self", ".", "setup", ")", ",", "main", "=", "load_code_info", "(", "self", ".", "main", ")", ",", "teardown", "=", "load_code_info", "(", "self", ".", "teardown", ")", ",", "name", "=", "self", ".", "name", ")"], "docstring": "Load coded info for all contained phases.", "docstring_tokens": ["Load", "coded", "info", "for", "all", "contained", "phases", "."], "sha": "655e85df7134db7bdf8f8fdd6ff9a6bf932e7b09", "url": "https://github.com/google/openhtf/blob/655e85df7134db7bdf8f8fdd6ff9a6bf932e7b09/openhtf/core/phase_group.py#L183-L189", "partition": "train", "idx": 221917}
{"repo": "ttinies/sc2gameLobby", "path": "sc2gameLobby/gameConfig.py", "func_name": "Config.getVersion", "original_string": "def getVersion(self):\n        \"\"\"the executable application's version\"\"\"\n        if isinstance(self.version, versions.Version):  return self.version\n        if self.version: # verify specified version exists\n            version = versions.Version(self.version) # create this object to allow self._version_ to be specified in multiple different ways by the user\n            if version.baseVersion not in self.installedApp.versionMap(): # verify that the selected version has an executable\n                raise runConfigs.lib.SC2LaunchError(\n                    \"specified game version %s executable is not available.%s    available:  %s\"%( \\\n                    version, os.linesep, \"  \".join(self.installedApp.listVersions())))\n            self.version = version\n        else: # get most recent executable's version\n            path = self.installedApp.exec_path()\n            vResult = self.installedApp.mostRecentVersion\n            self.version = versions.Version(vResult)\n        if self.debug: print(os.linesep.join([\n            \"Game configuration detail:\",\n            \"    platform:   %s\"%(self.os),\n            \"    app:        %s\"%(self.execPath),\n            \"    version:    %s\"%(self.version)]))\n        return self.version", "language": "python", "code": "def getVersion(self):\n        \"\"\"the executable application's version\"\"\"\n        if isinstance(self.version, versions.Version):  return self.version\n        if self.version: # verify specified version exists\n            version = versions.Version(self.version) # create this object to allow self._version_ to be specified in multiple different ways by the user\n            if version.baseVersion not in self.installedApp.versionMap(): # verify that the selected version has an executable\n                raise runConfigs.lib.SC2LaunchError(\n                    \"specified game version %s executable is not available.%s    available:  %s\"%( \\\n                    version, os.linesep, \"  \".join(self.installedApp.listVersions())))\n            self.version = version\n        else: # get most recent executable's version\n            path = self.installedApp.exec_path()\n            vResult = self.installedApp.mostRecentVersion\n            self.version = versions.Version(vResult)\n        if self.debug: print(os.linesep.join([\n            \"Game configuration detail:\",\n            \"    platform:   %s\"%(self.os),\n            \"    app:        %s\"%(self.execPath),\n            \"    version:    %s\"%(self.version)]))\n        return self.version", "code_tokens": ["def", "getVersion", "(", "self", ")", ":", "if", "isinstance", "(", "self", ".", "version", ",", "versions", ".", "Version", ")", ":", "return", "self", ".", "version", "if", "self", ".", "version", ":", "# verify specified version exists", "version", "=", "versions", ".", "Version", "(", "self", ".", "version", ")", "# create this object to allow self._version_ to be specified in multiple different ways by the user", "if", "version", ".", "baseVersion", "not", "in", "self", ".", "installedApp", ".", "versionMap", "(", ")", ":", "# verify that the selected version has an executable", "raise", "runConfigs", ".", "lib", ".", "SC2LaunchError", "(", "\"specified game version %s executable is not available.%s    available:  %s\"", "%", "(", "version", ",", "os", ".", "linesep", ",", "\"  \"", ".", "join", "(", "self", ".", "installedApp", ".", "listVersions", "(", ")", ")", ")", ")", "self", ".", "version", "=", "version", "else", ":", "# get most recent executable's version", "path", "=", "self", ".", "installedApp", ".", "exec_path", "(", ")", "vResult", "=", "self", ".", "installedApp", ".", "mostRecentVersion", "self", ".", "version", "=", "versions", ".", "Version", "(", "vResult", ")", "if", "self", ".", "debug", ":", "print", "(", "os", ".", "linesep", ".", "join", "(", "[", "\"Game configuration detail:\"", ",", "\"    platform:   %s\"", "%", "(", "self", ".", "os", ")", ",", "\"    app:        %s\"", "%", "(", "self", ".", "execPath", ")", ",", "\"    version:    %s\"", "%", "(", "self", ".", "version", ")", "]", ")", ")", "return", "self", ".", "version"], "docstring": "the executable application's version", "docstring_tokens": ["the", "executable", "application", "s", "version"], "sha": "5352d51d53ddeb4858e92e682da89c4434123e52", "url": "https://github.com/ttinies/sc2gameLobby/blob/5352d51d53ddeb4858e92e682da89c4434123e52/sc2gameLobby/gameConfig.py#L449-L468", "partition": "train", "idx": 80445}
{"repo": "audreyr/cookiecutter", "path": "cookiecutter/prompt.py", "func_name": "read_user_dict", "original_string": "def read_user_dict(var_name, default_value):\n    \"\"\"Prompt the user to provide a dictionary of data.\n\n    :param str var_name: Variable as specified in the context\n    :param default_value: Value that will be returned if no input is provided\n    :return: A Python dictionary to use in the context.\n    \"\"\"\n    # Please see http://click.pocoo.org/4/api/#click.prompt\n    if not isinstance(default_value, dict):\n        raise TypeError\n\n    default_display = 'default'\n\n    user_value = click.prompt(\n        var_name,\n        default=default_display,\n        type=click.STRING,\n        value_proc=process_json,\n    )\n\n    if user_value == default_display:\n        # Return the given default w/o any processing\n        return default_value\n    return user_value", "language": "python", "code": "def read_user_dict(var_name, default_value):\n    \"\"\"Prompt the user to provide a dictionary of data.\n\n    :param str var_name: Variable as specified in the context\n    :param default_value: Value that will be returned if no input is provided\n    :return: A Python dictionary to use in the context.\n    \"\"\"\n    # Please see http://click.pocoo.org/4/api/#click.prompt\n    if not isinstance(default_value, dict):\n        raise TypeError\n\n    default_display = 'default'\n\n    user_value = click.prompt(\n        var_name,\n        default=default_display,\n        type=click.STRING,\n        value_proc=process_json,\n    )\n\n    if user_value == default_display:\n        # Return the given default w/o any processing\n        return default_value\n    return user_value", "code_tokens": ["def", "read_user_dict", "(", "var_name", ",", "default_value", ")", ":", "# Please see http://click.pocoo.org/4/api/#click.prompt", "if", "not", "isinstance", "(", "default_value", ",", "dict", ")", ":", "raise", "TypeError", "default_display", "=", "'default'", "user_value", "=", "click", ".", "prompt", "(", "var_name", ",", "default", "=", "default_display", ",", "type", "=", "click", ".", "STRING", ",", "value_proc", "=", "process_json", ",", ")", "if", "user_value", "==", "default_display", ":", "# Return the given default w/o any processing", "return", "default_value", "return", "user_value"], "docstring": "Prompt the user to provide a dictionary of data.\n\n    :param str var_name: Variable as specified in the context\n    :param default_value: Value that will be returned if no input is provided\n    :return: A Python dictionary to use in the context.", "docstring_tokens": ["Prompt", "the", "user", "to", "provide", "a", "dictionary", "of", "data", "."], "sha": "3bc7b987e4ae9dcee996ae0b00375c1325b8d866", "url": "https://github.com/audreyr/cookiecutter/blob/3bc7b987e4ae9dcee996ae0b00375c1325b8d866/cookiecutter/prompt.py#L113-L136", "partition": "train", "idx": 172143}
{"repo": "google/grr", "path": "grr/server/grr_response_server/worker_lib.py", "func_name": "GRRWorker._ProcessMessages", "original_string": "def _ProcessMessages(self, notification, queue_manager):\n    \"\"\"Does the real work with a single flow.\"\"\"\n    flow_obj = None\n    session_id = notification.session_id\n\n    try:\n      # Take a lease on the flow:\n      flow_name = session_id.FlowName()\n      if flow_name in self.well_known_flows:\n        # Well known flows are not necessarily present in the data store so\n        # we need to create them instead of opening.\n        expected_flow = self.well_known_flows[flow_name].__class__\n        flow_obj = aff4.FACTORY.CreateWithLock(\n            session_id,\n            expected_flow,\n            lease_time=self.well_known_flow_lease_time,\n            blocking=False,\n            token=self.token)\n      else:\n        flow_obj = aff4.FACTORY.OpenWithLock(\n            session_id,\n            lease_time=self.flow_lease_time,\n            blocking=False,\n            token=self.token)\n\n      now = time.time()\n      logging.debug(\"Got lock on %s\", session_id)\n\n      # If we get here, we now own the flow. We can delete the notifications\n      # we just retrieved but we need to make sure we don't delete any that\n      # came in later.\n      queue_manager.DeleteNotification(session_id, end=notification.timestamp)\n\n      if flow_name in self.well_known_flows:\n        stats_collector_instance.Get().IncrementCounter(\n            \"well_known_flow_requests\", fields=[str(session_id)])\n\n        # We remove requests first and then process them in the thread pool.\n        # On one hand this approach increases the risk of losing requests in\n        # case the worker process dies. On the other hand, it doesn't hold\n        # the lock while requests are processed, so other workers can\n        # process well known flows requests as well.\n        with flow_obj:\n          responses = flow_obj.FetchAndRemoveRequestsAndResponses(session_id)\n\n        flow_obj.ProcessResponses(responses, self.thread_pool)\n\n      else:\n        with flow_obj:\n          self._ProcessRegularFlowMessages(flow_obj, notification)\n\n      elapsed = time.time() - now\n      logging.debug(\"Done processing %s: %s sec\", session_id, elapsed)\n      stats_collector_instance.Get().RecordEvent(\n          \"worker_flow_processing_time\", elapsed, fields=[flow_obj.Name()])\n\n      # Everything went well -> session can be run again.\n      self.queued_flows.ExpireObject(session_id)\n\n    except aff4.LockError:\n      # Another worker is dealing with this flow right now, we just skip it.\n      # We expect lots of these when there are few messages (the system isn't\n      # highly loaded) but it is interesting when the system is under load to\n      # know if we are pulling the optimal number of messages off the queue.\n      # A high number of lock fails when there is plenty of work to do would\n      # indicate we are wasting time trying to process work that has already\n      # been completed by other workers.\n      stats_collector_instance.Get().IncrementCounter(\"worker_flow_lock_error\")\n\n    except FlowProcessingError:\n      # Do nothing as we expect the error to be correctly logged and accounted\n      # already.\n      pass\n\n    except Exception as e:  # pylint: disable=broad-except\n      # Something went wrong when processing this session. In order not to spin\n      # here, we just remove the notification.\n      logging.exception(\"Error processing session %s: %s\", session_id, e)\n      stats_collector_instance.Get().IncrementCounter(\n          \"worker_session_errors\", fields=[str(type(e))])\n      queue_manager.DeleteNotification(session_id)", "language": "python", "code": "def _ProcessMessages(self, notification, queue_manager):\n    \"\"\"Does the real work with a single flow.\"\"\"\n    flow_obj = None\n    session_id = notification.session_id\n\n    try:\n      # Take a lease on the flow:\n      flow_name = session_id.FlowName()\n      if flow_name in self.well_known_flows:\n        # Well known flows are not necessarily present in the data store so\n        # we need to create them instead of opening.\n        expected_flow = self.well_known_flows[flow_name].__class__\n        flow_obj = aff4.FACTORY.CreateWithLock(\n            session_id,\n            expected_flow,\n            lease_time=self.well_known_flow_lease_time,\n            blocking=False,\n            token=self.token)\n      else:\n        flow_obj = aff4.FACTORY.OpenWithLock(\n            session_id,\n            lease_time=self.flow_lease_time,\n            blocking=False,\n            token=self.token)\n\n      now = time.time()\n      logging.debug(\"Got lock on %s\", session_id)\n\n      # If we get here, we now own the flow. We can delete the notifications\n      # we just retrieved but we need to make sure we don't delete any that\n      # came in later.\n      queue_manager.DeleteNotification(session_id, end=notification.timestamp)\n\n      if flow_name in self.well_known_flows:\n        stats_collector_instance.Get().IncrementCounter(\n            \"well_known_flow_requests\", fields=[str(session_id)])\n\n        # We remove requests first and then process them in the thread pool.\n        # On one hand this approach increases the risk of losing requests in\n        # case the worker process dies. On the other hand, it doesn't hold\n        # the lock while requests are processed, so other workers can\n        # process well known flows requests as well.\n        with flow_obj:\n          responses = flow_obj.FetchAndRemoveRequestsAndResponses(session_id)\n\n        flow_obj.ProcessResponses(responses, self.thread_pool)\n\n      else:\n        with flow_obj:\n          self._ProcessRegularFlowMessages(flow_obj, notification)\n\n      elapsed = time.time() - now\n      logging.debug(\"Done processing %s: %s sec\", session_id, elapsed)\n      stats_collector_instance.Get().RecordEvent(\n          \"worker_flow_processing_time\", elapsed, fields=[flow_obj.Name()])\n\n      # Everything went well -> session can be run again.\n      self.queued_flows.ExpireObject(session_id)\n\n    except aff4.LockError:\n      # Another worker is dealing with this flow right now, we just skip it.\n      # We expect lots of these when there are few messages (the system isn't\n      # highly loaded) but it is interesting when the system is under load to\n      # know if we are pulling the optimal number of messages off the queue.\n      # A high number of lock fails when there is plenty of work to do would\n      # indicate we are wasting time trying to process work that has already\n      # been completed by other workers.\n      stats_collector_instance.Get().IncrementCounter(\"worker_flow_lock_error\")\n\n    except FlowProcessingError:\n      # Do nothing as we expect the error to be correctly logged and accounted\n      # already.\n      pass\n\n    except Exception as e:  # pylint: disable=broad-except\n      # Something went wrong when processing this session. In order not to spin\n      # here, we just remove the notification.\n      logging.exception(\"Error processing session %s: %s\", session_id, e)\n      stats_collector_instance.Get().IncrementCounter(\n          \"worker_session_errors\", fields=[str(type(e))])\n      queue_manager.DeleteNotification(session_id)", "code_tokens": ["def", "_ProcessMessages", "(", "self", ",", "notification", ",", "queue_manager", ")", ":", "flow_obj", "=", "None", "session_id", "=", "notification", ".", "session_id", "try", ":", "# Take a lease on the flow:", "flow_name", "=", "session_id", ".", "FlowName", "(", ")", "if", "flow_name", "in", "self", ".", "well_known_flows", ":", "# Well known flows are not necessarily present in the data store so", "# we need to create them instead of opening.", "expected_flow", "=", "self", ".", "well_known_flows", "[", "flow_name", "]", ".", "__class__", "flow_obj", "=", "aff4", ".", "FACTORY", ".", "CreateWithLock", "(", "session_id", ",", "expected_flow", ",", "lease_time", "=", "self", ".", "well_known_flow_lease_time", ",", "blocking", "=", "False", ",", "token", "=", "self", ".", "token", ")", "else", ":", "flow_obj", "=", "aff4", ".", "FACTORY", ".", "OpenWithLock", "(", "session_id", ",", "lease_time", "=", "self", ".", "flow_lease_time", ",", "blocking", "=", "False", ",", "token", "=", "self", ".", "token", ")", "now", "=", "time", ".", "time", "(", ")", "logging", ".", "debug", "(", "\"Got lock on %s\"", ",", "session_id", ")", "# If we get here, we now own the flow. We can delete the notifications", "# we just retrieved but we need to make sure we don't delete any that", "# came in later.", "queue_manager", ".", "DeleteNotification", "(", "session_id", ",", "end", "=", "notification", ".", "timestamp", ")", "if", "flow_name", "in", "self", ".", "well_known_flows", ":", "stats_collector_instance", ".", "Get", "(", ")", ".", "IncrementCounter", "(", "\"well_known_flow_requests\"", ",", "fields", "=", "[", "str", "(", "session_id", ")", "]", ")", "# We remove requests first and then process them in the thread pool.", "# On one hand this approach increases the risk of losing requests in", "# case the worker process dies. On the other hand, it doesn't hold", "# the lock while requests are processed, so other workers can", "# process well known flows requests as well.", "with", "flow_obj", ":", "responses", "=", "flow_obj", ".", "FetchAndRemoveRequestsAndResponses", "(", "session_id", ")", "flow_obj", ".", "ProcessResponses", "(", "responses", ",", "self", ".", "thread_pool", ")", "else", ":", "with", "flow_obj", ":", "self", ".", "_ProcessRegularFlowMessages", "(", "flow_obj", ",", "notification", ")", "elapsed", "=", "time", ".", "time", "(", ")", "-", "now", "logging", ".", "debug", "(", "\"Done processing %s: %s sec\"", ",", "session_id", ",", "elapsed", ")", "stats_collector_instance", ".", "Get", "(", ")", ".", "RecordEvent", "(", "\"worker_flow_processing_time\"", ",", "elapsed", ",", "fields", "=", "[", "flow_obj", ".", "Name", "(", ")", "]", ")", "# Everything went well -> session can be run again.", "self", ".", "queued_flows", ".", "ExpireObject", "(", "session_id", ")", "except", "aff4", ".", "LockError", ":", "# Another worker is dealing with this flow right now, we just skip it.", "# We expect lots of these when there are few messages (the system isn't", "# highly loaded) but it is interesting when the system is under load to", "# know if we are pulling the optimal number of messages off the queue.", "# A high number of lock fails when there is plenty of work to do would", "# indicate we are wasting time trying to process work that has already", "# been completed by other workers.", "stats_collector_instance", ".", "Get", "(", ")", ".", "IncrementCounter", "(", "\"worker_flow_lock_error\"", ")", "except", "FlowProcessingError", ":", "# Do nothing as we expect the error to be correctly logged and accounted", "# already.", "pass", "except", "Exception", "as", "e", ":", "# pylint: disable=broad-except", "# Something went wrong when processing this session. In order not to spin", "# here, we just remove the notification.", "logging", ".", "exception", "(", "\"Error processing session %s: %s\"", ",", "session_id", ",", "e", ")", "stats_collector_instance", ".", "Get", "(", ")", ".", "IncrementCounter", "(", "\"worker_session_errors\"", ",", "fields", "=", "[", "str", "(", "type", "(", "e", ")", ")", "]", ")", "queue_manager", ".", "DeleteNotification", "(", "session_id", ")"], "docstring": "Does the real work with a single flow.", "docstring_tokens": ["Does", "the", "real", "work", "with", "a", "single", "flow", "."], "sha": "5cef4e8e2f0d5df43ea4877e9c798e0bf60bfe74", "url": "https://github.com/google/grr/blob/5cef4e8e2f0d5df43ea4877e9c798e0bf60bfe74/grr/server/grr_response_server/worker_lib.py#L303-L383", "partition": "train", "idx": 131566}
{"repo": "peterbrittain/asciimatics", "path": "asciimatics/widgets.py", "func_name": "Frame.move_to", "original_string": "def move_to(self, x, y, h):\n        \"\"\"\n        Make the specified location visible.  This is typically used by a widget to scroll the\n        canvas such that it is visible.\n\n        :param x: The x location to make visible.\n        :param y: The y location to make visible.\n        :param h: The height of the location to make visible.\n        \"\"\"\n        if self._has_border:\n            start_x = 1\n            width = self.canvas.width - 2\n            start_y = self.canvas.start_line + 1\n            height = self.canvas.height - 2\n        else:\n            start_x = 0\n            width = self.canvas.width\n            start_y = self.canvas.start_line\n            height = self.canvas.height\n\n        if ((x >= start_x) and (x < start_x + width) and\n                (y >= start_y) and (y + h < start_y + height)):\n            # Already OK - quit now.\n            return\n\n        if y < start_y:\n            self.canvas.scroll_to(y - 1 if self._has_border else y)\n        else:\n            line = y + h - self.canvas.height + (1 if self._has_border else 0)\n            self.canvas.scroll_to(max(0, line))", "language": "python", "code": "def move_to(self, x, y, h):\n        \"\"\"\n        Make the specified location visible.  This is typically used by a widget to scroll the\n        canvas such that it is visible.\n\n        :param x: The x location to make visible.\n        :param y: The y location to make visible.\n        :param h: The height of the location to make visible.\n        \"\"\"\n        if self._has_border:\n            start_x = 1\n            width = self.canvas.width - 2\n            start_y = self.canvas.start_line + 1\n            height = self.canvas.height - 2\n        else:\n            start_x = 0\n            width = self.canvas.width\n            start_y = self.canvas.start_line\n            height = self.canvas.height\n\n        if ((x >= start_x) and (x < start_x + width) and\n                (y >= start_y) and (y + h < start_y + height)):\n            # Already OK - quit now.\n            return\n\n        if y < start_y:\n            self.canvas.scroll_to(y - 1 if self._has_border else y)\n        else:\n            line = y + h - self.canvas.height + (1 if self._has_border else 0)\n            self.canvas.scroll_to(max(0, line))", "code_tokens": ["def", "move_to", "(", "self", ",", "x", ",", "y", ",", "h", ")", ":", "if", "self", ".", "_has_border", ":", "start_x", "=", "1", "width", "=", "self", ".", "canvas", ".", "width", "-", "2", "start_y", "=", "self", ".", "canvas", ".", "start_line", "+", "1", "height", "=", "self", ".", "canvas", ".", "height", "-", "2", "else", ":", "start_x", "=", "0", "width", "=", "self", ".", "canvas", ".", "width", "start_y", "=", "self", ".", "canvas", ".", "start_line", "height", "=", "self", ".", "canvas", ".", "height", "if", "(", "(", "x", ">=", "start_x", ")", "and", "(", "x", "<", "start_x", "+", "width", ")", "and", "(", "y", ">=", "start_y", ")", "and", "(", "y", "+", "h", "<", "start_y", "+", "height", ")", ")", ":", "# Already OK - quit now.", "return", "if", "y", "<", "start_y", ":", "self", ".", "canvas", ".", "scroll_to", "(", "y", "-", "1", "if", "self", ".", "_has_border", "else", "y", ")", "else", ":", "line", "=", "y", "+", "h", "-", "self", ".", "canvas", ".", "height", "+", "(", "1", "if", "self", ".", "_has_border", "else", "0", ")", "self", ".", "canvas", ".", "scroll_to", "(", "max", "(", "0", ",", "line", ")", ")"], "docstring": "Make the specified location visible.  This is typically used by a widget to scroll the\n        canvas such that it is visible.\n\n        :param x: The x location to make visible.\n        :param y: The y location to make visible.\n        :param h: The height of the location to make visible.", "docstring_tokens": ["Make", "the", "specified", "location", "visible", ".", "This", "is", "typically", "used", "by", "a", "widget", "to", "scroll", "the", "canvas", "such", "that", "it", "is", "visible", "."], "sha": "f471427d7786ce2d5f1eeb2dae0e67d19e46e085", "url": "https://github.com/peterbrittain/asciimatics/blob/f471427d7786ce2d5f1eeb2dae0e67d19e46e085/asciimatics/widgets.py#L763-L792", "partition": "train", "idx": 146076}
