{"repo": "googleapis/google-cloud-python", "path": "bigtable/google/cloud/bigtable/policy.py", "func_name": "Policy.bigtable_users", "original_string": "def bigtable_users(self):\n        \"\"\"Access to bigtable.user role memebers\n\n        For example:\n\n        .. literalinclude:: snippets.py\n            :start-after: [START bigtable_users_policy]\n            :end-before: [END bigtable_users_policy]\n        \"\"\"\n        result = set()\n        for member in self._bindings.get(BIGTABLE_USER_ROLE, ()):\n            result.add(member)\n        return frozenset(result)", "language": "python", "code": "def bigtable_users(self):\n        \"\"\"Access to bigtable.user role memebers\n\n        For example:\n\n        .. literalinclude:: snippets.py\n            :start-after: [START bigtable_users_policy]\n            :end-before: [END bigtable_users_policy]\n        \"\"\"\n        result = set()\n        for member in self._bindings.get(BIGTABLE_USER_ROLE, ()):\n            result.add(member)\n        return frozenset(result)", "code_tokens": ["def", "bigtable_users", "(", "self", ")", ":", "result", "=", "set", "(", ")", "for", "member", "in", "self", ".", "_bindings", ".", "get", "(", "BIGTABLE_USER_ROLE", ",", "(", ")", ")", ":", "result", ".", "add", "(", "member", ")", "return", "frozenset", "(", "result", ")"], "docstring": "Access to bigtable.user role memebers\n\n        For example:\n\n        .. literalinclude:: snippets.py\n            :start-after: [START bigtable_users_policy]\n            :end-before: [END bigtable_users_policy]", "docstring_tokens": ["Access", "to", "bigtable", ".", "user", "role", "memebers"], "sha": "85e80125a59cb10f8cb105f25ecc099e4b940b50", "url": "https://github.com/googleapis/google-cloud-python/blob/85e80125a59cb10f8cb105f25ecc099e4b940b50/bigtable/google/cloud/bigtable/policy.py#L113-L125", "partition": "train", "idx": 167504}
{"repo": "opendatateam/udata", "path": "udata/theme/__init__.py", "func_name": "theme_static_with_version", "original_string": "def theme_static_with_version(ctx, filename, external=False):\n    '''Override the default theme static to add cache burst'''\n    if current_app.theme_manager.static_folder:\n        url = assets.cdn_for('_themes.static',\n                             filename=current.identifier + '/' + filename,\n                             _external=external)\n    else:\n        url = assets.cdn_for('_themes.static',\n                             themeid=current.identifier,\n                             filename=filename,\n                             _external=external)\n    if url.endswith('/'):  # this is a directory, no need for cache burst\n        return url\n    if current_app.config['DEBUG']:\n        burst = time()\n    else:\n        burst = current.entrypoint.dist.version\n    return '{url}?_={burst}'.format(url=url, burst=burst)", "language": "python", "code": "def theme_static_with_version(ctx, filename, external=False):\n    '''Override the default theme static to add cache burst'''\n    if current_app.theme_manager.static_folder:\n        url = assets.cdn_for('_themes.static',\n                             filename=current.identifier + '/' + filename,\n                             _external=external)\n    else:\n        url = assets.cdn_for('_themes.static',\n                             themeid=current.identifier,\n                             filename=filename,\n                             _external=external)\n    if url.endswith('/'):  # this is a directory, no need for cache burst\n        return url\n    if current_app.config['DEBUG']:\n        burst = time()\n    else:\n        burst = current.entrypoint.dist.version\n    return '{url}?_={burst}'.format(url=url, burst=burst)", "code_tokens": ["def", "theme_static_with_version", "(", "ctx", ",", "filename", ",", "external", "=", "False", ")", ":", "if", "current_app", ".", "theme_manager", ".", "static_folder", ":", "url", "=", "assets", ".", "cdn_for", "(", "'_themes.static'", ",", "filename", "=", "current", ".", "identifier", "+", "'/'", "+", "filename", ",", "_external", "=", "external", ")", "else", ":", "url", "=", "assets", ".", "cdn_for", "(", "'_themes.static'", ",", "themeid", "=", "current", ".", "identifier", ",", "filename", "=", "filename", ",", "_external", "=", "external", ")", "if", "url", ".", "endswith", "(", "'/'", ")", ":", "# this is a directory, no need for cache burst", "return", "url", "if", "current_app", ".", "config", "[", "'DEBUG'", "]", ":", "burst", "=", "time", "(", ")", "else", ":", "burst", "=", "current", ".", "entrypoint", ".", "dist", ".", "version", "return", "'{url}?_={burst}'", ".", "format", "(", "url", "=", "url", ",", "burst", "=", "burst", ")"], "docstring": "Override the default theme static to add cache burst", "docstring_tokens": ["Override", "the", "default", "theme", "static", "to", "add", "cache", "burst"], "sha": "f016585af94b0ff6bd73738c700324adc8ba7f8f", "url": "https://github.com/opendatateam/udata/blob/f016585af94b0ff6bd73738c700324adc8ba7f8f/udata/theme/__init__.py#L48-L65", "partition": "train", "idx": 247312}
{"repo": "materialsproject/pymatgen", "path": "pymatgen/core/structure.py", "func_name": "Structure.insert", "original_string": "def insert(self, i, species, coords, coords_are_cartesian=False,\n               validate_proximity=False, properties=None):\n        \"\"\"\n        Insert a site to the structure.\n\n        Args:\n            i (int): Index to insert site\n            species (species-like): Species of inserted site\n            coords (3x1 array): Coordinates of inserted site\n            coords_are_cartesian (bool): Whether coordinates are cartesian.\n                Defaults to False.\n            validate_proximity (bool): Whether to check if inserted site is\n                too close to an existing site. Defaults to False.\n            properties (dict): Properties associated with the site.\n\n        Returns:\n            New structure with inserted site.\n        \"\"\"\n        if not coords_are_cartesian:\n            new_site = PeriodicSite(species, coords, self._lattice,\n                                    properties=properties)\n        else:\n            frac_coords = self._lattice.get_fractional_coords(coords)\n            new_site = PeriodicSite(species, frac_coords, self._lattice,\n                                    properties=properties)\n\n        if validate_proximity:\n            for site in self:\n                if site.distance(new_site) < self.DISTANCE_TOLERANCE:\n                    raise ValueError(\"New site is too close to an existing \"\n                                     \"site!\")\n\n        self._sites.insert(i, new_site)", "language": "python", "code": "def insert(self, i, species, coords, coords_are_cartesian=False,\n               validate_proximity=False, properties=None):\n        \"\"\"\n        Insert a site to the structure.\n\n        Args:\n            i (int): Index to insert site\n            species (species-like): Species of inserted site\n            coords (3x1 array): Coordinates of inserted site\n            coords_are_cartesian (bool): Whether coordinates are cartesian.\n                Defaults to False.\n            validate_proximity (bool): Whether to check if inserted site is\n                too close to an existing site. Defaults to False.\n            properties (dict): Properties associated with the site.\n\n        Returns:\n            New structure with inserted site.\n        \"\"\"\n        if not coords_are_cartesian:\n            new_site = PeriodicSite(species, coords, self._lattice,\n                                    properties=properties)\n        else:\n            frac_coords = self._lattice.get_fractional_coords(coords)\n            new_site = PeriodicSite(species, frac_coords, self._lattice,\n                                    properties=properties)\n\n        if validate_proximity:\n            for site in self:\n                if site.distance(new_site) < self.DISTANCE_TOLERANCE:\n                    raise ValueError(\"New site is too close to an existing \"\n                                     \"site!\")\n\n        self._sites.insert(i, new_site)", "code_tokens": ["def", "insert", "(", "self", ",", "i", ",", "species", ",", "coords", ",", "coords_are_cartesian", "=", "False", ",", "validate_proximity", "=", "False", ",", "properties", "=", "None", ")", ":", "if", "not", "coords_are_cartesian", ":", "new_site", "=", "PeriodicSite", "(", "species", ",", "coords", ",", "self", ".", "_lattice", ",", "properties", "=", "properties", ")", "else", ":", "frac_coords", "=", "self", ".", "_lattice", ".", "get_fractional_coords", "(", "coords", ")", "new_site", "=", "PeriodicSite", "(", "species", ",", "frac_coords", ",", "self", ".", "_lattice", ",", "properties", "=", "properties", ")", "if", "validate_proximity", ":", "for", "site", "in", "self", ":", "if", "site", ".", "distance", "(", "new_site", ")", "<", "self", ".", "DISTANCE_TOLERANCE", ":", "raise", "ValueError", "(", "\"New site is too close to an existing \"", "\"site!\"", ")", "self", ".", "_sites", ".", "insert", "(", "i", ",", "new_site", ")"], "docstring": "Insert a site to the structure.\n\n        Args:\n            i (int): Index to insert site\n            species (species-like): Species of inserted site\n            coords (3x1 array): Coordinates of inserted site\n            coords_are_cartesian (bool): Whether coordinates are cartesian.\n                Defaults to False.\n            validate_proximity (bool): Whether to check if inserted site is\n                too close to an existing site. Defaults to False.\n            properties (dict): Properties associated with the site.\n\n        Returns:\n            New structure with inserted site.", "docstring_tokens": ["Insert", "a", "site", "to", "the", "structure", "."], "sha": "4ca558cf72f8d5f8a1f21dfdfc0181a971c186da", "url": "https://github.com/materialsproject/pymatgen/blob/4ca558cf72f8d5f8a1f21dfdfc0181a971c186da/pymatgen/core/structure.py#L2658-L2690", "partition": "train", "idx": 134257}
{"repo": "nrcharles/caelum", "path": "caelum/forecast.py", "func_name": "data", "original_string": "def data(place):\n    \"\"\"get forecast data.\"\"\"\n    lat, lon = place\n    url = \"https://api.forecast.io/forecast/%s/%s,%s?solar\" % (APIKEY, lat,\n                                                               lon)\n    w_data = json.loads(urllib2.urlopen(url).read())\n    return w_data", "language": "python", "code": "def data(place):\n    \"\"\"get forecast data.\"\"\"\n    lat, lon = place\n    url = \"https://api.forecast.io/forecast/%s/%s,%s?solar\" % (APIKEY, lat,\n                                                               lon)\n    w_data = json.loads(urllib2.urlopen(url).read())\n    return w_data", "code_tokens": ["def", "data", "(", "place", ")", ":", "lat", ",", "lon", "=", "place", "url", "=", "\"https://api.forecast.io/forecast/%s/%s,%s?solar\"", "%", "(", "APIKEY", ",", "lat", ",", "lon", ")", "w_data", "=", "json", ".", "loads", "(", "urllib2", ".", "urlopen", "(", "url", ")", ".", "read", "(", ")", ")", "return", "w_data"], "docstring": "get forecast data.", "docstring_tokens": ["get", "forecast", "data", "."], "sha": "9a8e65806385978556d7bb2e6870f003ff82023e", "url": "https://github.com/nrcharles/caelum/blob/9a8e65806385978556d7bb2e6870f003ff82023e/caelum/forecast.py#L13-L19", "partition": "train", "idx": 83406}
{"repo": "gwpy/gwpy", "path": "gwpy/io/nds2.py", "func_name": "minute_trend_times", "original_string": "def minute_trend_times(start, end):\n    \"\"\"Expand a [start, end) interval for use in querying for minute trends\n\n    NDS2 requires start and end times for minute trends to be a multiple of\n    60 (to exactly match the time of a minute-trend sample), so this function\n    expands the given ``[start, end)`` interval to the nearest multiples.\n\n    Parameters\n    ----------\n    start : `int`\n        GPS start time of query\n\n    end : `int`\n        GPS end time of query\n\n    Returns\n    -------\n    mstart : `int`\n        ``start`` rounded down to nearest multiple of 60\n    mend : `int`\n        ``end`` rounded up to nearest multiple of 60\n    \"\"\"\n    if start % 60:\n        start = int(start) // 60 * 60\n    if end % 60:\n        end = int(end) // 60 * 60 + 60\n    return int(start), int(end)", "language": "python", "code": "def minute_trend_times(start, end):\n    \"\"\"Expand a [start, end) interval for use in querying for minute trends\n\n    NDS2 requires start and end times for minute trends to be a multiple of\n    60 (to exactly match the time of a minute-trend sample), so this function\n    expands the given ``[start, end)`` interval to the nearest multiples.\n\n    Parameters\n    ----------\n    start : `int`\n        GPS start time of query\n\n    end : `int`\n        GPS end time of query\n\n    Returns\n    -------\n    mstart : `int`\n        ``start`` rounded down to nearest multiple of 60\n    mend : `int`\n        ``end`` rounded up to nearest multiple of 60\n    \"\"\"\n    if start % 60:\n        start = int(start) // 60 * 60\n    if end % 60:\n        end = int(end) // 60 * 60 + 60\n    return int(start), int(end)", "code_tokens": ["def", "minute_trend_times", "(", "start", ",", "end", ")", ":", "if", "start", "%", "60", ":", "start", "=", "int", "(", "start", ")", "//", "60", "*", "60", "if", "end", "%", "60", ":", "end", "=", "int", "(", "end", ")", "//", "60", "*", "60", "+", "60", "return", "int", "(", "start", ")", ",", "int", "(", "end", ")"], "docstring": "Expand a [start, end) interval for use in querying for minute trends\n\n    NDS2 requires start and end times for minute trends to be a multiple of\n    60 (to exactly match the time of a minute-trend sample), so this function\n    expands the given ``[start, end)`` interval to the nearest multiples.\n\n    Parameters\n    ----------\n    start : `int`\n        GPS start time of query\n\n    end : `int`\n        GPS end time of query\n\n    Returns\n    -------\n    mstart : `int`\n        ``start`` rounded down to nearest multiple of 60\n    mend : `int`\n        ``end`` rounded up to nearest multiple of 60", "docstring_tokens": ["Expand", "a", "[", "start", "end", ")", "interval", "for", "use", "in", "querying", "for", "minute", "trends"], "sha": "7a92b917e7dd2d99b15895293a1fa1d66cdb210a", "url": "https://github.com/gwpy/gwpy/blob/7a92b917e7dd2d99b15895293a1fa1d66cdb210a/gwpy/io/nds2.py#L608-L634", "partition": "train", "idx": 211239}
{"repo": "sprockets/sprockets-influxdb", "path": "sprockets_influxdb.py", "func_name": "_sample_batch", "original_string": "def _sample_batch():\n    \"\"\"Determine if a batch should be processed and if not, pop off all of\n    the pending metrics for that batch.\n\n    :rtype: bool\n\n    \"\"\"\n    if _sample_probability == 1.0 or random.random() < _sample_probability:\n        return True\n\n    # Pop off all the metrics for the batch\n    for database in _measurements:\n        _measurements[database] = _measurements[database][_max_batch_size:]\n    return False", "language": "python", "code": "def _sample_batch():\n    \"\"\"Determine if a batch should be processed and if not, pop off all of\n    the pending metrics for that batch.\n\n    :rtype: bool\n\n    \"\"\"\n    if _sample_probability == 1.0 or random.random() < _sample_probability:\n        return True\n\n    # Pop off all the metrics for the batch\n    for database in _measurements:\n        _measurements[database] = _measurements[database][_max_batch_size:]\n    return False", "code_tokens": ["def", "_sample_batch", "(", ")", ":", "if", "_sample_probability", "==", "1.0", "or", "random", ".", "random", "(", ")", "<", "_sample_probability", ":", "return", "True", "# Pop off all the metrics for the batch", "for", "database", "in", "_measurements", ":", "_measurements", "[", "database", "]", "=", "_measurements", "[", "database", "]", "[", "_max_batch_size", ":", "]", "return", "False"], "docstring": "Determine if a batch should be processed and if not, pop off all of\n    the pending metrics for that batch.\n\n    :rtype: bool", "docstring_tokens": ["Determine", "if", "a", "batch", "should", "be", "processed", "and", "if", "not", "pop", "off", "all", "of", "the", "pending", "metrics", "for", "that", "batch", "."], "sha": "cce73481b8f26b02e65e3f9914a9a22eceff3063", "url": "https://github.com/sprockets/sprockets-influxdb/blob/cce73481b8f26b02e65e3f9914a9a22eceff3063/sprockets_influxdb.py#L631-L644", "partition": "train", "idx": 11297}
{"repo": "jelmer/python-fastimport", "path": "fastimport/processors/filter_processor.py", "func_name": "FilterProcessor._convert_rename", "original_string": "def _convert_rename(self, fc):\n        \"\"\"Convert a FileRenameCommand into a new FileCommand.\n\n        :return: None if the rename is being ignored, otherwise a\n          new FileCommand based on the whether the old and new paths\n          are inside or outside of the interesting locations.\n          \"\"\"\n        old = fc.old_path\n        new = fc.new_path\n        keep_old = self._path_to_be_kept(old)\n        keep_new = self._path_to_be_kept(new)\n        if keep_old and keep_new:\n            fc.old_path = self._adjust_for_new_root(old)\n            fc.new_path = self._adjust_for_new_root(new)\n            return fc\n        elif keep_old:\n            # The file has been renamed to a non-interesting location.\n            # Delete it!\n            old = self._adjust_for_new_root(old)\n            return commands.FileDeleteCommand(old)\n        elif keep_new:\n            # The file has been renamed into an interesting location\n            # We really ought to add it but we don't currently buffer\n            # the contents of all previous files and probably never want\n            # to. Maybe fast-import-info needs to be extended to\n            # remember all renames and a config file can be passed\n            # into here ala fast-import?\n            self.warning(\"cannot turn rename of %s into an add of %s yet\" %\n                (old, new))\n        return None", "language": "python", "code": "def _convert_rename(self, fc):\n        \"\"\"Convert a FileRenameCommand into a new FileCommand.\n\n        :return: None if the rename is being ignored, otherwise a\n          new FileCommand based on the whether the old and new paths\n          are inside or outside of the interesting locations.\n          \"\"\"\n        old = fc.old_path\n        new = fc.new_path\n        keep_old = self._path_to_be_kept(old)\n        keep_new = self._path_to_be_kept(new)\n        if keep_old and keep_new:\n            fc.old_path = self._adjust_for_new_root(old)\n            fc.new_path = self._adjust_for_new_root(new)\n            return fc\n        elif keep_old:\n            # The file has been renamed to a non-interesting location.\n            # Delete it!\n            old = self._adjust_for_new_root(old)\n            return commands.FileDeleteCommand(old)\n        elif keep_new:\n            # The file has been renamed into an interesting location\n            # We really ought to add it but we don't currently buffer\n            # the contents of all previous files and probably never want\n            # to. Maybe fast-import-info needs to be extended to\n            # remember all renames and a config file can be passed\n            # into here ala fast-import?\n            self.warning(\"cannot turn rename of %s into an add of %s yet\" %\n                (old, new))\n        return None", "code_tokens": ["def", "_convert_rename", "(", "self", ",", "fc", ")", ":", "old", "=", "fc", ".", "old_path", "new", "=", "fc", ".", "new_path", "keep_old", "=", "self", ".", "_path_to_be_kept", "(", "old", ")", "keep_new", "=", "self", ".", "_path_to_be_kept", "(", "new", ")", "if", "keep_old", "and", "keep_new", ":", "fc", ".", "old_path", "=", "self", ".", "_adjust_for_new_root", "(", "old", ")", "fc", ".", "new_path", "=", "self", ".", "_adjust_for_new_root", "(", "new", ")", "return", "fc", "elif", "keep_old", ":", "# The file has been renamed to a non-interesting location.", "# Delete it!", "old", "=", "self", ".", "_adjust_for_new_root", "(", "old", ")", "return", "commands", ".", "FileDeleteCommand", "(", "old", ")", "elif", "keep_new", ":", "# The file has been renamed into an interesting location", "# We really ought to add it but we don't currently buffer", "# the contents of all previous files and probably never want", "# to. Maybe fast-import-info needs to be extended to", "# remember all renames and a config file can be passed", "# into here ala fast-import?", "self", ".", "warning", "(", "\"cannot turn rename of %s into an add of %s yet\"", "%", "(", "old", ",", "new", ")", ")", "return", "None"], "docstring": "Convert a FileRenameCommand into a new FileCommand.\n\n        :return: None if the rename is being ignored, otherwise a\n          new FileCommand based on the whether the old and new paths\n          are inside or outside of the interesting locations.", "docstring_tokens": ["Convert", "a", "FileRenameCommand", "into", "a", "new", "FileCommand", "."], "sha": "5cef9e037b7d7b37f58f522ac9ea4e343e6a1dff", "url": "https://github.com/jelmer/python-fastimport/blob/5cef9e037b7d7b37f58f522ac9ea4e343e6a1dff/fastimport/processors/filter_processor.py#L241-L270", "partition": "train", "idx": 80585}
{"repo": "cocaine/cocaine-tools", "path": "cocaine/tools/dispatch.py", "func_name": "group_view", "original_string": "def group_view(name, **kwargs):\n    \"\"\"\n    Show specified routing group.\n    \"\"\"\n    ctx = Context(**kwargs)\n    ctx.execute_action('group:view', **{\n        'storage': ctx.repo.create_secure_service('storage'),\n        'name': name,\n    })", "language": "python", "code": "def group_view(name, **kwargs):\n    \"\"\"\n    Show specified routing group.\n    \"\"\"\n    ctx = Context(**kwargs)\n    ctx.execute_action('group:view', **{\n        'storage': ctx.repo.create_secure_service('storage'),\n        'name': name,\n    })", "code_tokens": ["def", "group_view", "(", "name", ",", "*", "*", "kwargs", ")", ":", "ctx", "=", "Context", "(", "*", "*", "kwargs", ")", "ctx", ".", "execute_action", "(", "'group:view'", ",", "*", "*", "{", "'storage'", ":", "ctx", ".", "repo", ".", "create_secure_service", "(", "'storage'", ")", ",", "'name'", ":", "name", ",", "}", ")"], "docstring": "Show specified routing group.", "docstring_tokens": ["Show", "specified", "routing", "group", "."], "sha": "d8834f8e04ca42817d5f4e368d471484d4b3419f", "url": "https://github.com/cocaine/cocaine-tools/blob/d8834f8e04ca42817d5f4e368d471484d4b3419f/cocaine/tools/dispatch.py#L1280-L1288", "partition": "train", "idx": 6403}
{"repo": "google/fleetspeak", "path": "fleetspeak/src/client/daemonservice/client/client.py", "func_name": "FleetspeakConnection._ReadN", "original_string": "def _ReadN(self, n):\n    \"\"\"Reads n characters from the input stream, or until EOF.\n\n    This is equivalent to the current CPython implementation of read(n), but\n    not guaranteed by the docs.\n\n    Args:\n      n: int\n\n    Returns:\n      string\n    \"\"\"\n    ret = \"\"\n    while True:\n      chunk = self._read_file.read(n - len(ret))\n      ret += chunk\n\n      if len(ret) == n or not chunk:\n        return ret", "language": "python", "code": "def _ReadN(self, n):\n    \"\"\"Reads n characters from the input stream, or until EOF.\n\n    This is equivalent to the current CPython implementation of read(n), but\n    not guaranteed by the docs.\n\n    Args:\n      n: int\n\n    Returns:\n      string\n    \"\"\"\n    ret = \"\"\n    while True:\n      chunk = self._read_file.read(n - len(ret))\n      ret += chunk\n\n      if len(ret) == n or not chunk:\n        return ret", "code_tokens": ["def", "_ReadN", "(", "self", ",", "n", ")", ":", "ret", "=", "\"\"", "while", "True", ":", "chunk", "=", "self", ".", "_read_file", ".", "read", "(", "n", "-", "len", "(", "ret", ")", ")", "ret", "+=", "chunk", "if", "len", "(", "ret", ")", "==", "n", "or", "not", "chunk", ":", "return", "ret"], "docstring": "Reads n characters from the input stream, or until EOF.\n\n    This is equivalent to the current CPython implementation of read(n), but\n    not guaranteed by the docs.\n\n    Args:\n      n: int\n\n    Returns:\n      string", "docstring_tokens": ["Reads", "n", "characters", "from", "the", "input", "stream", "or", "until", "EOF", "."], "sha": "bc95dd6941494461d2e5dff0a7f4c78a07ff724d", "url": "https://github.com/google/fleetspeak/blob/bc95dd6941494461d2e5dff0a7f4c78a07ff724d/fleetspeak/src/client/daemonservice/client/client.py#L214-L232", "partition": "train", "idx": 239493}
{"repo": "gitenberg-dev/gitberg", "path": "gitenberg/config.py", "func_name": "check_config", "original_string": "def check_config():\n    \"\"\" Report if there is an existing config file\n    \"\"\"\n    configfile = ConfigFile()\n    global data\n    if data.keys() > 0:\n        # FIXME: run a better check of this file\n        print(\"gitberg config file exists\")\n        print(\"\\twould you like to edit your gitberg config file?\")\n    else:\n        print(\"No config found\")\n        print(\"\\twould you like to create a gitberg config file?\")\n    answer = input(\"-->  [Y/n]\")\n    # By default, the answer is yes, as denoted by the capital Y\n    if not answer:\n        answer = 'Y'\n\n    # If yes, generate a new configuration\n    # to be written out as yaml\n\n    if answer in 'Yy':\n        print(\"Running gitberg config generator ...\")\n        # config.exists_or_make()\n        config_gen = ConfigGenerator(current=data)\n        config_gen.ask()\n        # print(config_gen.answers)\n        data = config_gen.answers\n        configfile.write()\n        print(\"Config written to {}\".format(configfile.file_path))", "language": "python", "code": "def check_config():\n    \"\"\" Report if there is an existing config file\n    \"\"\"\n    configfile = ConfigFile()\n    global data\n    if data.keys() > 0:\n        # FIXME: run a better check of this file\n        print(\"gitberg config file exists\")\n        print(\"\\twould you like to edit your gitberg config file?\")\n    else:\n        print(\"No config found\")\n        print(\"\\twould you like to create a gitberg config file?\")\n    answer = input(\"-->  [Y/n]\")\n    # By default, the answer is yes, as denoted by the capital Y\n    if not answer:\n        answer = 'Y'\n\n    # If yes, generate a new configuration\n    # to be written out as yaml\n\n    if answer in 'Yy':\n        print(\"Running gitberg config generator ...\")\n        # config.exists_or_make()\n        config_gen = ConfigGenerator(current=data)\n        config_gen.ask()\n        # print(config_gen.answers)\n        data = config_gen.answers\n        configfile.write()\n        print(\"Config written to {}\".format(configfile.file_path))", "code_tokens": ["def", "check_config", "(", ")", ":", "configfile", "=", "ConfigFile", "(", ")", "global", "data", "if", "data", ".", "keys", "(", ")", ">", "0", ":", "# FIXME: run a better check of this file", "print", "(", "\"gitberg config file exists\"", ")", "print", "(", "\"\\twould you like to edit your gitberg config file?\"", ")", "else", ":", "print", "(", "\"No config found\"", ")", "print", "(", "\"\\twould you like to create a gitberg config file?\"", ")", "answer", "=", "input", "(", "\"-->  [Y/n]\"", ")", "# By default, the answer is yes, as denoted by the capital Y", "if", "not", "answer", ":", "answer", "=", "'Y'", "# If yes, generate a new configuration", "# to be written out as yaml", "if", "answer", "in", "'Yy'", ":", "print", "(", "\"Running gitberg config generator ...\"", ")", "# config.exists_or_make()", "config_gen", "=", "ConfigGenerator", "(", "current", "=", "data", ")", "config_gen", ".", "ask", "(", ")", "# print(config_gen.answers)", "data", "=", "config_gen", ".", "answers", "configfile", ".", "write", "(", ")", "print", "(", "\"Config written to {}\"", ".", "format", "(", "configfile", ".", "file_path", ")", ")"], "docstring": "Report if there is an existing config file", "docstring_tokens": ["Report", "if", "there", "is", "an", "existing", "config", "file"], "sha": "3f6db8b5a22ccdd2110d3199223c30db4e558b5c", "url": "https://github.com/gitenberg-dev/gitberg/blob/3f6db8b5a22ccdd2110d3199223c30db4e558b5c/gitenberg/config.py#L94-L122", "partition": "train", "idx": 8633}
