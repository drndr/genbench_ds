{"input": "Richardson extrapolation with parameter estimation [SEP] def richardson ( vals , k , c = None ) : if c is None : c = richardson_parameter ( vals , k ) return vals [ k ] - ( vals [ k ] - vals [ k - 1 ] ) / c", "target": 1, "target_options": [0, 1]}
{"input": "Retrieves the list of jobTemplates for the current realm . [SEP] def get_all_jobtemplates ( self ) : endpoint = self . _build_url ( 'jobTemplates' , { 'paginationPageSize' : self . PAGE_SIZE } ) data = self . _query_api ( 'GET' , endpoint ) return data [ 'results' ]", "target": 1, "target_options": [0, 1]}
{"input": "Prepare a gemini database from VCF inputs prepared with snpEff . [SEP] def prep_gemini_db ( fnames , call_info , samples , extras ) : data = samples [ 0 ] name , caller , is_batch = call_info build_type = _get_build_type ( fnames , samples , caller ) out_dir = utils . safe_makedir ( os . path . join ( data [ \"dirs\" ] [ \"work\" ] , \"gemini\" ) ) gemini_vcf = get_multisample_vcf ( fnames , name , caller , data ) # If we're building a gemini database, normalize the inputs if build_type : passonly = all ( \"gemini_allvariants\" not in dd . get_tools_on ( d ) for d in samples ) gemini_vcf = normalize . normalize ( gemini_vcf , data , passonly = passonly ) decomposed = True else : decomposed = False ann_vcf = run_vcfanno ( gemini_vcf , data , decomposed ) gemini_db = os . path . join ( out_dir , \"%s-%s.db\" % ( name , caller ) ) if ann_vcf and build_type and not utils . file_exists ( gemini_db ) : ped_file = create_ped_file ( samples + extras , gemini_vcf ) # Original approach for hg19/GRCh37 if vcfanno . is_human ( data , builds = [ \"37\" ] ) and \"gemini_orig\" in build_type : gemini_db = create_gemini_db_orig ( gemini_vcf , data , gemini_db , ped_file ) else : gemini_db = create_gemini_db ( ann_vcf , data , gemini_db , ped_file ) # only pass along gemini_vcf_downstream if uniquely created here if os . path . islink ( gemini_vcf ) : gemini_vcf = None return [ [ ( name , caller ) , { \"db\" : gemini_db if utils . file_exists ( gemini_db ) else None , \"vcf\" : ann_vcf or gemini_vcf , \"decomposed\" : decomposed } ] ]", "target": 1, "target_options": [0, 1]}
{"input": "Load administration interface from entry point group . [SEP] def load_entry_point_group ( self , entry_point_group ) : for ep in pkg_resources . iter_entry_points ( group = entry_point_group ) : admin_ep = dict ( ep . load ( ) ) keys = tuple ( k in admin_ep for k in ( 'model' , 'modelview' , 'view_class' ) ) if keys == ( False , False , True ) : self . register_view ( admin_ep . pop ( 'view_class' ) , * admin_ep . pop ( 'args' , [ ] ) , * * admin_ep . pop ( 'kwargs' , { } ) ) elif keys == ( True , True , False ) : warnings . warn ( 'Usage of model and modelview kwargs are deprecated in ' 'favor of view_class, args and kwargs.' , PendingDeprecationWarning ) self . register_view ( admin_ep . pop ( 'modelview' ) , admin_ep . pop ( 'model' ) , admin_ep . pop ( 'session' , db . session ) , * * admin_ep ) else : raise Exception ( 'Admin entry point dictionary must contain ' 'either \"view_class\" OR \"model\" and \"modelview\" keys.' )", "target": 1, "target_options": [0, 1]}
{"input": "Returns vector from top to bottom [SEP] def get_vec_tb ( self ) : return self . height * self . sin_a ( ) , self . height * self . cos_a ( )", "target": 1, "target_options": [0, 1]}
{"input": "Returns an alignment and a tree from Sequences object seqs . [SEP] def align_and_build_tree ( seqs , moltype , best_tree = False , params = None ) : aln = align_unaligned_seqs ( seqs , moltype = moltype , params = params ) tree = build_tree_from_alignment ( aln , moltype , best_tree , params ) return { 'Align' : aln , 'Tree' : tree }", "target": 1, "target_options": [0, 1]}
{"input": "Auto - update the pre - commit config to the latest versions of repos . [SEP] def autoupdate ( config_file , store , tags_only , repos = ( ) ) : migrate_config ( config_file , quiet = True ) retv = 0 output_repos = [ ] changed = False input_config = load_config ( config_file ) for repo_config in input_config [ 'repos' ] : if ( repo_config [ 'repo' ] in { LOCAL , META } or # Skip updating any repo_configs that aren't for the specified repo repos and repo_config [ 'repo' ] not in repos ) : output_repos . append ( repo_config ) continue output . write ( 'Updating {}...' . format ( repo_config [ 'repo' ] ) ) try : new_repo_config = _update_repo ( repo_config , store , tags_only ) except RepositoryCannotBeUpdatedError as error : output . write_line ( error . args [ 0 ] ) output_repos . append ( repo_config ) retv = 1 continue if new_repo_config [ 'rev' ] != repo_config [ 'rev' ] : changed = True output . write_line ( 'updating {} -> {}.' . format ( repo_config [ 'rev' ] , new_repo_config [ 'rev' ] , ) , ) output_repos . append ( new_repo_config ) else : output . write_line ( 'already up to date.' ) output_repos . append ( repo_config ) if changed : output_config = input_config . copy ( ) output_config [ 'repos' ] = output_repos _write_new_config_file ( config_file , output_config ) return retv", "target": 1, "target_options": [0, 1]}
{"input": "Sets the amperage of each motor for when it is activated by driver . Values are initialized from the robot_config . high_current values and can then be changed through this method by other parts of the API . [SEP] def set_active_current ( self , settings ) : self . _active_current_settings [ 'now' ] . update ( settings ) # if an axis specified in the `settings` is currently active, # reset it's current to the new active-current value active_axes_to_update = { axis : amperage for axis , amperage in self . _active_current_settings [ 'now' ] . items ( ) if self . _active_axes . get ( axis ) is True if self . current [ axis ] != amperage } if active_axes_to_update : self . _save_current ( active_axes_to_update , axes_active = True )", "target": 1, "target_options": [0, 1]}
{"input": "Compute the macro average scores for the ROCAUC curves . [SEP] def _score_macro_average ( self , n_classes ) : # Gather all FPRs all_fpr = np . unique ( np . concatenate ( [ self . fpr [ i ] for i in range ( n_classes ) ] ) ) avg_tpr = np . zeros_like ( all_fpr ) # Compute the averages per class for i in range ( n_classes ) : avg_tpr += interp ( all_fpr , self . fpr [ i ] , self . tpr [ i ] ) # Finalize the average avg_tpr /= n_classes # Store the macro averages self . fpr [ MACRO ] = all_fpr self . tpr [ MACRO ] = avg_tpr self . roc_auc [ MACRO ] = auc ( self . fpr [ MACRO ] , self . tpr [ MACRO ] )", "target": 1, "target_options": [0, 1]}
{"input": "Decorator that logs the cost time of a function . [SEP] def timeit ( func ) : @ wraps ( func ) def wrapped_func ( * args , * * kwargs ) : start = timer ( ) result = func ( * args , * * kwargs ) cost = timer ( ) - start logger . debug ( '<method: %s> finished in %2.2f sec' % ( func . __name__ , cost ) ) return result return wrapped_func", "target": 1, "target_options": [0, 1]}
